import sys
from pprint import pprint
import subprocess
import platform
import tarfile
import StringIO
from optparse import OptionParser
import os
import hashlib
import difflib
import sqlite3
import shutil

env_file = ""	
common_mountfile = ""
special_files = ""
hardware_platform = ""
os_type = ""
mount_dict = {}
task_path = ""
condor_submit_path = ""
parrot_submit_path = ""
task_file = ""
condor_submit_file = ""
parrot_submit_file = ""
condor_requirements = ""
user_cmd = ""

if sys.version_info >= (3,):
	import urllib.request as urllib2
	import urllib.parse as urlparse
else:
	import urllib2
	import urlparse

if sys.version_info > (2,6,):
	import json
else:
	import simplejson as json #json module is introduce in python 2.4.3

def md5_cal(filename, block_size=2**20):
	try:
		with open(filename, 'rb') as f:
			md5 = hashlib.md5()
			while True:
				data = f.read(block_size)
				if not data:
					break
				md5.update(data)
			return md5.hexdigest()
	except:
		sys.exit("md5_cal(" + filename + ") failed.\n")

def url_check(url):
	try:
		f = urllib2.urlopen(urllib2.Request(url))
	except:
		print "url({0}) is broken.".format(url)
		return 1
	return 0

#Problem: this function needs extension: redirection of remote dependencies
def remote_dependencies_check(remote_dependencies, package_dir, behavior):
	print "remote dependencies checking ..."
	for item_1 in remote_dependencies:
		item = remote_dependencies[item_1]
		pprint(item)
		url = item["remote-storage-location"]
		if url_check(url) == 1:
			sys.exit(0)
		checksum = item["checksum"]
		checksum_tool = item["checksum-tool"]
		dest = item["location-in-package"]
		format_remote_storage = item["remote-storage-format"]
		if format_remote_storage == "git":
			branch_name = item["branch-name"]
		else:
			branch_name = ""
		download_func(url, checksum, checksum_tool, dest, format_remote_storage, package_dir, branch_name)

def download_dependency(url, checksum, checksum_tool, dest, format_remote_storage):
	print "entre into download_dependency"
	print url, checksum, checksum_tool, dest, format_remote_storage
	dir_dest = os.path.dirname(dest)
	old_dest = dest

	scheme, netloc, path, query, fragment = urlparse.urlsplit(url)
	filename = os.path.basename(path)
	dest = os.path.join(dir_dest, filename)

	if not os.path.exists(dir_dest):
		os.makedirs(dir_dest)

	if os.path.exists(dest):
		if checksum_tool == "md5sum":
			local_checksum = md5_cal(dest)
		else:
			sys.exit(checksum_tool + "is not supported currently!")
		if not local_checksum == checksum:
			os.remove(dest)
			if os.path.exists(old_dest):
				shutil.rmtree(old_dest)

	if not os.path.exists(dest):
		try:
			response = urllib2.urlopen(url)
			data = response.read()
		except URLerror as e:
			print "URLerror({0}): {1}".format(e.errno, e.strerror)
			sys.exit(0)
		with open(dest, "wb") as code:
			code.write(data)

	if checksum_tool == "md5sum":
		local_checksum = md5_cal(dest)
	else:
		sys.exit(checksum_tool + "is not supported currently!")

	if not local_checksum == checksum:
		print local_checksum, checksum
		sys.exit("the version of " + url + " is incorrect!\n")
	
	if not os.path.exists(old_dest):
		tfile = tarfile.open(dest, "r:gz")
		tfile.extractall(dir_dest)

#the db table itself does not understand the collaberation relationship between cvmfs, parrot, SITECONF
def cvmfs_software(item, conn_cursor, package_dir, batch_type):
	if batch_type == "local":
		#construct the parrot submit script
		parrot_submit_file.write("#!/bin/sh\n")
		parrot_submit_file.write("export HTTP_PROXY=http://cache01.hep.wisc.edu:3128\n")
		#download cctools
		cctools_item = db_search("cctools", "", "x86_64", conn_cursor) 
		print cctools_item
		dest = os.path.dirname(package_dir) + "/cache/cctools-x86_64-redhat5"
		download_dependency(cctools_item[3], cctools_item[6], "md5sum", dest, "tgz")
		cvmfs_repo = item[3][6:]
		print cvmfs_repo
		if cvmfs_repo == "cms.cern.ch":
			parrot_submit_file.write("export CMS_VERSION=" + item[1] + "\n")
			parrot_submit_file.write("export SCRAM_ARCH=" + item[2] + "\n")
			task_file.write('#!/bin/sh\n')
			task_file.write('rm -rf ${CMS_VERSION}\n')
			task_file.write('mkdir ${CMS_VERSION}\n')
			task_file.write('cd ${CMS_VERSION}\n')
			task_file.write('\n')
			task_file.write('. /cvmfs/cms.cern.ch/cmsset_default.sh\n')
			task_file.write('scramv1 project CMSSW ${CMS_VERSION}\n')
			task_file.write('cd ${CMS_VERSION}\n')
			task_file.write('eval `scram runtime -sh`\n')
			task_file.write('cd ..\n')
			task_file.write(user_cmd[0] + '\n')
			parrot_submit_file.write(dest + "/bin/parrot_run -M")
			#download SITECONF
			site_item = db_search("cms-siteconf-local-cvmfs", "", "", conn_cursor)
			dest = os.path.dirname(package_dir) + "/cache/cvmfs/cms.cern.ch/SITECONF"
			download_dependency(site_item[3], site_item[6], "md5sum", dest, "tgz")
			parrot_submit_file.write("/cvmfs/cms.cern.ch/SITECONF/local=" + dest + "/local /bin/sh task.sh\n" )
	elif batch_type == "condor":
		pass			

def db_search(name, version, platform, conn_cursor):
	sql_cmd = 'SELECT * FROM sw_table where name = "' + name + '" and version = "' + version + '" and platform = "' + platform + '"'
	conn_cursor.execute(sql_cmd)
	result = conn_cursor.fetchall()
	if len(result) == 0:
		sys.exit(sql_cmd + " fails!\n")
	item = result[0]
	return item

def dependency_process(name, version, platform, conn_cursor, package_dir, batch_type):
	item = db_search(name, version, platform, conn_cursor)
#table schema: (name text, version text, platform text, store text, store_type text, type text)
	store = item[3] 
	print store[0:5]
	if store[0:5] == "cvmfs":
		cvmfs_software(item, conn_cursor, package_dir, batch_type)	

def execution_environment_check(execution_environment, package_dir, batch_type):
	print "Execution environment checking ..."
	print execution_environment["hardware-platform"]
	print execution_environment["os"]
	global hardware_platform
	global os_type
	hardware_platform = execution_environment["hardware-platform"]
	os_type = execution_environment["os"]

	global task_path
	global parrot_submit_path
	global condor_submit_path
	task_path = package_dir + "/task.sh"
	parrot_submit_path = package_dir + "/local.sh"
	condor_submit_path = package_dir + "/task.submit"
	global task_file
	global parrot_submit_file
	global condor_submit_file
	task_file = open(task_path, "wb")
	parrot_submit_file = open(parrot_submit_path, "wb")
	condor_submit_file = open(condor_submit_path, "wb")

	if batch_type == "local":
		uname_list = platform.uname() #(system,node,release,version,machine,processor)
		for i in range(len(uname_list)):
			print uname_list[i]
		print ''
	
		if execution_environment["hardware-platform"].lower() != uname_list[4].lower():
			sys.exit("The specification requires " + execution_environment["hardware-platform"].lower() + ", but the machine is " + uname_list[4].lower() + "!\n")
	
		if execution_environment["os"].lower() != uname_list[0].lower():
			sys.exit("The specification requires " + execution_environment["os"].lower() + ", but the machine is " + uname_list[0].lower() + "!\n")
	elif batch_type == "condor":
		global condor_requirements
		condor_requirements = 'TARGET.Arch == "' + hardware_platform + '" && TARGET.OpSys == "' + os_type + '"'	
		print condor_requirements
	else:
		sys.exit(batch_type + " is not supported currently!\n")

def software_dependencies_installation(software_dependencies, conn_cursor, package_dir, batch_type):
	print "Installing software dependencies ..."
	i = 1
	for item in software_dependencies:
		name = software_dependencies[item]['name']
		version = software_dependencies[item]['version']
		platform = software_dependencies[item]['platform']
		dependency_process(name, version, platform, conn_cursor, package_dir, batch_type)
		i = i + 1

def dynamic_linker_path():
	if hardware_platform == "x86_64":
		return os.path.dirname(env_file) + "/lib64/ld-linux-x86-64.so.2"	
	else:
		return "undefined platform type"

def construct_mountfile(package_dir):
	print mount_dict
	mountfile = package_dir + "/mountlist"		
	new_root = mount_dict["/"]
	del mount_dict["/"]
	print mount_dict
	with open(mountfile, "wb") as file1:
		file1.write("/ " + new_root + "\n")	
		file1.write(new_root + " " + new_root + "\n")	
		for key in mount_dict:
			file1.write(key + " " + mount_dict[key] + "\n")
			file1.write(mount_dict[key] + " " + mount_dict[key] + "\n")
		print "common_mountfile"	
		print common_mountfile
		with open(common_mountfile, "rb") as file2:
			for line in file2:
				file1.write(line)
				print line
		print "special_files"
		print special_files
		with open(special_files, "rb") as file3:
			for line in file3:
				file1.write(line)
				print line
	return mountfile

def construct_env():
	print env_file
	with open(env_file, "rb") as file1:
		env_dict = {}
		for line in file1:
			index = line.find("=")
#			key = '"' + line[:index] + '"'
#			value = '"' + line[(index+1):-1] + '"'
			key = line[:index] 
			value = line[(index+1):-1] 
			env_dict[key] = value	
		return env_dict

def func1(cmd, output_dir):
	print cmd
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/stdout"
	with open(stdout, 'w+') as file1:
		file1.write(output)
#	print "Command output : ", output
#	print "Command exit status/return code : ", p_status
	

def workflow_repeat(package_dir, batch_type, output_dir):
	os.chdir(package_dir)
	task_file.close()
	parrot_submit_file.close()
	condor_submit_file.close()
	if batch_type == "local":
		#set environment variables dict, ld-linux path throught -l parameter of parrot_run, set mountlist through -m parameter of parrot_run
		#cmd = "/bin/sh local.sh" 
		cmd = "/bin/sh " + package_dir + "/local.sh"
		func1(cmd, output_dir)
	elif batch_type == "condor":
		pass
	else:
		pass

def specification_process(json_package, package_dir, method, behavior, cmd, conn_cursor, batch_type, output_dir):
	if not os.path.exists(package_dir):
		os.makedirs(package_dir)
	#if batch_type is local, create the task.sh based on the user's requirements, download parrot, download SITEINFO, create a clean environment, do the experiment.
	#if batch_type is condor, create the task.sh based on the user's requirements, create condor submit file, submit condor job.
	if json_package.has_key("execution-environment") and json_package["execution-environment"]:
		execution_environment_check(json_package["execution-environment"], package_dir, batch_type)
	else:
		print "this spec has no execution-environment"

	if json_package.has_key("software-dependencies") and json_package["software-dependencies"]:
		software_dependencies_installation(json_package["software-dependencies"], conn_cursor, package_dir, batch_type)
	else:
		print "this spec has no software-dependencies"

	workflow_repeat(package_dir, batch_type, output_dir)
#
def dependency_check(dependency_list):
	for item in dependency_list:
		print "dependency check -- ", item, " "
		p = subprocess.Popen("which " + item, stdout = subprocess.PIPE, shell = True)
		(output, err) = p.communicate()
		p_status = p.wait()
		if p_status != 0:
			sys.exit("command `which(" + item + ")` failed. Please install " + item + " and ensure its directory be added into the PATH environment varibale.\n")

def get_sandbox_id(path):
	i = 1
	while(os.path.exists(path + '/' + str(i))):
		i = i + 1
	return i

def main():
	#Problem: extension support incremental download
	parser = OptionParser(usage="usage: %prog [options] run \"command\"",
						version="%prog 1.0")
	parser.add_option("-c", "--config",
					action="store",
					default="./package.json",
					help="The specification json file")
	parser.add_option("-s", "--sandbox",
					action="store", # optional because action defaults to "store"
					default="./test",
					help="The path of sandbox",)
	parser.add_option("-o", "--output",
					action="store", # optional because action defaults to "store"
					default="./test",
					help="The path of output",)
	parser.add_option("-T", "--batch_type",
					action="store", # optional because action defaults to "store"
					default="local",
					help="Batch system type. One of: local, cloud, condor. (By default: local)",)
	parser.add_option("-m", "--method",
					action="store", # optional because action defaults to "store"
					default="parrot",
					help="Repeat method (chroot:require root account; parrot: does not require root account.)",)
	parser.add_option("--source",
					action="store", # optional because action defaults to "store"
					help="The specification source.",)
	parser.add_option("--target",
					action="store", # optional because action defaults to "store"
					help="The specification destination.",)
	(options, args) = parser.parse_args()

	print 'Number of arguments:', len(sys.argv), 'arguments.'
	print 'Argument List:', str(sys.argv)
	cmd = sys.argv[-1]

	behavior = args[0]
	if behavior not in ["run", "setup", "localize", "merge", "diff"]:
		print "Behaviors currently supported by spectool: run, setup, localize, merge, and diff.\n"

	output_dir = options.output
	output_dir = os.path.abspath(output_dir)

	if behavior in ["run", "setup", "localize", "merge"]:
		sandbox = options.sandbox
		sandbox = os.path.abspath(sandbox)
		sandbox_no = get_sandbox_id(sandbox)
		package_dir = sandbox + '/' + str(sandbox_no)
		print package_dir
#		if os.path.exists(package_dir):
#			print "This sandbox already exists! Please choose another sandbox or first delete this sandbox!!\n"
#			sys.exit(0)
		method = options.method
#		if method == "chroot" and os.getuid() != 0:
#			print "chroot method needs root authority! Please first log in as the root account and then run the program again!!\n"
#			sys.exit(0)
#		if method != "chroot" and method != "parrot":
#			print "spectool currently only support two methods: parrot and chroot.\n"
#			sys.exit(0)

		json_file = options.config
		if not os.path.isfile(json_file):
			print "The json file does not exists! Please check!!\n"
			sys.exit(0)
		with open(json_file) as json_data: #python 2.4 does not support this syntax: with open () as
			json_spec = json.load(json_data)
			package_spec = json_spec["package"]

	conn = sqlite3.connect('software.db')
	conn_cursor = conn.cursor()
	batch_type = options.batch_type
	print "batch_type:", batch_type

	global user_cmd
	user_cmd = args[1:]

	if behavior in ["run", "setup", "localize"]:
		dependency_list = []
		dependency_check(dependency_list)
		specification_process(package_spec, package_dir, method, behavior, cmd, conn_cursor, batch_type, output_dir)

	if behavior == "localize":
		package_spec["package-location"] = package_dir
		new_json = "local.json"
		outfile_name = os.path.join(package_dir, new_json)
		with open(outfile_name, "w") as outfile:
			json.dump(json_spec, outfile, indent = 4)
		print "The localized version of the specification is: " + new_json + '\n'
		conn.close()

if __name__ == "__main__":
	main()
#	cmd = "/bin/sh " + "/afs/nd.edu/user20/hmeng/code-github/cctools/spectool/test/18" + "/local.sh"
#	print cmd
#	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
#	(output, err) = p.communicate()
#	p_status = p.wait()
#	print "Command output : ", output
#	print "Command exit status/return code : ", p_status
	


#set sts=4 sw=4 ts=4 expandtab ft=python
