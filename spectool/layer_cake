#!/usr/bin/python
import sys
from pprint import pprint
import subprocess
import platform
import tarfile
import StringIO
from optparse import OptionParser
import os
import hashlib
import difflib
import sqlite3
import shutil

env_file = ""	
common_mountfile = ""
special_files = ""
hardware_platform = ""
os_type = ""
linux_distro = ''
dist_name = ''
dist_version = ''
mount_dict = {}
task_path = ""
condor_submit_path = ""
parrot_submit_path = ""
task_file = ""
condor_submit_file = ""
parrot_submit_file = ""
condor_requirements = ""
user_cmd = ""

if sys.version_info >= (3,):
	import urllib.request as urllib2
	import urllib.parse as urlparse
else:
	import urllib2
	import urlparse

if sys.version_info > (2,6,):
	import json
else:
	import simplejson as json #json module is introduce in python 2.4.3

def md5_cal(filename, block_size=2**20):
	try:
		with open(filename, 'rb') as f:
			md5 = hashlib.md5()
			while True:
				data = f.read(block_size)
				if not data:
					break
				md5.update(data)
			return md5.hexdigest()
	except:
		sys.exit("md5_cal(" + filename + ") failed.\n")

def url_check(url):
	try:
		f = urllib2.urlopen(urllib2.Request(url))
	except:
		print "url({0}) is broken.".format(url)
		return 1
	return 0

#Problem: this function needs extension: redirection of remote dependencies
def remote_dependencies_check(remote_dependencies, package_dir, behavior):
	print "remote dependencies checking ..."
	for item_1 in remote_dependencies:
		item = remote_dependencies[item_1]
		pprint(item)
		url = item["remote-storage-location"]
		if url_check(url) == 1:
			sys.exit(0)
		checksum = item["checksum"]
		checksum_tool = item["checksum-tool"]
		dest = item["location-in-package"]
		format_remote_storage = item["remote-storage-format"]
		if format_remote_storage == "git":
			branch_name = item["branch-name"]
		else:
			branch_name = ""
		download_func(url, checksum, checksum_tool, dest, format_remote_storage, package_dir, branch_name)

def download_dependency(url, checksum, checksum_tool, dest, format_remote_storage):
	print "entre into download_dependency"
	print url, checksum, checksum_tool, dest, format_remote_storage
	dir_dest = os.path.dirname(dest)
	old_dest = dest

	scheme, netloc, path, query, fragment = urlparse.urlsplit(url)
	filename = os.path.basename(path)
	dest = os.path.join(dir_dest, filename)

	if not os.path.exists(dir_dest):
		os.makedirs(dir_dest)

#	if os.path.exists(dest):
#		if checksum_tool == "md5sum":
#			local_checksum = md5_cal(dest)
#		else:
#			sys.exit(checksum_tool + "is not supported currently!")
#		if not local_checksum == checksum:
#			os.remove(dest)
#			if os.path.exists(old_dest):
#				shutil.rmtree(old_dest)

	if not os.path.exists(dest):
		try:
			response = urllib2.urlopen(url)
			data = response.read()
		except URLerror as e:
			print "URLerror({0}): {1}".format(e.errno, e.strerror)
			sys.exit(0)
		with open(dest, "wb") as code:
			code.write(data)

	if checksum_tool == "md5sum":
		local_checksum = md5_cal(dest)
	else:
		sys.exit(checksum_tool + "is not supported currently!")

	if not local_checksum == checksum:
		print local_checksum, checksum
		sys.exit("the version of " + url + " is incorrect!\n")
	
	if not os.path.exists(old_dest):
		tfile = tarfile.open(dest, "r:gz")
		tfile.extractall(dir_dest)

#the db table itself does not understand the collaberation relationship between cvmfs, parrot, SITECONF
def cvmfs_software(item, sw_conn_cursor, package_dir, batch_type):
	if batch_type == "local":
		#construct the parrot submit script
		parrot_submit_file.write("#!/bin/sh\n")
		parrot_submit_file.write("export HTTP_PROXY=http://cache01.hep.wisc.edu:3128\n")
		#download cctools
		cctools_item = db_search("cctools", "redhat5", "x86_64", sw_conn_cursor) 
		print cctools_item
		dest = os.path.dirname(package_dir) + "/cache/cctools-x86_64-redhat5"
		download_dependency(cctools_item[3], cctools_item[6], "md5sum", dest, "tgz")
		cvmfs_repo = item[3][6:]
		print cvmfs_repo
		if cvmfs_repo == "cms.cern.ch":
			parrot_submit_file.write("export CMS_VERSION=" + item[1] + "\n")
			parrot_submit_file.write("export SCRAM_ARCH=" + item[2] + "\n")
			task_file.write('#!/bin/sh\n')
			task_file.write('rm -rf ${CMS_VERSION}\n')
			task_file.write('mkdir ${CMS_VERSION}\n')
			task_file.write('cd ${CMS_VERSION}\n')
			task_file.write('\n')
			task_file.write('. /cvmfs/cms.cern.ch/cmsset_default.sh\n')
			task_file.write('scramv1 project CMSSW ${CMS_VERSION}\n')
			task_file.write('cd ${CMS_VERSION}\n')
			task_file.write('eval `scram runtime -sh`\n')
			task_file.write('cd ..\n')
			task_file.write(user_cmd[0] + '\n')
			parrot_submit_file.write(dest + "/bin/parrot_run -M")
			#download SITECONF
			site_item = db_search("cms-siteconf-local-cvmfs", "", "", sw_conn_cursor)
			dest = os.path.dirname(package_dir) + "/cache/cvmfs/cms.cern.ch/SITECONF"
			download_dependency(site_item[3], site_item[6], "md5sum", dest, "tgz")
			parrot_submit_file.write("/cvmfs/cms.cern.ch/SITECONF/local=" + dest + "/local /bin/sh task.sh\n" )
	elif batch_type == "condor":
		pass			
	elif batch_type == "ec2":
		pass
	else:
		pass

def db_search(name, version, platform, sw_conn_cursor):
	sql_cmd = 'SELECT * FROM sw_table where name = "' + name + '" and version = "' + version + '" and platform = "' + platform + '"'
	sw_conn_cursor.execute(sql_cmd)
	result = sw_conn_cursor.fetchall()
	if len(result) == 0:
		sys.exit(sql_cmd + " fails!\n")
	item = result[0]
	return item

def dependency_process(name, version, platform, sw_conn_cursor, package_dir, batch_type):
	item = db_search(name, version, platform, sw_conn_cursor)
#table schema: (name text, version text, platform text, store text, store_type text, type text)
	store = item[3] 
	print store[0:5]
	if store[0:5] == "cvmfs":
		cvmfs_software(item, sw_conn_cursor, package_dir, batch_type)	

def ec2_execution_environment_check ( execution_environment ):
	print "Execution ec2 environment checking ..."
	global hardware_platform
	hardware_platform = execution_environment["hardware-platform"]
	distro_name = execution_environment["linux-distribution"]["dist-name"].lower()
	distro_version = execution_environment["linux-distribution"]["dist-version"]
	index = distro_version.find('.')
	global dist_name
	dist_name = distro_name
	global dist_version
	dist_version = distro_version
	global linux_distro
	linux_distro = distro_name + distro_version[:index]

def execution_environment_check(execution_environment, package_dir, batch_type):
	print "Execution environment checking ..."
	print execution_environment["hardware-platform"]
	print execution_environment["os"]
	global hardware_platform
	global os_type
	hardware_platform = execution_environment["hardware-platform"]
	os_type = execution_environment["os"]

	global task_path
	global parrot_submit_path
	global condor_submit_path
	task_path = package_dir + "/task.sh"
	parrot_submit_path = package_dir + "/local.sh"
	condor_submit_path = package_dir + "/task.submit"
	global task_file
	global parrot_submit_file
	global condor_submit_file
	task_file = open(task_path, "wb")
	parrot_submit_file = open(parrot_submit_path, "wb")
	condor_submit_file = open(condor_submit_path, "wb")

	if batch_type == "local":
		uname_list = platform.uname() #(system,node,release,version,machine,processor)
		for i in range(len(uname_list)):
			print uname_list[i]
		print ''
	
		if execution_environment["hardware-platform"].lower() != uname_list[4].lower():
			sys.exit("The specification requires " + execution_environment["hardware-platform"].lower() + ", but the machine is " + uname_list[4].lower() + "!\n")
	
		if execution_environment["os"].lower() != uname_list[0].lower():
			sys.exit("The specification requires " + execution_environment["os"].lower() + ", but the machine is " + uname_list[0].lower() + "!\n")
	elif batch_type == "condor":
		global condor_requirements
		condor_requirements = 'TARGET.Arch == "' + hardware_platform + '" && TARGET.OpSys == "' + os_type + '"'	
		print condor_requirements
	elif batch_type == "ec2":
		pass
	else:
		sys.exit(batch_type + " is not supported currently!\n")

def software_dependencies_installation(software_dependencies, sw_conn_cursor, package_dir, batch_type):
	print "Installing software dependencies ..."
	i = 1
	for item in software_dependencies:
		name = software_dependencies[item]['name']
		version = software_dependencies[item]['version']
		platform = software_dependencies[item]['platform']
		dependency_process(name, version, platform, sw_conn_cursor, package_dir, batch_type)
		i = i + 1

def dynamic_linker_path():
	if hardware_platform == "x86_64":
		return os.path.dirname(env_file) + "/lib64/ld-linux-x86-64.so.2"	
	else:
		return "undefined platform type"

def construct_mountfile(package_dir):
	print mount_dict
	mountfile = package_dir + "/mountlist"		
	new_root = mount_dict["/"]
	del mount_dict["/"]
	print mount_dict
	with open(mountfile, "wb") as file1:
		file1.write("/ " + new_root + "\n")	
		file1.write(new_root + " " + new_root + "\n")	
		for key in mount_dict:
			file1.write(key + " " + mount_dict[key] + "\n")
			file1.write(mount_dict[key] + " " + mount_dict[key] + "\n")
		print "common_mountfile"	
		print common_mountfile
		with open(common_mountfile, "rb") as file2:
			for line in file2:
				file1.write(line)
				print line
		print "special_files"
		print special_files
		with open(special_files, "rb") as file3:
			for line in file3:
				file1.write(line)
				print line
	return mountfile

def construct_env():
	print env_file
	with open(env_file, "rb") as file1:
		env_dict = {}
		for line in file1:
			index = line.find("=")
#			key = '"' + line[:index] + '"'
#			value = '"' + line[(index+1):-1] + '"'
			key = line[:index] 
			value = line[(index+1):-1] 
			env_dict[key] = value	
		return env_dict

def func1(cmd, output_dir):
	print cmd
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/stdout"
	with open(stdout, 'w+') as file1:
		file1.write(output)
#	print "Command output : ", output
#	print "Command exit status/return code : ", p_status
	

def workflow_repeat(package_dir, batch_type, output_dir):
	os.chdir(package_dir)
	task_file.close()
	parrot_submit_file.close()
	condor_submit_file.close()
	if batch_type == "local":
		#set environment variables dict, ld-linux path throught -l parameter of parrot_run, set mountlist through -m parameter of parrot_run
		#cmd = "/bin/sh local.sh" 
		cmd = "/bin/sh " + package_dir + "/local.sh"
		func1(cmd, output_dir)
	elif batch_type == "condor":
		pass
	elif batch_type == "ec2":
		pass
	else:
		pass

def func_call(cmd):
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()


def ec2_process(json_package, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type):
	if json_package.has_key("execution-environment") and json_package["execution-environment"]:
		ec2_execution_environment_check(json_package["execution-environment"])
		print hardware_platform
		print linux_distro
	else:
		print "this spec has no execution-environment"



	batch_set = ['ec2_level1', 'ec2_level2', 'ec2_level3', 'ec2_level4']
	if batch_type in batch_set:
		cmd = 'ssh -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'yum -y install wget\''
		print cmd	
		func_call(cmd)
		
		python_item = db_search("python", linux_distro, hardware_platform, sw_conn_cursor) 
		python_url = python_item[3]
		#get the url of python
		cmd = 'ssh -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'wget ' + python_url + '\''
		print cmd	
		func_call(cmd)
		
		scheme, netloc, path, query, fragment = urlparse.urlsplit(python_url)
		python_url_filename = os.path.basename(path)
		cmd = 'ssh -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'tar zxvf ' + python_url_filename + '\''
		print cmd	 
		func_call(cmd)
	
	batch_set = ['ec2_level1', 'ec2_level2']
	#another way to do this is to add the os information into the json file
	if batch_type in batch_set:
		os_item = db_search(dist_name, dist_version, hardware_platform, sw_conn_cursor)
		os_url = os_item[3]
		cmd = 'ssh -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'wget ' + os_url + '\''
		print cmd	
		func_call(cmd)

		#set the parrot_run -m parameter
		scheme, netloc, path, query, fragment = urlparse.urlsplit(os_url)
		os_url_filename = os.path.basename(path)
		cmd = 'ssh -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'tar zxvf ' + os_url_filename + '\''
		print cmd	 
		func_call(cmd)

	#scp layer_cake, cmssw.json, software.db to vm
	cmd = 'scp -i ' + ssh_key + ' layer_cake software.db ' + json_file + ' ' + user_name + '@' + public_dns + ':' 
	print cmd
	func_call(cmd)

	python_dir = "python-%s_%s" % (hardware_platform, linux_distro) 
	cmd = 'ssh -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'' + python_dir + '/bin/python layer_cake -c ' + json_file + ' -s specification -o output run "' + user_cmd[0] + '"\''
	print cmd	 
	func_call(cmd)

	cmd = 'ssh -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'tar czf output.tar.gz -C output stdout\''
	print cmd	 
	func_call(cmd)

	cmd = 'scp -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ':output.tar.gz .'
	print cmd	 
	func_call(cmd)

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)

	cmd = 'tar zxC ' + output_dir + ' -f output.tar.gz'
	print cmd	 
	func_call(cmd)

def specification_process(json_package, package_dir, method, behavior, cmd, sw_conn_cursor, cloud_conn_cursor, batch_type, output_dir):
	if not os.path.exists(package_dir):
		os.makedirs(package_dir)
	#if batch_type is local, create the task.sh based on the user's requirements, download parrot, download SITEINFO, create a clean environment, do the experiment.
	#if batch_type is condor, create the task.sh based on the user's requirements, create condor submit file, submit condor job.
	if json_package.has_key("execution-environment") and json_package["execution-environment"]:
		execution_environment_check(json_package["execution-environment"], package_dir, batch_type)
	else:
		print "this spec has no execution-environment"

	if json_package.has_key("software-dependencies") and json_package["software-dependencies"]:
		software_dependencies_installation(json_package["software-dependencies"], sw_conn_cursor, package_dir, batch_type)
	else:
		print "this spec has no software-dependencies"

	workflow_repeat(package_dir, batch_type, output_dir)


def dependency_check(dependency_list):
	for item in dependency_list:
		print "dependency check -- ", item, " "
		p = subprocess.Popen("which " + item, stdout = subprocess.PIPE, shell = True)
		(output, err) = p.communicate()
		p_status = p.wait()
		if p_status != 0:
			sys.exit("command `which(" + item + ")` failed. Please install " + item + " and ensure its directory be added into the PATH environment varibale.\n")

def get_sandbox_id(path):
	i = 1
	while(os.path.exists(path + '/' + str(i))):
		i = i + 1
	return i

def get_instance_id(image_id):
	cmd = 'ec2-run-instances ' + image_id + ' -t t1.micro -k my-key-pair -g sg-24f96141 --associate-public-ip-address true'
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()
	while True:
		line = output.readline()
		if line != '':
			line = line.rstrip()	
			if line[:8] == 'INSTANCE':
				instance_id = line[9:19]
				print instance_id
				return instance_id

def get_public_dns(instance_id):
	public_dns = ''
	while public_dns == '':
		cmd = 'ec2-describe-instances ' + instance_id
		p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
		(output, err) = p.communicate()
		p_status = p.wait()
		while True:
			line = output.readline()
			if line != '':
				line = line.rstrip()	
				str1 = 'PRIVATEIPADDRESS' 
				if line[:len(str1)] == str1:
					index = line.find("ec2")
					public_dns = line[index:-1]
	print public_dns
	return public_dns

def main():
	#Problem: extension support incremental download
	parser = OptionParser(usage="usage: %prog [options] run \"command\"",
						version="%prog 1.0")
	parser.add_option("-c", "--config",
					action="store",
					default="./package.json",
					help="The specification json file")
	parser.add_option("-s", "--sandbox",
					action="store", # optional because action defaults to "store"
					default="./test",
					help="The path of sandbox",)
	parser.add_option("-o", "--output",
					action="store", # optional because action defaults to "store"
					default="./test",
					help="The path of output",)
	parser.add_option("-T", "--batch_type",
					action="store", # optional because action defaults to "store"
					default="local",
					help="Batch system type. One of: local, ec2, condor. (By default: local)",)
	parser.add_option("-m", "--method",
					action="store", # optional because action defaults to "store"
					default="parrot",
					help="Repeat method (chroot:require root account; parrot: does not require root account.)",)
	parser.add_option("--source",
					action="store", # optional because action defaults to "store"
					help="The specification source.",)
	parser.add_option("--target",
					action="store", # optional because action defaults to "store"
					help="The specification destination.",)
	(options, args) = parser.parse_args()

	print 'Number of arguments:', len(sys.argv), 'arguments.'
	print 'Argument List:', str(sys.argv)
	cmd = sys.argv[-1]

	behavior = args[0]
	if behavior not in ["run", "setup", "localize", "merge", "diff"]:
		print "Behaviors currently supported by spectool: run, setup, localize, merge, and diff.\n"

	output_dir = options.output
	output_dir = os.path.abspath(output_dir)

	if behavior in ["run", "setup", "localize", "merge"]:
		sandbox = options.sandbox
		sandbox = os.path.abspath(sandbox)
		sandbox_no = get_sandbox_id(sandbox)
		package_dir = sandbox + '/' + str(sandbox_no)
		print package_dir
		method = options.method

		json_file = options.config
		if not os.path.isfile(json_file):
			print "The json file does not exists! Please check!!\n"
			sys.exit(0)
		with open(json_file) as json_data: #python 2.4 does not support this syntax: with open () as
			json_spec = json.load(json_data)
			package_spec = json_spec["package"]

	sw_conn = sqlite3.connect('software.db')
	sw_conn_cursor = sw_conn.cursor()

	cloud_conn = sqlite3.connect('ec2.db')
	cloud_conn_cursor = cloud_conn.cursor()
	batch_type = options.batch_type
#	print "batch_type:", batch_type

	global user_cmd
	user_cmd = args[1:]

	if behavior in ["run", "setup", "localize"]:
		dependency_list = []
		dependency_check(dependency_list)
		user_name = 'root'
		ssh_key = 'my-key-pair.pem'
		if batch_type == "ec2-level1":
			#ec2-run-instances ami-15166c25 -t t1.micro -k my-key-pair -g sg-24f96141 --associate-public-ip-address true
			#resolve the above result to get the instance id
			#ec2-describe-instances to get the public DNS of the instance id
			instance_id = get_instance_id('ami-15166c25')
			public_dns = get_public_dns(instance_id)
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)

		elif batch_type == "ec2-level2":
			#ssh -i ...
			public_dns = ''	
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		elif batch_type == "ec2-level3":
			#ec2-run-instances ami-d76a29e7 -t t1.micro -k my-key-pair -g sg-24f96141 --associate-public-ip-address true
			#resolve the above result to get the instance id
			#ec2-describe-instances to get the public DNS of the instance id
			instance_id = get_instance_id('ami-d76a29e7')
			public_dns = get_public_dns(instance_id)
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		elif batch_type == "ec2-level4":
			#ssh -i my-key-pair.pem root@ec2-54-186-101-95.us-west-2.compute.amazonaws.com
			public_dns = ''	
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		elif batch_type == "ec2-level5":
			#ssh -i my-key-pair.pem root@ec2-54-186-101-95.us-west-2.compute.amazonaws.com
			public_dns = 'ec2-54-186-101-95.us-west-2.compute.amazonaws.com'
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		else:
			specification_process(package_spec, package_dir, method, behavior, cmd, sw_conn_cursor, cloud_conn_cursor, batch_type, output_dir)

	if behavior == "localize":
		package_spec["package-location"] = package_dir
		new_json = "local.json"
		outfile_name = os.path.join(package_dir, new_json)
		with open(outfile_name, "w") as outfile:
			json.dump(json_spec, outfile, indent = 4)
		print "The localized version of the specification is: " + new_json + '\n'

	sw_conn.close()
	cloud_conn.close()

if __name__ == "__main__":
	main()

#set sts=4 sw=4 ts=4 expandtab ft=python
