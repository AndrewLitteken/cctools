#!/usr/bin/python
import sys
from pprint import pprint
import subprocess
import platform
import tarfile
import StringIO
from optparse import OptionParser
import os
import hashlib
import difflib
import sqlite3
import shutil
import datetime

needed_create_mountfile = 0
sandbox_no = 0
env_file = ""	
common_mountfile = ""
special_files = ""
hardware_platform = ""
os_type = ""
linux_distro = ''
dist_name = ''
dist_version = ''
mount_dict = {}
task_path = ""
condor_submit_path = ""
parrot_submit_path = ""
task_file = ""
condor_submit_file = ""
parrot_submit_file = ""
condor_requirements = ""
user_cmd = ""

if sys.version_info >= (3,):
	import urllib.request as urllib2
	import urllib.parse as urlparse
else:
	import urllib2
	import urlparse

if sys.version_info > (2,6,):
	import json
else:
	import simplejson as json #json module is introduce in python 2.4.3

def func_call(cmd):
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()

def md5_cal(filename, block_size=2**20):
	try:
		with open(filename, 'rb') as f:
			md5 = hashlib.md5()
			while True:
				data = f.read(block_size)
				if not data:
					break
				md5.update(data)
			return md5.hexdigest()
	except:
		sys.exit("md5_cal(" + filename + ") failed.\n")

def url_check(url):
	try:
		f = urllib2.urlopen(urllib2.Request(url))
	except:
		print "url({0}) is broken.".format(url)
		return 1
	return 0

#Problem: this function needs extension: redirection of remote dependencies
def remote_dependencies_check(remote_dependencies, package_dir, behavior):
	print "remote dependencies checking ..."
	for item_1 in remote_dependencies:
		item = remote_dependencies[item_1]
		pprint(item)
		url = item["remote-storage-location"]
		if url_check(url) == 1:
			sys.exit(0)
		checksum = item["checksum"]
		checksum_tool = item["checksum-tool"]
		dest = item["location-in-package"]
		format_remote_storage = item["remote-storage-format"]
		if format_remote_storage == "git":
			branch_name = item["branch-name"]
		else:
			branch_name = ""
		download_func(url, checksum, checksum_tool, dest, format_remote_storage, package_dir, branch_name)

def download_dependency(url, checksum, checksum_tool, dest, format_remote_storage):
	print "entre into download_dependency"
	print url, checksum, checksum_tool, dest, format_remote_storage
	dir_dest = os.path.dirname(dest)
	old_dest = dest

	scheme, netloc, path, query, fragment = urlparse.urlsplit(url)
	filename = os.path.basename(path)
	dest = os.path.join(dir_dest, filename)

	if not os.path.exists(dir_dest):
		os.makedirs(dir_dest)

	if os.path.exists(dest):
		return
#	if os.path.exists(dest):
#		if checksum_tool == "md5sum":
#			local_checksum = md5_cal(dest)
#		else:
#			sys.exit(checksum_tool + "is not supported currently!")
#		if not local_checksum == checksum:
#			os.remove(dest)
#			if os.path.exists(old_dest):
#				shutil.rmtree(old_dest)

	if not os.path.exists(dest):
#		cmd = 'wget -o ' + dest + ' ' + url 
#		print cmd
#		func_call(cmd)

		try:
			response = urllib2.urlopen(url)
			data = response.read()
		except urllib2.URLerror as e:
			print "URLerror({0}): {1}".format(e.errno, e.strerror)
			sys.exit(0)
		with open(dest, "wb") as code:
			code.write(data)

	if checksum_tool == "md5sum":
		local_checksum = md5_cal(dest)
	else:
		sys.exit(checksum_tool + "is not supported currently!")

	if not local_checksum == checksum:
		print local_checksum, checksum
		sys.exit("the version of " + url + " is incorrect!\n")
	
	if not os.path.exists(old_dest):
		tfile = tarfile.open(dest, "r:gz")
		tfile.extractall(dir_dest)

#the db table itself does not understand the collaberation relationship between cvmfs, parrot, SITECONF
def cvmfs_software(item, sw_conn_cursor, package_dir, batch_type):
	if batch_type == "local":
		#construct the parrot submit script
		parrot_submit_file.write("#!/bin/sh\n")
		parrot_submit_file.write("export HTTP_PROXY=http://cache01.hep.wisc.edu:3128\n")
		#download cctools
		cctools_item = db_search("cctools", "redhat5", "x86_64", sw_conn_cursor) 
		#print cctools_item
		dest = os.path.dirname(package_dir) + "/cache/cctools-x86_64-redhat5"
		download_dependency(cctools_item[3], cctools_item[6], "md5sum", dest, "tgz")
		cvmfs_repo = item[3][6:]
		#print cvmfs_repo
		if cvmfs_repo == "cms.cern.ch":
			parrot_submit_file.write("export CMS_VERSION=" + item[1] + "\n")
			parrot_submit_file.write("export SCRAM_ARCH=" + item[2] + "\n")
			task_file.write('#!/bin/sh\n')
			task_file.write('rm -rf ${CMS_VERSION}\n')
			task_file.write('mkdir ${CMS_VERSION}\n')
			task_file.write('cd ${CMS_VERSION}\n')
			task_file.write('\n')
			task_file.write('. /cvmfs/cms.cern.ch/cmsset_default.sh\n')
			task_file.write('scramv1 project CMSSW ${CMS_VERSION}\n')
			task_file.write('cd ${CMS_VERSION}\n')
			task_file.write('eval `scram runtime -sh`\n')
			task_file.write('cd ..\n')
			task_file.write(user_cmd[0] + '\n')
			parrot_submit_file.write(dest + "/bin/parrot_run -M")
			#download SITECONF
			site_item = db_search("cms-siteconf-local-cvmfs", "", "", sw_conn_cursor)
			dest = os.path.dirname(package_dir) + "/cache/cvmfs/cms.cern.ch/SITECONF"
			download_dependency(site_item[3], site_item[6], "md5sum", dest, "tgz")
			parrot_submit_file.write("/cvmfs/cms.cern.ch/SITECONF/local=" + dest + "/local /bin/sh " + package_dir + "/task.sh\n" )
	elif batch_type == "condor":
		pass			
	elif batch_type == "ec2":
		pass
	else:
		pass

def db_search(name, version, platform, sw_conn_cursor):
	sql_cmd = 'SELECT * FROM sw_table where name = "' + name + '" and version = "' + version + '" and platform = "' + platform + '"'
	sw_conn_cursor.execute(sql_cmd)
	result = sw_conn_cursor.fetchall()
	if len(result) == 0:
		sys.exit(sql_cmd + " fails!\n")
	item = result[0]
	return item

def dependency_process(name, version, platform, mountpoint, sw_conn_cursor, package_dir, batch_type):
	item = db_search(name, version, platform, sw_conn_cursor)
	#print "software **** : %s" % item[3]
#table schema: (name text, version text, platform text, store text, store_type text, type text)
	store = item[3] 
	#print store[0:5]
	global mount_dict
	if store[0:5] == "cvmfs":
		cvmfs_software(item, sw_conn_cursor, package_dir, batch_type)	
		mount_dict[mountpoint] = mountpoint
	else:
		#dest = os.path.dirname(package_dir) + "/cache"
		dest = os.path.dirname(package_dir) + "/cache/" + item[0] + '-' + item[1] + '-' + item[2]
		download_dependency(store, item[6], "md5sum", dest, "tgz")
		mount_dict[mountpoint] = dest
	if item[5] == 'os':
		global env_file
		global common_mountfile
		global special_files
		env_file = dest + "/env_list"
		common_mountfile = dest + "/common-mountlist"
		special_files = dest + "/special_files"
		global needed_create_mountfile
		needed_create_mountfile = 1

def ec2_execution_environment_check ( execution_environment ):
	print "Execution ec2 environment checking ..."
	global hardware_platform
	hardware_platform = execution_environment["hardware-platform"]
	distro_name = execution_environment["linux-distribution"]["dist-name"].lower()
	distro_version = execution_environment["linux-distribution"]["dist-version"]
	index = distro_version.find('.')
	global dist_name
	dist_name = distro_name
	global dist_version
	dist_version = distro_version
	global linux_distro
	linux_distro = distro_name + distro_version[:index]

def execution_environment_check(execution_environment, package_dir, batch_type):
	print "Execution environment checking ..."
#	print execution_environment["hardware-platform"]
#	print execution_environment["os"]
	global hardware_platform
	global os_type
	hardware_platform = execution_environment["hardware-platform"]
	os_type = execution_environment["os"]

	global task_path
	global parrot_submit_path
	global condor_submit_path
	task_path = package_dir + "/task.sh"
	parrot_submit_path = package_dir + "/local.sh"
	condor_submit_path = package_dir + "/task.submit"
	global task_file
	global parrot_submit_file
	global condor_submit_file
	task_file = open(task_path, "wb")
	parrot_submit_file = open(parrot_submit_path, "wb")
	condor_submit_file = open(condor_submit_path, "wb")

	if batch_type == "local":
		uname_list = platform.uname() #(system,node,release,version,machine,processor)
#		for i in range(len(uname_list)):
#			print uname_list[i]
#		print ''
	
		if execution_environment["hardware-platform"].lower() != uname_list[4].lower():
			sys.exit("The specification requires " + execution_environment["hardware-platform"].lower() + ", but the machine is " + uname_list[4].lower() + "!\n")
	
		if execution_environment["os"].lower() != uname_list[0].lower():
			sys.exit("The specification requires " + execution_environment["os"].lower() + ", but the machine is " + uname_list[0].lower() + "!\n")
	elif batch_type == "condor":
		global condor_requirements
		condor_requirements = 'TARGET.Arch == "' + hardware_platform + '" && TARGET.OpSys == "' + os_type + '"'	
		print condor_requirements
	elif batch_type == "ec2":
		pass
	else:
		sys.exit(batch_type + " is not supported currently!\n")

def software_dependencies_installation(software_dependencies, sw_conn_cursor, package_dir, batch_type):
	print "Installing software dependencies ..."
	i = 1
	for item in software_dependencies:
		name = software_dependencies[item]['name']
		version = software_dependencies[item]['version']
		platform = software_dependencies[item]['platform']
		mountpoint = software_dependencies[item]['mountpoint']
		#print name, version, platform
		dependency_process(name, version, platform, mountpoint, sw_conn_cursor, package_dir, batch_type)
		i = i + 1

def dynamic_linker_path():
	if hardware_platform == "x86_64":
		return os.path.dirname(env_file) + "/lib64/ld-linux-x86-64.so.2"	
	else:
		return "undefined platform type"

def construct_mountfile(sandbox_dir):
	#print mount_dict
	mountfile = sandbox_dir + "/mountlist"		
	new_root = mount_dict["/"]
	del mount_dict["/"]
	#print mount_dict
	with open(mountfile, "wb") as file1:
		file1.write("/ " + new_root + "\n")	
		file1.write(new_root + " " + new_root + "\n")	
		for key in mount_dict:
			file1.write(key + " " + mount_dict[key] + "\n")
			file1.write(mount_dict[key] + " " + mount_dict[key] + "\n")
		#print "common_mountfile"	
		#print common_mountfile
		with open(common_mountfile, "rb") as file2:
			for line in file2:
				file1.write(line)
		#print "special_files"
		#print special_files
		file1.write(sandbox_dir + ' ' + sandbox_dir + '\n')
		file1.write('/etc/hosts /etc/hosts\n')
		file1.write('/etc/resolv.conf /etc/resolv.conf\n')
		with open(special_files, "rb") as file3:
			for line in file3:
				file1.write(line)
		
	return mountfile

def construct_env(package_dir):
	with open(env_file, "rb") as file1:
		env_dict = {}
		for line in file1:
			index = line.find("=")
#			key = '"' + line[:index] + '"'
#			value = '"' + line[(index+1):-1] + '"'
			key = line[:index] 
			value = line[(index+1):-1] 
			env_dict[key] = value	
		env_dict['PWD'] = package_dir
		return env_dict

def func1(cmd, output_dir):
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/stdout"
	with open(stdout, 'w+') as file1:
		file1.write(output)
	
def func1_withenv(cmd, env_dict, output_dir):
	p = subprocess.Popen(cmd, env = env_dict, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/stdout"
	with open(stdout, 'w+') as file1:
		file1.write(output)


def workflow_repeat(package_dir, batch_type, output_dir):
	os.chdir(package_dir)
	task_file.close()
	parrot_submit_file.close()
	condor_submit_file.close()
	if batch_type == "local":
		if needed_create_mountfile == 1:
			dynamic_linker = dynamic_linker_path()
			mountfile = construct_mountfile(package_dir)
			env_dict = construct_env(package_dir)
			env_dict['PARROT_MOUNT_FILE'] = mountfile
			#here, setting the linker will cause strange errors.
			#env_dict['PARROT_LDSO_PATH'] = dynamic_linker
			print env_dict
			cmd = "/bin/sh " + package_dir + "/local.sh"
			func1_withenv(cmd, env_dict, output_dir)
		#set environment variables dict, ld-linux path throught -l parameter of parrot_run, set mountlist through -m parameter of parrot_run
		#cmd = "/bin/sh local.sh" 
		else:
			cmd = "/bin/sh " + package_dir + "/local.sh"
			func1(cmd, output_dir)



	elif batch_type == "condor":
		pass
	elif batch_type == "ec2":
		pass
	else:
		pass


def ec2_process(json_package, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type):
	if json_package.has_key("execution-environment") and json_package["execution-environment"]:
		ec2_execution_environment_check(json_package["execution-environment"])
		print hardware_platform
		print linux_distro
	else:
		print "this spec has no execution-environment"


	batch_set = ['ec2_level1', 'ec2_level2', 'ec2_level3', 'ec2_level4']
	if batch_type in batch_set:
		print "Start install python on the VM: %s" % datetime.datetime.now()
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'yum -y install wget\''
		print cmd	
		func_call(cmd)
		
		python_item = db_search("python", linux_distro, hardware_platform, sw_conn_cursor) 
		python_url = python_item[3]
		#get the url of python
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'wget ' + python_url + '\''
		print cmd	
		func_call(cmd)
		
		scheme, netloc, path, query, fragment = urlparse.urlsplit(python_url)
		python_url_filename = os.path.basename(path)
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'tar zxvf ' + python_url_filename + '\''
		print cmd	 
		print "Finish install python on the VM: %s" % datetime.datetime.now()
		func_call(cmd)
	
	batch_set = ['ec2_level1', 'ec2_level2']
	#another way to do this is to add the os information into the json file
	if batch_type in batch_set:
		print "Start add os into json: %s" % datetime.datetime.now()
		outfile_name = 'merged_' + json_file	
		with open(outfile_name, "w") as outfile:
			with open(json_file) as json_data: #python 2.4 does not support this syntax: with open () as
				json_spec = json.load(json_data)
				json_spec_copy = json_spec
				dict1 = {'name': dist_name, 'version': dist_version, 'platform': hardware_platform, 'mountpoint': '/'}
				json_spec_copy["package"]['software-dependencies'][linux_distro] = dict1
			json.dump(json_spec_copy, outfile, indent = 4)
		json_file = outfile_name
		print "Finish add os into json: %s" % datetime.datetime.now()


	#scp layer_cake, cmssw.json, software.db to vm
	print "Start send layer_cake software.db json file: %s" % datetime.datetime.now()
	cmd = 'scp -i ' + ssh_key + ' layer_cake software.db ' + json_file + ' ' + user_name + '@' + public_dns + ':' 
	print cmd
	func_call(cmd)
	print "Finish send layer_cake software.db json file: %s" % datetime.datetime.now()

	print "Start Execution on the VM: %s" % datetime.datetime.now()
	python_dir = "python-%s-%s" % (hardware_platform, linux_distro) 
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'' + python_dir + '/bin/python layer_cake -c ' + json_file + ' -s specification -o output run "' + user_cmd[0] + '"\''
	print cmd	 
	func_call(cmd)
	print "Finish Execution on the VM: %s" % datetime.datetime.now()

	print "Start Post Processing: %s" % datetime.datetime.now()
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'tar czf output.tar.gz -C output stdout\''
	print cmd	 
	func_call(cmd)

	cmd = 'scp -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ':output.tar.gz .'
	print cmd	 
	func_call(cmd)

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)

	cmd = 'tar zxC ' + output_dir + ' -f output.tar.gz'
	print cmd	 
	func_call(cmd)
	print "Finish Post Processing: %s" % datetime.datetime.now()

def specification_process(json_package, package_dir, method, behavior, cmd, sw_conn_cursor, cloud_conn_cursor, batch_type, output_dir):
	if not os.path.exists(package_dir):
		os.makedirs(package_dir)
	#if batch_type is local, create the task.sh based on the user's requirements, download parrot, download SITEINFO, create a clean environment, do the experiment.
	#if batch_type is condor, create the task.sh based on the user's requirements, create condor submit file, submit condor job.
	if json_package.has_key("execution-environment") and json_package["execution-environment"]:
		execution_environment_check(json_package["execution-environment"], package_dir, batch_type)
	else:
		print "this spec has no execution-environment"

	if json_package.has_key("software-dependencies") and json_package["software-dependencies"]:
		software_dependencies_installation(json_package["software-dependencies"], sw_conn_cursor, package_dir, batch_type)
	else:
		print "this spec has no software-dependencies"

	workflow_repeat(package_dir, batch_type, output_dir)


def dependency_check(dependency_list):
	for item in dependency_list:
		print "dependency check -- ", item, " "
		p = subprocess.Popen("which " + item, stdout = subprocess.PIPE, shell = True)
		(output, err) = p.communicate()
		p_status = p.wait()
		if p_status != 0:
			sys.exit("command `which(" + item + ")` failed. Please install " + item + " and ensure its directory be added into the PATH environment varibale.\n")

def get_sandbox_id(path):
	i = 1
	while(os.path.exists(path + '/' + str(i))):
		i = i + 1
	return i

def get_instance_id(image_id):
	#cmd = 'ec2-run-instances ' + image_id + ' -t t1.micro -k my-key-pair -g sg-24f96141 --associate-public-ip-address true'
	cmd = 'ec2-run-instances ' + image_id + ' -t c3.large -k my-key-pair -g sg-24f96141 --associate-public-ip-address true'
	print cmd
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	p_status = p.wait()
	while True:
		line = p.stdout.readline()
		if line != '':
			line = line.rstrip()	
			if line[:8] == 'INSTANCE':
				instance_id = line[9:19]
				print instance_id
				return instance_id

def get_public_dns(instance_id):
	public_dns = ''
	while public_dns == None or public_dns == '' or public_dns == 'l':
		cmd = 'ec2-describe-instances ' + instance_id
		p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
		p_status = p.wait()
		while True:
			line = p.stdout.readline()
			if line != '':
				line = line.rstrip()	
				str1 = 'PRIVATEIPADDRESS' 
				if line[:16] == str1:
					index = line.find("ec2")
					public_dns = line[index:]
					#print public_dns
					break
	return public_dns

def main():
	#Problem: extension support incremental download
	parser = OptionParser(usage="usage: %prog [options] run \"command\"",
						version="%prog 1.0")
	parser.add_option("-c", "--config",
					action="store",
					default="./package.json",
					help="The specification json file")
	parser.add_option("-s", "--sandbox",
					action="store", # optional because action defaults to "store"
					default="./test",
					help="The path of sandbox",)
	parser.add_option("-o", "--output",
					action="store", # optional because action defaults to "store"
					default="./test",
					help="The path of output",)
	parser.add_option("-T", "--batch_type",
					action="store", # optional because action defaults to "store"
					default="local",
					help="Batch system type. One of: local, ec2, condor. (By default: local)",)
	parser.add_option("-m", "--method",
					action="store", # optional because action defaults to "store"
					default="parrot",
					help="Repeat method (chroot:require root account; parrot: does not require root account.)",)
	parser.add_option("--source",
					action="store", # optional because action defaults to "store"
					help="The specification source.",)
	parser.add_option("--target",
					action="store", # optional because action defaults to "store"
					help="The specification destination.",)
	(options, args) = parser.parse_args()

	print 'Number of arguments:', len(sys.argv), 'arguments.'
	print 'Argument List:', str(sys.argv)
	cmd = sys.argv[-1]

	behavior = args[0]
	if behavior not in ["run", "setup", "localize", "merge", "diff"]:
		print "Behaviors currently supported by spectool: run, setup, localize, merge, and diff.\n"

	output_dir = options.output
	output_dir = os.path.abspath(output_dir)

	if behavior in ["run", "setup", "localize", "merge"]:
		sandbox = options.sandbox
		sandbox = os.path.abspath(sandbox)
		global sandbox_no
		sandbox_no = get_sandbox_id(sandbox)
		package_dir = sandbox + '/' + str(sandbox_no)
		print package_dir
		method = options.method

		json_file = options.config
		if not os.path.isfile(json_file):
			print "The json file does not exists! Please check!!\n"
			sys.exit(0)
		with open(json_file) as json_data: #python 2.4 does not support this syntax: with open () as
			json_spec = json.load(json_data)
			package_spec = json_spec["package"]

	sw_conn = sqlite3.connect('software.db')
	sw_conn_cursor = sw_conn.cursor()

	cloud_conn = sqlite3.connect('ec2.db')
	cloud_conn_cursor = cloud_conn.cursor()
	batch_type = options.batch_type
#	print "batch_type:", batch_type

	global user_cmd
	user_cmd = args[1:]

	if behavior in ["run", "setup", "localize"]:
		dependency_list = []
		dependency_check(dependency_list)
		user_name = 'root'
		ssh_key = 'my-key-pair.pem'
		if batch_type == "ec2_level1":
			print "ec2_level 1 Start a ec2 VM: %s" % datetime.datetime.now()
			#ec2-run-instances ami-15166c25 -t t1.micro -k my-key-pair -g sg-24f96141 --associate-public-ip-address true
			#resolve the above result to get the instance id
			#ec2-describe-instances to get the public DNS of the instance id
			#instance_id = get_instance_id('ami-15166c25')
			instance_id = get_instance_id('ami-16aecc26')
			public_dns = get_public_dns(instance_id)
			print instance_id, public_dns
			print "ec2_level 1 finishing start a ec2 VM: %s" % datetime.datetime.now()
			#public_dns = "dns"
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)

		elif batch_type == "ec2_level2":
			#public_dns = 'ec2-54-68-43-227.us-west-2.compute.amazonaws.com'
			public_dns = 'ec2-54-68-203-165.us-west-2.compute.amazonaws.com'
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		elif batch_type == "ec2_level3":
			#ec2-run-instances ami-d76a29e7 -t t1.micro -k my-key-pair -g sg-24f96141 --associate-public-ip-address true
			#resolve the above result to get the instance id
			#ec2-describe-instances to get the public DNS of the instance id
			instance_id = get_instance_id('ami-d76a29e7')
			public_dns = get_public_dns(instance_id)
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		elif batch_type == "ec2_level4":
			#ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i my-key-pair.pem root@ec2-54-186-101-95.us-west-2.compute.amazonaws.com
			public_dns = 'ec2-54-187-212-35.us-west-2.compute.amazonaws.com'
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		elif batch_type == "ec2_level5":
			#ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i my-key-pair.pem root@ec2-54-186-101-95.us-west-2.compute.amazonaws.com
			public_dns = 'ec2-54-187-212-35.us-west-2.compute.amazonaws.com'
			ec2_process(package_spec, json_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type)
		else:
			specification_process(package_spec, package_dir, method, behavior, cmd, sw_conn_cursor, cloud_conn_cursor, batch_type, output_dir)

	if behavior == "localize":
		package_spec["package-location"] = package_dir
		new_json = "local.json"
		outfile_name = os.path.join(package_dir, new_json)
		with open(outfile_name, "w") as outfile:
			json.dump(json_spec, outfile, indent = 4)
		print "The localized version of the specification is: " + new_json + '\n'

	sw_conn.close()
	cloud_conn.close()

if __name__ == "__main__":
	main()

#set sts=4 sw=4 ts=4 expandtab ft=python
