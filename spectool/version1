#! /usr/bin/python2.7
import sys
from pprint import pprint
import subprocess
import platform
import tarfile
import StringIO
from optparse import OptionParser
import os
import hashlib
import difflib
import sqlite3
import shutil

env_file = ""	
common_mountfile = ""
special_files = ""
hardware_platform = ""
mount_dict = {}

if sys.version_info >= (3,):
	import urllib.request as urllib2
	import urllib.parse as urlparse
else:
	import urllib2
	import urlparse

if sys.version_info > (2,6,):
	import json
else:
	import simplejson as json #json module is introduce in python 2.4.3

def md5_cal(filename, block_size=2**20):
	try:
		with open(filename, 'rb') as f:
			md5 = hashlib.md5()
			while True:
				data = f.read(block_size)
				if not data:
					break
				md5.update(data)
			return md5.hexdigest()
	except:
		sys.exit("md5_cal(" + filename + ") failed.\n")

def url_check(url):
	try:
		f = urllib2.urlopen(urllib2.Request(url))
	except:
		print "url({0}) is broken.".format(url)
		return 1
	return 0

def download_func(url, checksum, checksum_tool, dest, format_remote_storage, package_dir, branch_name):
	dir_dest = os.path.dirname(dest)
	try:
		response = urllib2.urlopen(url)
		data = response.read()
	except URLerror as e:
		print "URLerror({0}): {1}".format(e.errno, e.strerror)
		sys.exit(0)
	scheme, netloc, path, query, fragment = urlparse.urlsplit(url)
	filename = os.path.basename(path)

	if format_remote_storage == "plain-text":
		dest = os.path.join(package_dir, dest)
		#with open(dest, "wb") as code: with open is not available in python 2.4.3
		with open(dest, "wb") as code:
			code.write(data)
		if checksum_tool == "md5sum":
			local_checksum = md5_cal(dest)
		else:
			sys.exit(checksum_tool + "is not supported currently!")
		if not local_checksum == checksum:
			print local_checksum, checksum
			sys.exit("the version of " + url + " is incorrect!\n")
	elif format_remote_storage == "tar":
		dest_dir = os.path.join(package_dir, dir_dest)
		dest = os.path.join(dest_dir, filename)
		if not os.path.exists(dest_dir):
			os.makedirs(dest_dir)
		with open(dest, "wb") as code:
			code.write(data)
		if checksum_tool == "md5sum":
			local_checksum = md5_cal(dest)
		else:
			sys.exit(checksum_tool + "is not supported currently!")
		if not local_checksum == checksum:
			print local_checksum, checksum
			sys.exit("the version of " + url + " is incorrect!\n")
		tfile = tarfile.open(dest, "r:")
		tfile.extractall(dest_dir)
		os.remove(dest)
		'''
		no checksum verification process
		dest = os.path.join(package_dir, dir_dest)
		compressedFile = StringIO.StringIO()
		compressedFile.write(data)
		compressedFile.seek(0)
		tfile = tarfile.open(mode="r:", fileobj = compressedFile);
		tfile.extractall(dest)
		'''
	elif format_remote_storage == "tgz":
		dest_dir = os.path.join(package_dir, dir_dest)
		dest = os.path.join(dest_dir, filename)
		if not os.path.exists(dest_dir):
			os.makedirs(dest_dir)
		with open(dest, "wb") as code:
			code.write(data)
		if checksum_tool == "md5sum":
			local_checksum = md5_cal(dest)
		else:
			sys.exit(checksum_tool + "is not supported currently!")
		if not local_checksum == checksum:
			print local_checksum, checksum
			sys.exit("the version of " + url + " is incorrect!\n")
		tfile = tarfile.open(dest, "r:gz")
		tfile.extractall(dest_dir)
		os.remove(dest)
		'''
		tfile = tarfile.open(mode="r:gz", fileobj = compressedFile);
		tfile.extractall(dest)
		'''
	elif format_remote_storage == "git":
		dest_dir = os.path.join(package_dir, dir_dest)
		if not os.path.exists(dest_dir):
			os.makedirs(dest_dir)
		os.chdir(dest_dir)
		subprocess.call("git clone -b " + branch_name + " " + url, shell = True)
		filename = filename[:-4]
		dest_path = os.path.join(package_dir, dest)
		if not os.path.exists(dest_path):
			subprocess.call("mv " + filename + " " + dest_path, shell = True)
		os.chdir(dest_path)
		subprocess.call("git checkout " + checksum, shell = True)
	else:
		sys.exit("this format is not supported currently!\n")

#Problem: this function needs extension: redirection of remote dependencies
def remote_dependencies_check(remote_dependencies, package_dir, behavior):
	print "remote dependencies checking ..."
	for item_1 in remote_dependencies:
		item = remote_dependencies[item_1]
		pprint(item)
		url = item["remote-storage-location"]
		if url_check(url) == 1:
			sys.exit(0)
		checksum = item["checksum"]
		checksum_tool = item["checksum-tool"]
		dest = item["location-in-package"]
		format_remote_storage = item["remote-storage-format"]
		if format_remote_storage == "git":
			branch_name = item["branch-name"]
		else:
			branch_name = ""
		download_func(url, checksum, checksum_tool, dest, format_remote_storage, package_dir, branch_name)

def download_dependency(url, checksum, checksum_tool, dest, format_remote_storage):
	print "entre into download_dependency"
	print url, checksum, checksum_tool, dest, format_remote_storage
	dir_dest = os.path.dirname(dest)
	old_dest = dest

	scheme, netloc, path, query, fragment = urlparse.urlsplit(url)
	filename = os.path.basename(path)
	dest = os.path.join(dir_dest, filename)

	if not os.path.exists(dir_dest):
		os.makedirs(dir_dest)

	if os.path.exists(dest):
		if checksum_tool == "md5sum":
			local_checksum = md5_cal(dest)
		else:
			sys.exit(checksum_tool + "is not supported currently!")
		if not local_checksum == checksum:
			os.remove(dest)
			if os.path.exists(old_dest):
				shutil.rmtree(old_dest)

	if not os.path.exists(dest):
		try:
			response = urllib2.urlopen(url)
			data = response.read()
		except URLerror as e:
			print "URLerror({0}): {1}".format(e.errno, e.strerror)
			sys.exit(0)
		with open(dest, "wb") as code:
			code.write(data)

	if checksum_tool == "md5sum":
		local_checksum = md5_cal(dest)
	else:
		sys.exit(checksum_tool + "is not supported currently!")

	if not local_checksum == checksum:
		print local_checksum, checksum
		sys.exit("the version of " + url + " is incorrect!\n")
	
	if not os.path.exists(old_dest):
		tfile = tarfile.open(dest, "r:gz")
		tfile.extractall(dir_dest)


def dependency_process(name, version, platform, distro, conn_cursor, package_dir, mountpoint):
	if distro == "":
		sql_cmd = 'SELECT * FROM sw_table where name = "' + name + '" and version = "' + version + '" and platform = "' + platform + '"'
	else:
		sql_cmd = 'SELECT * FROM sw_table where name = "' + name + '" and version = "' + version + '" and platform = "' + platform + '" and distro = "' + distro + '"' 
	conn_cursor.execute(sql_cmd)
	result = conn_cursor.fetchall()
	if len(result) == 0:
		sys.exit(sql_cmd + " fails!\n")
	for item in conn_cursor.execute(sql_cmd):
		pprint(item)
#table schema: (name text, version text, platform text, distro text, url text, checksum text)

	url = item[4]
	checksum = item[5]
	checksum_tool = "md5sum"
	dest = os.path.dirname(package_dir) + "/cache/" + item[0] + '-' + item[1] + '-' + item[2]
	global mount_dict
	if item[3] != '':
		dest = dest + '-' + item[3]
	else:
		global env_file
		global common_mountfile
		global special_files
		env_file = dest + "/env_list"
		common_mountfile = dest + "/common-mountlist"
		special_files = dest + "/special_files"
		print env_file, common_mountfile, special_files

	mount_dict[mountpoint] = dest
	format_remote_storage = "tgz"
	print name, version, platform, distro
	print url, checksum, checksum_tool, dest
	download_dependency(url, checksum, checksum_tool, dest, format_remote_storage)

#Problem: this function needs extension: check whether the VM satisfies the requirement; how to set the imperfect match range.
def execution_environment_check(execution_environment, conn_cursor, package_dir):
	print "Execution environment checking ..."
	print execution_environment["hardware-platform"]
	print execution_environment["os"]
	print execution_environment["kernel-release"]
	print execution_environment["distribution-version"]["dist-name"]
	print execution_environment["distribution-version"]["dist-version"]
	global hardware_platform
	hardware_platform = execution_environment["hardware-platform"]
	print "hardware_platform"
	print hardware_platform
	uname_list = platform.uname() #(system,node,release,version,machine,processor)
	for i in range(len(uname_list)):
		print uname_list[i]
	print ''
	#linux_dist = platform.linux_distribution() #(distname,version,id)
	linux_dist = platform.dist() #(distname,version,id) #platform.linux_distribution is not available in python 2.4.3
	for i in range(len(linux_dist)):
		print linux_dist[i]
	print ''

	if execution_environment["hardware-platform"].lower() != uname_list[4].lower():
		sys.exit("The specification requires " + execution_environment["hardware-platform"].lower() + ", but the machine is " + uname_list[4].lower() + "!\n")

	if execution_environment["os"].lower() != uname_list[0].lower():
		sys.exit("The specification requires " + execution_environment["os"].lower() + ", but the machine is " + uname_list[0].lower() + "!\n")

#	if execution_environment["kernel-release"].lower() != uname_list[2].lower():
#		sys.exit("The specification requires " + execution_environment["kernel-release"].lower() + ", but the machine is " + uname_list[2].lower() + "!\n")
#
#	if execution_environment["distribution-version"]["dist-name"].lower() != linux_dist[0].lower():
#		sys.exit("The specification requires " + execution_environment["distribution-version"]["dist-name"] + ", but the machine is " + linux_dist[0] + "!\n")
	dependency_process(execution_environment["distribution-version"]["dist-name"].lower(), execution_environment["distribution-version"]["dist-version"].lower(), execution_environment["hardware-platform"].lower(), '', conn_cursor, package_dir, "/")
	return [execution_environment["distribution-version"]["dist-name"].lower(), execution_environment["distribution-version"]["dist-version"].lower(), execution_environment["hardware-platform"].lower()]

def software_dependencies_installation(software_dependencies, conn_cursor, package_dir, os_info):
	print "Installing software dependencies ..."
	#pprint(software_dependencies)
	i = 1
#	index = os_info[1].find('.')
#	distro = os_info[0] + os_info[1][:index]
	for item in software_dependencies:
		#pprint(software_dependencies[item])
#		if (software_dependencies[item]).has_key("version"):
#			version = software_dependencies[item]['version']
#		else:
#			version = "any"
#		
#		if (software_dependencies[item]).has_key("distro"):
#			distro = software_dependencies[item]['distro']
#		else:
#			distro = ""
		name = software_dependencies[item]['name']
		version = software_dependencies[item]['version']
		platform = software_dependencies[item]['platform']
		distro = software_dependencies[item]['distro']
		mountpoint = software_dependencies[item]['mountpoint']
		dependency_process(name, version, platform, distro, conn_cursor, package_dir, mountpoint)
		i = i + 1

def package_combination(package_structure, package_dir, behavior):
	print "combining package ..."
	#pprint(package_structure)
	for item_1 in package_structure:
		item = package_structure[item_1]
		url = item["remote-storage-location"]
		format_package = item["format-in-package"]
		dest = item["location-in-package"]
		format_remote_storage = item["remote-storage-format"]
		checksum_tool = item["checksum-tool"]
		checksum = item["checksum"]
		download_func(url, checksum, checksum_tool, dest, format_remote_storage, package_dir, "")

def software_combination(software_dependencies, package_dir, behavior):
	print "combine software dependencies ..."
	#pprint(software_dependencies)
	for item in software_dependencies:
		url = item["remote-storage-location"]
		format_package = item["format-in-package"]
		dest = item["location-in-package"]
		format_remote_storage = item["remote-storage-format"]
		checksum_tool = item["checksum-tool"]
		checksum = item["checksum"]
		download_func(url, checksum, checksum_tool, dest, format_remote_storage, package_dir, "")

def dynamic_linker_path():
	if hardware_platform == "x86_64":
		return os.path.dirname(env_file) + "/lib64/ld-linux-x86-64.so.2"	
	else:
		return "undefined platform type"

def construct_mountfile(package_dir):
	print mount_dict
	mountfile = package_dir + "/mountlist"		
	new_root = mount_dict["/"]
	del mount_dict["/"]
	print mount_dict
	with open(mountfile, "wb") as file1:
		file1.write("/ " + new_root + "\n")	
		file1.write(new_root + " " + new_root + "\n")	
		for key in mount_dict:
			file1.write(key + " " + mount_dict[key] + "\n")
			file1.write(mount_dict[key] + " " + mount_dict[key] + "\n")
		print "common_mountfile"	
		print common_mountfile
		with open(common_mountfile, "rb") as file2:
			for line in file2:
				file1.write(line)
				print line
		print "special_files"
		print special_files
		with open(special_files, "rb") as file3:
			for line in file3:
				file1.write(line)
				print line
	return mountfile

def construct_env():
	print env_file
	with open(env_file, "rb") as file1:
		env_dict = {}
		for line in file1:
			index = line.find("=")
#			key = '"' + line[:index] + '"'
#			value = '"' + line[(index+1):-1] + '"'
			key = line[:index] 
			value = line[(index+1):-1] 
			env_dict[key] = value	
		return env_dict

def workflow_repeat(package_dir, method, behavior, cmd):
	#pprint(workflow)
	os.chdir(package_dir)
	if behavior == "run":

		print "**************************************************************************\n"
		print "You are currently work inside a sandbox.\n"
		print "after everything is done, run the command `exit` to exit.\n"
		print "**************************************************************************\n"

	if method == "parrot":
		if behavior == "run":
			try:
				#set environment variables dict, ld-linux path throught -l parameter of parrot_run, set mountlist through -m parameter of parrot_run
				dynamic_linker = dynamic_linker_path()
				print dynamic_linker
				mountfile = construct_mountfile(package_dir)
				print mountfile
				env_dict = construct_env()
				print env_dict
				parrot_cmd = "/home/hmeng/cctools/bin/parrot_run -m " + mountfile + " -l " + dynamic_linker + " " + "/bin/sh"
				print parrot_cmd
				subprocess.call(parrot_cmd, env = env_dict, shell = True)
			except:
				sys.exit("Repeat workflow failed.\n")
		elif behavior == "setup" or behavior == "localize":
			print "All the necessary preparations have finished! The repeat shell is: " + package_dir + "/repeat-workflow\n"
		else:
			pass
	else:
		if behavior == "run":
			try:
				subprocess.call("chroot_package_run -p " + package_dir + " -e " + env_list, shell = True)
			except:
				sys.exit("Repeat workflow failed.\n")
		elif behavior == "setup" or behavior == "localize":
			print "All the necessary preparations have finished! The repeat shell is: " + package_dir + "/repeat-workflow\n"
		else:
			pass

def compare_json(json_1, json_2, name_1, name_2):
	for item in json_1:
		if item not in json_2:
			print "Item %s in \"%s\", but not in \"%s\"" %(item, name_1, name_2)
			print "<<<<<<<<%s in %s:" %(item, name_1)
			pprint(json_1[item])
			print "\n"
		elif json_1[item] != json_2[item]:
			print "Item %s in both files, but values differ:" %item
			print "<<<<<<<<%s in %s:" %(item, name_1)
			pprint(json_1[item])
			print ">>>>>>>>%s in %s:" %(item, name_2)
			pprint(json_2[item])
			print "\n"
	for item in json_2:
		if item not in json_1:
			print "Item %s in \"%s\", but not in \"%s\"" %(item, name_2, name_1)
			print ">>>>>>>>%s in %s:" %(item, name_2)
			pprint(json_2[item])
			print "\n"

def specification_process(json_package, package_dir, method, behavior, cmd, conn_cursor):
	if not os.path.exists(package_dir):
		os.makedirs(package_dir)

	if json_package.has_key("execution-environment") and json_package["execution-environment"]:
		os_info = execution_environment_check(json_package["execution-environment"], conn_cursor, package_dir)
	else:
		print "this spec has no execution-environment"

	if json_package.has_key("software-dependencies") and json_package["software-dependencies"]:
		software_dependencies_installation(json_package["software-dependencies"], conn_cursor, package_dir, os_info)
	else:
		print "this spec has no software-dependencies"

#	if json_package.has_key("filesystem-structure") and json_package["filesystem-structure"]:
#		package_combination(json_package["filesystem-structure"], package_dir, behavior)
#	else:
#		print "this spec uses the root filesystem of the host directly."

	workflow_repeat(package_dir, method, behavior, cmd)

def dependency_check():
	dependency_list = ["parrot_run", "chroot_package_run"]
	for item in dependency_list:
		print "dependency check -- ", item, " "
		p = subprocess.Popen("which " + item, stdout = subprocess.PIPE, shell = True)
		(output, err) = p.communicate()
		p_status = p.wait()
		if p_status != 0:
			sys.exit("command `which(" + item + ")` failed. Please install " + item + " and ensure its directory be added into the PATH environment varibale.\n")

def get_sandbox_id(path):
	i = 1
	while(os.path.exists(path + '/' + str(i))):
		i = i + 1
	return i

def main():
	#Problem: extension support incremental download
	parser = OptionParser(usage="usage: %prog [options] run \"command\"",
						version="%prog 1.0")
	parser.add_option("-c", "--config",
					action="store",
					default="./package.json",
					help="The specification json file")
	parser.add_option("-s", "--sandbox",
					action="store", # optional because action defaults to "store"
					default="./test",
					help="The path of sandbox",)
	parser.add_option("-m", "--method",
					action="store", # optional because action defaults to "store"
					default="parrot",
					help="Repeat method (chroot:require root account; parrot: does not require root account.)",)
	parser.add_option("--source",
					action="store", # optional because action defaults to "store"
					help="The specification source.",)
	parser.add_option("--target",
					action="store", # optional because action defaults to "store"
					help="The specification destination.",)
	(options, args) = parser.parse_args()

	print 'Number of arguments:', len(sys.argv), 'arguments.'
	print 'Argument List:', str(sys.argv)
	cmd = sys.argv[-1]

	behavior = args[0]
	if behavior not in ["run", "setup", "localize", "merge", "diff"]:
		print "Behaviors currently supported by spectool: run, setup, localize, merge, and diff.\n"

	if behavior in ["run", "setup", "localize", "merge"]:
		sandbox = options.sandbox
		sandbox = os.path.abspath(sandbox)
		sandbox_no = get_sandbox_id(sandbox)
		package_dir = sandbox + '/' + str(sandbox_no)
		print package_dir
#		if os.path.exists(package_dir):
#			print "This sandbox already exists! Please choose another sandbox or first delete this sandbox!!\n"
#			sys.exit(0)
		method = options.method
		if method == "chroot" and os.getuid() != 0:
			print "chroot method needs root authority! Please first log in as the root account and then run the program again!!\n"
			sys.exit(0)
		if method != "chroot" and method != "parrot":
			print "spectool currently only support two methods: parrot and chroot.\n"
			sys.exit(0)
		json_file = options.config
		if not os.path.isfile(json_file):
			print "The json file does not exists! Please check!!\n"
			sys.exit(0)
		with open(json_file) as json_data: #python 2.4 does not support this syntax: with open () as
			json_spec = json.load(json_data)
			package_spec = json_spec["package"]

	conn = sqlite3.connect('software.db')
	conn_cursor = conn.cursor()


	if behavior in ["run", "setup", "localize"]:
		dependency_check()
		
		specification_process(package_spec, package_dir, method, behavior, cmd, conn_cursor)

	if behavior == "localize":
		package_spec["package-location"] = package_dir
		new_json = "local.json"
		outfile_name = os.path.join(package_dir, new_json)
		with open(outfile_name, "w") as outfile:
			json.dump(json_spec, outfile, indent = 4)
		print "The localized version of the specification is: " + new_json + '\n'

	if behavior == "diff":
		if len(args) != 3:
			parser.error("wrong number of arguments! The diff behavior needs two specification files.")
		with open(args[1]) as json1_data:
			json1 = json.load(json1_data)
		with open(args[2]) as json2_data:
			json2 = json.load(json2_data)
		compare_json(json1["package"]["remote-dependencies"], json2["package"]["remote-dependencies"], args[1], args[2])
		compare_json(json1["package"]["execution-environment"], json2["package"]["execution-environment"], args[1], args[2])
		compare_json(json1["package"]["filesystem-structure"], json2["package"]["filesystem-structure"], args[1], args[2])
		compare_json(json1["package"]["software-dependencies"], json2["package"]["software-dependencies"], args[1], args[2])
		compare_json(json1["package"]["workflow"], json2["package"]["workflow"], args[1], args[2])

	if behavior == "merge":
		if package_spec.has_key("basic-specification") and os.path.exists(package_spec["basic-specification"]):
			basic_json_filename = package_spec["basic-specification"]
			print "The specification has a basic specification:" + basic_json_filename
			with open(basic_json_filename) as basic_json:
				basic_spec = json.load(basic_json)
			basic_package = basic_spec["package"]
		else:
			print "The basic specification does not exist"
			sys.exit(0)
		if basic_package.has_key("package-location") and os.path.isdir(basic_package["package-location"]):
			print "the target is a localized version"
		else:
			print "the target does not exist"
			specification_process(basic_package, package_dir, method, behavior)
		specification_process(package_spec, package_dir, method, behavior, cmd)
	
	conn.close()

if __name__ == "__main__":
	main()

#set sts=4 sw=4 ts=4 expandtab ft=python
