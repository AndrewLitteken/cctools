#!/usr/bin/python
'''
Copyright (C) 2003-2004 Douglas Thain and the University of Wisconsin
Copyright (C) 2005- The University of Notre Dame
This software is distributed under the GNU General Public License.
See the file COPYING for details.
'''
import sys
from stat import *
from pprint import pprint
import subprocess
import platform
import re
import tarfile
import StringIO
from optparse import OptionParser
import os
import hashlib
import difflib
import sqlite3
import shutil
import datetime
import time
import getpass
import grp

Is_CVMFS_Parrot_App = 0

#If the current user name and group can not be found in /etc/passwd and /etc/group, a fake passwd and group file will be constructed.
Need_Fake_Passwd_File = 0
Need_Fake_Group_File = 0

Has_Parrot_Localfile = 0
Need_Separate_Rootfs = 0 #whether a separate OS image is needed.

Sandbox_ID = 0

#the following three files locate under each seprate OS image
Env_File_Path = "" #includes all the environment variables	
Common_Mountfile_Path = "" #includes all the common mountpoint (/proc, /dev, /sys, /mnt, /disc, /selinux)
Special_File_Path = "" #the path of the file which includes all the file paths of special types (block, character, socket, pipe)

Host_Linux_Distro = '' #the linux distribution info of the host machine

#the following five items comes from the specification file
Hardware_Platform = ""
Kernel_Type = "" #Options: linux, windows or Mac.
Linux_Distro = '' #linux distribution info specified in the specification file.
Distro_Name = ''
Distro_Version = ''

Mount_Dict = {}

Parrot_Submit_Path = ""
Parrot_Submit_File = ""
Parrot_Task_Path = ""
Parrot_Task_File = ""

Condor_Submit_Path = ""
Condor_Submit_File = ""

CWD_Setting = ""
User_Cmd = ""
Host_CCTOOLS_Path = "" #the path of the cctools binary which is compatible with the host machine under the umbrella cache 

if sys.version_info >= (3,):
	import urllib.request as urllib2
	import urllib.parse as urlparse
else:
	import urllib2
	import urlparse

if sys.version_info > (2,6,):
	import json
else:
	import simplejson as json #json module is introduce in python 2.4.3

""" Execute a command and return the standard output.
Parameter cmd: the command needs to execute using the subprocess module
Return: the output of the execution.
"""
def func_call(cmd):
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()
	return output

def func_call_output(cmd, output_dir):
	output = func_call(cmd)
	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/stdout"
	with open(stdout, 'w+') as file1:
		file1.write(output)
	
def func_call_output_withenv(cmd, env_dict, output_dir):
	p = subprocess.Popen(cmd, env = env_dict, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()
	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/stdout"
	with open(stdout, 'w+') as file1:
		file1.write(output)

""" Calculate the md5sum of a file
Parameter filename: the name of the file 
Parameter block_size: the size of each block
Return: the md5 value of the content of the file
"""
def md5_cal(filename, block_size=2**20):
	try:
		with open(filename, 'rb') as f:
			md5 = hashlib.md5()
			while True:
				data = f.read(block_size)
				if not data:
					break
				md5.update(data)
			return md5.hexdigest()
	except:
		sys.exit("md5_cal(" + filename + ") failed.\n")

""" Check whether a url is broken or not.
Parameter url: a url
Return: if the url is broken, return 1; otherwise, return 0.
"""
def url_check(url):
	try:
		f = urllib2.urlopen(urllib2.Request(url))
	except:
		print "url({0}) is broken.".format(url)
		return 1
	return 0

""" Download each dependency from the url and verify its integrity.
Parameter url: the storage location of the dependency
Parameter checksum: the checksum of the dependency
Parameter checksum_tool: the tool used to calculate the checksum, such as md5sum.
Parameter dest: the destination of the dependency where the downloaded dependency will be put
Parameter format_remote_storage: the file format of the dependency, such as .tgz.
"""
def dependency_download(url, checksum, checksum_tool, dest, format_remote_storage):
	print "Download software from %s into the dir (%s)" % (url, dest)
	dest_dir = os.path.dirname(dest)
	dest_uncompress = dest #dest_uncompress is the path of the uncompressed-version dependency

	scheme, netloc, path, query, fragment = urlparse.urlsplit(url)
	filename = os.path.basename(path)
	dest = os.path.join(dest_dir, filename) #dest is the path of the compressed-version dependency

	if not os.path.exists(dest_dir):
		os.makedirs(dest_dir)

	if not os.path.exists(dest):
		#download the dependency from the url
		#this method currently will fail when the data size is larger than the memory size, use subprocess + wget can solve it
		try:
			response = urllib2.urlopen(url)
			data = response.read()
		except urllib2.URLerror as e:
			sys.exit("URLerror({0}): {1}".format(e.errno, e.strerror))
		with open(dest, "wb") as code:
			code.write(data)
		#if it exists, the uncompressed-version directory will be deleted first
		if os.path.exists(dest_uncompress):
			shutil.rmtree(dest_uncompress)

	#calculate the checkusm of the compressed-version dependency
	if checksum_tool == "md5sum":
		local_checksum = md5_cal(dest)
	else:
		sys.exit(checksum_tool + "is not supported currently!")

	if not local_checksum == checksum:
		sys.exit("the version of " + url + " is incorrect!\n")
	
	#if the uncompressed-version dependency does not exist, uncompress the dependency
	if not os.path.exists(dest_uncompress):
		tfile = tarfile.open(dest, "r:gz")
		tfile.extractall(dest_dir)

def cctools_download(sandbox_dir, sw_conn_cursor):
	cctools_item = db_search("cctools", Host_Linux_Distro, Hardware_Platform, sw_conn_cursor) 
	dest = os.path.dirname(sandbox_dir) + "/cache/cctools-" + Hardware_Platform + "-" + Host_Linux_Distro
	name = "cctools"
	print "dependency_process(%s) start: %s" % (name, datetime.datetime.now())
	dependency_download(cctools_item[3], cctools_item[6], "md5sum", dest, "tgz")
	print "dependency_process(%s) end: %s" % (name, datetime.datetime.now())
	return dest

#the db table itself does not understand the collaberation relationship between cvmfs, parrot, SITECONF
def cvmfs_software(item, sw_conn_cursor, sandbox_dir, batch_type):
	global Is_CVMFS_Parrot_App 
	Is_CVMFS_Parrot_App = 1
	#construct the parrot submit script
	Parrot_Submit_File.write("#!/bin/sh\n")
	Parrot_Submit_File.write("export HTTP_PROXY=http://cache01.hep.wisc.edu:3128\n")
	cctools_download(sandbox_dir, sw_conn_cursor)
	cvmfs_repo = item[3][6:]
	if cvmfs_repo == "cms.cern.ch":
		Parrot_Task_File.write('#!/bin/sh\n')
		Parrot_Task_File.write('rm -rf ${CMS_VERSION}\n\n')
		Parrot_Task_File.write('. /cvmfs/cms.cern.ch/cmsset_default.sh\n')
		Parrot_Task_File.write('scramv1 project CMSSW ${CMS_VERSION}\n')
		Parrot_Task_File.write('cd ${CMS_VERSION}\n')
		Parrot_Task_File.write('eval `scram runtime -sh`\n')
		Parrot_Task_File.write('cd ..\n')
		Parrot_Task_File.write('cd ' + CWD_Setting + '; ' + User_Cmd[0] + '\n')

		Parrot_Submit_File.write("export CMS_VERSION=" + item[1] + "\n")
		Parrot_Submit_File.write("export SCRAM_ARCH=" + item[2] + "\n")

		#download SITECONF
		site_item = db_search("cms-siteconf-local-cvmfs", "", "", sw_conn_cursor)
		dest = os.path.dirname(sandbox_dir) + "/cache/cvmfs/cms.cern.ch/SITECONF"
		dependency_download(site_item[3], site_item[6], "md5sum", dest, "tgz")
		parrot_dest = "%s/cache/cctools-%s-%s/bin/parrot_run" % (os.path.dirname(sandbox_dir), Hardware_Platform, Host_Linux_Distro)
		#Parrot_Submit_File.write('env; ' + parrot_dest + " -d all -o log -M /cvmfs/cms.cern.ch/SITECONF/local=" + dest + "/local /bin/sh " + sandbox_dir + "/task.sh\n" )
		Parrot_Submit_File.write('env; ' + parrot_dest + " -M /cvmfs/cms.cern.ch/SITECONF/local=" + dest + "/local /bin/sh " + sandbox_dir + "/task.sh\n" )

		global Has_Parrot_Localfile
		Has_Parrot_Localfile = 1

""" Search a software given the name, version, platform information
"""
def db_search(name, version, platform, db_conn_cursor):
	sql_cmd = 'SELECT * FROM sw_table where name = "' + name + '" and version = "' + version + '" and platform = "' + platform + '"'
	db_conn_cursor.execute(sql_cmd)
	result = db_conn_cursor.fetchall()
	if len(result) == 0:
		sys.exit(sql_cmd + " fails!\n")
	#if multiple items satisfy the requirements, the first one will be used.
	item = result[0]
	return item

def dependency_process(name, version, platform, mountpoint, sw_conn_cursor, sandbox_dir, batch_type):
	item = db_search(name, version, platform, sw_conn_cursor)
	#table schema: (name text, version text, platform text, store text, store_type text, type text)
	store = item[3] 
	global Mount_Dict 
	if store[0:5] == "cvmfs":
		cvmfs_software(item, sw_conn_cursor, sandbox_dir, batch_type)	
		Mount_Dict[mountpoint] = mountpoint
	else:
		if item[5] == 'os':
			dest = os.path.dirname(sandbox_dir) + "/cache/" + item[0] + '-' + item[1] + '-' + item[2]
			global Env_File_Path
			global Common_Mountfile_Path
			global Special_File_Path
			global Need_Separate_Rootfs
			Env_File_Path = dest + "/env_list"
			Common_Mountfile_Path = dest + "/common-mountlist"
			Special_File_Path = dest + "/special_files"
			Need_Separate_Rootfs = 1
		else:
			dest = os.path.dirname(sandbox_dir) + "/cache/" + item[0] + '-' + item[2] + '-' + item[1]
		dependency_download(store, item[6], "md5sum", dest, "tgz")
		Mount_Dict[mountpoint] = dest
	
''' Set the global environment parameters according to the specification file
'''	
def env_parameter_init(hardware_spec, kernel_spec, os_spec):
	global Hardware_Platform
	global Kernel_Type
	global Distro_Name
	global Distro_Version
	global Linux_Distro
	Hardware_Platform = hardware_spec["platform"].lower()
	Kernel_Type = kernel_spec["type"].lower()
	Distro_Name = os_spec["name"].lower()
	Distro_Version = os_spec["version"].lower()
	index = Distro_Version.find('.')
	Linux_Distro = Distro_Name + Distro_Version[:index]

def env_check(sandbox_dir, batch_type):
	print "Execution environment checking ..."
	
	if batch_type != "docker" and batch_type != "chroot" and batch_type != "local":
		sys.exit("Currently local execution engine only support three sandbox techniques: docker, chroot or local!\n")

	global Parrot_Task_Path
	global Parrot_Submit_Path
	global Parrot_Task_File
	global Parrot_Submit_File
	Parrot_Task_Path = sandbox_dir + "/task.sh"
	Parrot_Submit_Path = sandbox_dir + "/local.sh"
	Parrot_Task_File = open(Parrot_Task_Path, "wb")
	Parrot_Submit_File = open(Parrot_Submit_Path, "wb")

	uname_list = platform.uname() #format of uname_list: (system,node,release,version,machine,processor)
#	for i in range(len(uname_list)):
#		print uname_list[i],
#	print ''
	
	dist_list = platform.dist()
	print "The hardware information of the local machine:", dist_list
	global Host_Linux_Distro
	arch_index = uname_list[2].find('ARCH')
	if arch_index != -1:
		Host_Linux_Distro = 'arch'		
	redhat_index = uname_list[2].find('el')
	centos_index = uname_list[2].find('centos')
	if redhat_index != -1:
		dist_version = uname_list[2][redhat_index + 2]
		if centos_index != -1 or dist_list[0].lower() == 'centos':
			Host_Linux_Distro = 'centos' + dist_version
		else:
			Host_Linux_Distro = 'redhat' + dist_version		
	print "The OS distribution information of the local machine:", Host_Linux_Distro

	if Hardware_Platform != uname_list[4].lower():
		sys.exit("The specification requires " + Hardware_Platform + ", but the local machine is " + uname_list[4].lower() + "!\n")

	if Kernel_Type != uname_list[0].lower():
		sys.exit("The specification requires " + Kernel_Type + ", but the local machine is " + uname_list[0].lower() + "!\n")

""" Installation each software dependency specified in the software section of the specification
Parameter software_spec: the software section of the specification
Parameter sw_conn_cursor: the cursor of the connection to software.db
Parameter sandbox_dir: the sandbox directory
Parameter batch_type: the batch type
"""
def software_install(software_spec, sw_conn_cursor, sandbox_dir, batch_type):
	print "Installing software dependencies ..."
	i = 1
	for item in software_spec:
		name = software_spec[item]['name']
		version = software_spec[item]['version']
		platform = software_spec[item]['platform']
		mountpoint = software_spec[item]['mountpoint']
		print "dependency_process(%s) start: %s" % (name, datetime.datetime.now())
		dependency_process(name, version, platform, mountpoint, sw_conn_cursor, sandbox_dir, batch_type)
		print "dependency_process(%s) end: %s" % (name, datetime.datetime.now())
		i = i + 1

	#if the OS distribution does not match, add the OS image into the dependency list of the application and download it into the local machine
	if Linux_Distro != Host_Linux_Distro:
		print "The required linux distro specified in the specification is %s; the linux distro of the host machine is %s. The %s os images will be downloaded." % (Linux_Distro, Host_Linux_Distro, Linux_Distro)
		name = Distro_Name
		version = Distro_Version 
		mountpoint = '/'	
		print "dependency_process(%s) start: %s" % (name, datetime.datetime.now())
		dependency_process(name, version, Hardware_Platform, mountpoint, sw_conn_cursor, sandbox_dir, batch_type)
		print "dependency_process(%s) end: %s" % (name, datetime.datetime.now())

	#if the batch_type is local, add cctools into the dependency list to guarantee parrot can be used to create sandbox for the worst case (No root access authority and no docker).
	if batch_type == "local":
		global Host_CCTOOLS_Path
		Host_CCTOOLS_Path = cctools_download(sandbox_dir, sw_conn_cursor)

""" Return the path of ld-linux.so within the downloaded os image dependency
"""
def get_linker_path():
	#Env_File_Path is directly under the directory of the downloaded os image dependency
	if Hardware_Platform == "x86_64":
		return os.path.dirname(Env_File_Path) + "/lib64/ld-linux-x86-64.so.2"	
	else:
		return "undefined platform type"

""" Construct the docker volume parameters based on Mount_Dict 
"""
def construct_docker_volume(sandbox_dir, input_dict):
	del Mount_Dict["/"] #remove "/" from the Mount_Dict to avoid messing the root directory of the host machine
	volume_paras = ""
	if Is_CVMFS_Parrot_App == 1:
		cvmfs_data_path = os.path.dirname(sandbox_dir) + '/cache/cvmfs/cms.cern.ch/SITECONF/local'
		Mount_Dict[cvmfs_data_path] = '/cvmfs/cms.cern.ch/SITECONF/local'
	for key in Mount_Dict:
		volume_paras = volume_paras + " -v " + Mount_Dict[key] + ":" + key + " "

	for key in input_dict:
		volume_paras = volume_paras + " -v " + input_dict[key] + ":" + key + " "

	return volume_paras

""" Get the path environment variable from envfile and add the mountpoints of software dependencies into it
"""
def obtain_path():
	with open(Env_File_Path, "rb") as f:
		path_env = ''	
		for line in f:
			if line[:5] == 'PATH=':
				path_env = line[5:-1]
				break
	for key in Mount_Dict:
		path_env = key + "/bin:" + path_env 
	return path_env

def transfer_env_para_docker(env_para_dict):
	other_envs = ''
	for key in env_para_dict:
		if key:
			other_envs = other_envs + ' -e "' + key + '=' + env_para_dict[key] + '" '
	return other_envs

""" Construct the path environment from the mountpoints of software dependencies for the case where a separate rootfs needs to be constrcuted
"""
def collect_software_bin():
	extra_path = ""
	print "collect_software_bin(): Mount_Dict: ", Mount_Dict 
	for key in Mount_Dict:
		if key != '/':
			extra_path += '%s/bin:' % key
	if Host_CCTOOLS_Path != "":
		extra_path += '%s/bin:' % Host_CCTOOLS_Path 
	return extra_path

""" Judge whether a user exists in /etc/passwd
"""
def In_local_passwd():
	user_name = getpass.getuser()
	with open('/etc/passwd') as f:
		for line in f:
			if line[:len(user_name)] == user_name:
				print "%s is included in /etc/passwd!" % user_name
				return 'yes'
	return 'no'

""" Judge whether a group exists in /etc/group
"""
def In_local_group():
	group_name = grp.getgrgid(os.getgid())[0]
	with open('/etc/group') as f:
		for line in f:
			if line[:len(group_name)] == group_name:
				print "%s is included in /etc/group!" % group_name
				return 'yes'
	return 'no'

""" Create the mountfile if parrot is used to create a sandbox for the application
Return the path of the mountfile
"""
def construct_mountfile(sandbox_dir, input_dict):
	mountfile_path = sandbox_dir + "/mountlist"		
	with open(mountfile_path, "wb") as mountfile:
		new_root = Mount_Dict["/"]
		mountfile.write("/ " + new_root + "\n")	
		del Mount_Dict["/"]
		mountfile.write(new_root + " " + new_root + "\n")	
		for key in Mount_Dict:
			mountfile.write(key + " " + Mount_Dict[key] + "\n")
			mountfile.write(Mount_Dict[key] + " " + Mount_Dict[key] + "\n")

		with open(Common_Mountfile_Path, "rb") as f:
			for line in f:
				mountfile.write(line)
		mountfile.write(sandbox_dir + ' ' + sandbox_dir + '\n')
		mountfile.write('/etc/hosts /etc/hosts\n')
		mountfile.write('/etc/resolv.conf /etc/resolv.conf\n')
		#nd workstation uses NSCD (Name Service Cache Daemon) to deal with passwd, group, hosts services. Here first check whether the current uid and gid is in the /etc/passwd and /etc/group, if yes, use them. Otherwise, construct separate passwd and group files.
		existed_user = In_local_passwd()
		if existed_user == 'yes':
			mountfile.write('/etc/passwd /etc/passwd\n')
		else:
			print 'the user is not included in the /etc/passwd!'
			with open('.passwd', 'w+') as f:
				f.write('%s:x:%d:%d:unknown:%s:%s\n' % (getpass.getuser(), os.getuid(), os.getgid(), sandbox_dir + '/' + getpass.getuser(), os.environ['SHELL']))
			mountfile.write('/etc/passwd %s/.passwd\n' % (sandbox_dir))

			with open('.__acl', 'w+') as acl_file:
				acl_file.write('%s rwlax\n' % getpass.getuser())

			#getpass.getuser() returns the login name of the user
			os.makedirs(getpass.getuser())

			global Need_Fake_Passwd_File
			Need_Fake_Passwd_File = 1

		existed_group = In_local_group()
		if existed_group == 'yes':
			mountfile.write('/etc/group /etc/group\n')
		else:
			print 'the group is not included in the /etc/group!'
			with open('.group', 'w+') as f:
				f.write('%s:x:%d:%d\n' % (grp.getgrgid(os.getgid())[0], os.getgid(), os.getuid()))
			mountfile.write('/etc/group %s/.group\n' % (sandbox_dir))

			global Need_Fake_Group_File
			Need_Fake_Group_File = 1
	
		#add /var/run/nscd/socket into mountlist
		mountfile.write('/var/run/nscd/socket ENOENT\n')
		mountfile.write('/tmp /tmp\n')
		dest = "%s/cache/cctools-%s-%s/bin" % (os.path.dirname(sandbox_dir), Hardware_Platform, Host_Linux_Distro)
		mountfile.write(dest + ' ' + dest + '\n')

		with open(Special_File_Path, "rb") as f:
			for line in f:
				mountfile.write(line)

		#add the input_dict into mountflie 
		for key in input_dict:
			mountfile.write(key + " " + input_dict[key] + "\n")

	return mountfile_path

""" Add the input files into the mountfile
"""
def add_inputs_to_mountfile(sandbox_dir, input_dict):
	mountfile_path = sandbox_dir + "/mountlist"		
	with open(mountfile_path, "wb") as f:
		#add the input_dict into mountflie 
		for key in input_dict:
			f.write(key + " " + input_dict[key] + "\n")
		for key in Mount_Dict:
			f.write(key + " " + Mount_Dict[key] + "\n")
			f.write(Mount_Dict[key] + " " + Mount_Dict[key] + "\n")
	return mountfile_path

""" Read Env_File_Path and save all the environment variables into a dictionary
Return: a dictionary which includes all the environment variables from Env_File_Path
"""
def construct_env(sandbox_dir):
	with open(Env_File_Path, "rb") as f:
		env_dict = {}
		for line in f:
			index = line.find("=")
			key = line[:index] 
			value = line[(index+1):-1] 
			env_dict[key] = value	
		env_dict['PWD'] = sandbox_dir
		return env_dict

""" Check whether a docker images exists on the local machine or not.
"""
def has_docker_image():
	name = "%s-%s-%s" %(Distro_Name, Distro_Version, Hardware_Platform)
	cmd = 'docker images ' + name
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	p_status = p.wait()
	while True:
		line = p.stdout.readline()
		if line != '':
			line = line.rstrip()	
			if line[:len(name)] == name:
				return 'yes'
		else:
			return 'no'

""" Create a docker image based on the cached os image directory
"""
def create_docker_image(sandbox_dir):
	name = "%s-%s-%s" %(Distro_Name, Distro_Version, Hardware_Platform)
	location = os.path.dirname(sandbox_dir) + '/cache/' + name
	#docker container runs as root user, so use the owner option of tar command to set the owner of the docker image
	cmd = 'cd ' + location + '; tar --owner=root -c .|docker import - ' + name + '; cd -'
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	p_status = p.wait()

""" Construct directory mount list and file mount list for chroot. chroot requires the target mountpoint must be created within the chroot jail.
Return: a tuple includes the directory mount list and the file mount list
"""
def construct_chroot_mount_dict(sandbox_dir, output_dir, input_dict, need_separate_rootfs):
	dir_dirct = {}
	file_dict = {}
	if need_separate_rootfs == 1:
		with open(Common_Mountfile_Path) as f:
			for line in f:
				index = line.find(' ')
				item = line[:index]
				dir_dirct[item] = item	
	
		with open(Special_File_Path) as f:
			for line in f:
				index = line.find(' ')
				item = line[:index]
				if os.path.exists(item):
					file_dict[item] = item	
	
	if Is_CVMFS_Parrot_App == 1:
		cctools_path = os.path.dirname(sandbox_dir) + '/cache/cctools-x86_64-' + Host_Linux_Distro 
		dir_dirct[cctools_path] = cctools_path
		
	dir_dirct[sandbox_dir] = sandbox_dir
	dir_dirct[output_dir] = output_dir 
	for key in Mount_Dict:
		if key != '/':
			dir_dirct[Mount_Dict[key]] = key

	file_dict['/etc/passwd'] = '/etc/passwd'
	file_dict['/etc/group'] = '/etc/group'
	file_dict['/etc/hosts'] = '/etc/hosts'
	file_dict['/etc/resolv.conf'] = '/etc/resolv.conf'

	for key in input_dict:
		value = input_dict[key]
		mode = os.lstat(value).st_mode
		if S_ISDIR(mode):
			dir_dirct[value] = key
		else:
			file_dict[value] = key

	return (dir_dirct, file_dict)

""" Create each target mountpoint under the cached os image directory, `mount --bind`
"""
def chroot_mount_bind(dir_dirct, file_dict, sandbox_dir, need_separate_rootfs):
	if need_separate_rootfs == 1:
		os_image_name = "%s-%s-%s" %(Distro_Name, Distro_Version, Hardware_Platform)
		os_image_path = os.path.dirname(sandbox_dir) + '/cache/' + os_image_name
	else:
		os_image_path = '/'
	#mount --bind -o ro hostdir sandboxdir
	for key in dir_dirct:
		if key == '/cvmfs/cms.cern.ch':
			jaildir = '%s%s/cache/cvmfs/cms.cern.ch/SITECONF/local' % (os_image_path, os.path.dirname(sandbox_dir))
			hostdir = '%s/cache/cvmfs/cms.cern.ch/SITECONF/local' % (os.path.dirname(sandbox_dir))
		else:	
			jaildir = '%s%s' % (os_image_path, dir_dirct[key]) 
			hostdir = key
		if not os.path.exists(jaildir):
			os.makedirs(jaildir)
		cmd = 'mount --bind -o ro %s %s' % (hostdir, jaildir)
		print cmd
		func_call(cmd)

	for key in file_dict:
		jailfile = '%s%s' % (os_image_path, file_dict[key]) 
		hostfile = key
		if not os.path.exists(jailfile):
			d = os.path.dirname(jailfile)
			if not os.path.exists(d):
				os.makedirs(d)
			with open(jailfile, 'w+') as f:
				pass
		cmd = 'mount --bind -o ro %s %s' % (hostfile, jailfile)
		print cmd
		func_call(cmd)

""" Remove all the created target mountpoints within the cached os image directory
It is not necessary to change the mode of the output dir, because only the root user can use the chroot method.
"""
def chroot_post_process(dir_dirct, file_dict, sandbox_dir, need_separate_rootfs):
	if need_separate_rootfs == 1:
		os_image_name = "%s-%s-%s" %(Distro_Name, Distro_Version, Hardware_Platform)
		os_image_path = os.path.dirname(sandbox_dir) + '/cache/' + os_image_name
	else:
		os_image_path = '/'
	print "chroot_post_process"
	print "dir_dirct:", dir_dirct
	print "file_dict:", file_dict 

	#file_dict must be processed ahead of dir_dirct, because we can not umount a directory if there is another mountpoints created for files under it.
	for key in file_dict:
		jailfile = '%s%s' % (os_image_path, file_dict[key]) 
		if os.path.exists(jailfile):
			cmd = 'umount -f %s' % (jailfile)
			print cmd
			func_call(cmd)

	for key in dir_dirct:
		if key == '/cvmfs/cms.cern.ch':
			jaildir = '%s%s/cache/cvmfs/cms.cern.ch/SITECONF/local' % (os_image_path, os.path.dirname(sandbox_dir))
		else:	
			jaildir = '%s%s' % (os_image_path, dir_dirct[key]) 
		if os.path.exists(jaildir):
			cmd = 'umount -f %s' % (jaildir)
			print cmd
			func_call(cmd)
			#remove all the empty ancestor directory
			parent_dir = jaildir
			mode = os.lstat(parent_dir).st_mode
			if S_ISDIR(mode):
				while len(os.listdir(parent_dir)) == 0:
					os.rmdir(parent_dir)
					parent_dir = os.path.dirname(parent_dir)

""" Run user task directory on the host's rootfs
"""
def execute_task_host_rootfs(sandbox_dir, env_dict, batch_type):
	Parrot_Task_File.close()
	Parrot_Submit_File.close()
	#need to construct the local.sh
	if Is_CVMFS_Parrot_App == 1:
		cmd = "/bin/sh " + sandbox_dir + "/local.sh"
		func_call_output_withenv(cmd, env_dict, sandbox_dir)
		print "%s is done " % cmd
	else:
		if batch_type == 'local':
			cmd = "parrot_run " + User_Cmd[0]
		elif batch_type == 'chroot':
			cmd = 'chroot / /bin/sh -c "cd %s; %s"' %(sandbox_dir, User_Cmd[0]) 
		print "cmd:", cmd
		func_call_output_withenv(cmd, env_dict, sandbox_dir)


""" Run user's task with the help of the sandbox techniques, which currently inculde chroot, parrot, docker.
"""
def workflow_repeat(sandbox_dir, batch_type, output_dir, sw_conn_cursor, input_dict, env_para_dict):
	#sandbox_dir will be the home directory of the sandbox
	os.chdir(sandbox_dir)
	#at this point, all the software should be under the cache dir, all the mountpoint of the software should be in Mount_Dict 
	if batch_type == "chroot":
		print "chroot ******"
		if Need_Separate_Rootfs == 1:
			#traverse the common-mountlist file to create the mountpoint and mount --bind -o ro
			#traverse the special file to create the mountpoint and mount --bind
			#remount /etc/passwd /etc/group /etc/hosts /etc/resolv.conf
			print "local-chroot rootfs construct and env setting start: %s" % datetime.datetime.now()
			(dir_dirct, file_dict) = construct_chroot_mount_dict(sandbox_dir, output_dir, input_dict, 1)
			chroot_mount_bind(dir_dirct, file_dict, sandbox_dir, 1)
			#redirect outputdir
			env_dict = construct_env(sandbox_dir)
			extra_path = collect_software_bin()
			env_dict['PATH'] = '%s:%s' % (env_dict['PATH'], extra_path[:-1])
			for key in env_para_dict:
				env_dict[key] = env_para_dict[key]
			print "local-chroot rootfs construct and env setting end: %s" % datetime.datetime.now()

			#run User_Cmd
			os_image_name = "%s-%s-%s" %(Distro_Name, Distro_Version, Hardware_Platform)
			os_image_path = os.path.dirname(sandbox_dir) + '/cache/' + os_image_name
			if Is_CVMFS_Parrot_App == 1:
				Parrot_Task_File.close()
				Parrot_Submit_File.close()
				sub_cmd = "/bin/sh " + sandbox_dir + "/local.sh"
				cmd = 'env; strace -o strace.log chroot %s /bin/sh -c "cd %s; %s"' % (os_image_path, sandbox_dir, User_Cmd[0])
			else:
				cmd = 'chroot %s /bin/sh -c "cd %s; %s"' % (os_image_path, sandbox_dir, User_Cmd[0])
			func_call_output_withenv(cmd, env_dict, sandbox_dir)
			print "local-chroot User_Cmd execute end: %s" % datetime.datetime.now()
			
			#post-process to clean up
			chroot_post_process(dir_dirct, file_dict, sandbox_dir, 1)
			print "local-chroot post processing end: %s" % datetime.datetime.now()
		else:
			print "chroot does not seprate rootfs"
			(dir_dirct, file_dict) = construct_chroot_mount_dict(sandbox_dir, output_dir, input_dict, 0)
			chroot_mount_bind(dir_dirct, file_dict, sandbox_dir, 0)
			env_dict = os.environ
			for key in env_para_dict:
				env_dict[key] = env_para_dict[key]
			extra_path = collect_software_bin()
			env_dict['PATH'] = '%s:%s' % (env_dict['PATH'], extra_path[:-1])
			execute_task_host_rootfs(sandbox_dir, env_dict, 'chroot')
			chroot_post_process(dir_dirct, file_dict, sandbox_dir, 0)
		#rename the sandbox_dir to output_dir
		os.rename(sandbox_dir, output_dir)
	elif batch_type == "docker":
		print "local-docker import os image directory into a docker image start: %s" % datetime.datetime.now()
		print "docker *******"
		print "uid: %s; gid: %d" % (os.getuid(), os.getgid())
		if Need_Separate_Rootfs == 1:
			if has_docker_image() == 'no':
				create_docker_image(sandbox_dir)
			print "local-docker import os image directory into a docker image end: %s" % datetime.datetime.now()

			#-v /home/hmeng/umbrella_test/output:/home/hmeng/umbrella_test/output 
			volume_output = " -v %s:%s " % (sandbox_dir, sandbox_dir)
			#-v /home/hmeng/umbrella_test/cache/git-x86_64-redhat5:/software/git-x86_64-redhat5/ 
			volume_parameters = construct_docker_volume(sandbox_dir, input_dict)

			#-e "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/software/git-x86_64-redhat5/bin" 
			path_env = obtain_path() 
			other_envs = transfer_env_para_docker(env_para_dict)
			docker_image_name = "%s-%s-%s" %(Distro_Name, Distro_Version, Hardware_Platform)
			#by default, docker executes User_Cmd as the root user, `chown` is used to change the owner of the output dir to be the user who calls `umbrella`
			chown_cmd = 'chown -R %d:%d %s' % (os.getuid(), os.getgid(), sandbox_dir)
			#to count the post processing time, this cmd is split into two commands
			container_name = "container_%s" % docker_image_name
			cmd = 'docker run --name %s -i -t %s %s -e "PATH=%s" %s %s /bin/sh -c "cd %s; %s; %s"' % (container_name, volume_output, volume_parameters, path_env, other_envs, docker_image_name, sandbox_dir, User_Cmd[0], chown_cmd)
			print cmd
			func_call(cmd)
			print "local-docker docker run User_Cmd end: %s" % datetime.datetime.now()
			print "Rename the sandbox dir(%s) to the output directory(%s)" % (sandbox_dir, output_dir)
			os.rename(sandbox_dir, output_dir)
			cmd = 'docker rm %s' % container_name
			func_call(cmd)
			print "local-docker docker post processing end: %s" % datetime.datetime.now()
		else:
			#if a separate rootfs is not needed to execute the user's cmd, should forcely use other execution engine to run the user cmd.
			execute_task_host_rootfs(sandbox_dir) #need to midify
			os.rename(sandbox_dir, output_dir)
	elif batch_type == "local":
		print "local *******"
		print "local-parrot pre-processing start: %s" % datetime.datetime.now()
		print "uid: %s(%s); gid: %d(%s)" % (os.getuid(), getpass.getuser(), os.getgid(), grp.getgrgid(os.getgid())[0])

		if Need_Separate_Rootfs == 1:
			env_dict = construct_env(sandbox_dir)
			env_dict['PARROT_MOUNT_FILE'] = construct_mountfile(sandbox_dir, input_dict)
			#here, setting the linker will cause strange errors.
			env_dict['PARROT_LDSO_PATH'] = get_linker_path() 
			env_dict['USER'] = getpass.getuser()
			env_dict['HOME'] = sandbox_dir + '/' + getpass.getuser()
			extra_path = collect_software_bin()
			env_dict['PATH'] = '%s%s' % (extra_path, env_dict['PATH'])

			if Has_Parrot_Localfile == 0:
				Parrot_Submit_File.write("#!/bin/sh\n")

				dest = "%s/cache/cctools-%s-%s" % (os.path.dirname(sandbox_dir), Hardware_Platform, Host_Linux_Distro)
				Parrot_Submit_File.write(dest + '/bin/parrot_run ')
				Parrot_Submit_File.write(User_Cmd[0] + '\n')
				
			Parrot_Task_File.close()
			Parrot_Submit_File.close()
			print "local-parrot pre-processing end: %s" % datetime.datetime.now()
			cmd = "/bin/sh " + sandbox_dir + "/local.sh"
			func_call_output_withenv(cmd, env_dict, sandbox_dir)

			print "local-parrot User_Cmd execution end: %s" % datetime.datetime.now()
		else:
			print "local does not seprate rootfs"
			env_dict = os.environ
			env_dict['PARROT_MOUNT_FILE'] = add_inputs_to_mountfile(sandbox_dir, input_dict)
			for key in env_para_dict:
				env_dict[key] = env_para_dict[key]
			extra_path = collect_software_bin()
			#print "extra_path: ", extra_path
			if 'PATH' not in env_dict: #if we run umbrella on Condor, Condor will not set PATH by default.
				env_dict['PATH'] = '/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin'
			env_dict['PATH'] = '%s%s' % (extra_path, env_dict['PATH'])
			#print "env_dict: ", env_dict 

			execute_task_host_rootfs(sandbox_dir, env_dict, 'local')
		print "Rename the sandbox dir(%s) to the output directory(%s)" % (sandbox_dir, output_dir)
		os.rename(sandbox_dir, output_dir)
		print "local-parrot post processing end: %s" % datetime.datetime.now()
	else:
		pass

""" the process of specification when condor execution engine is chosen
"""
def condor_process(spec, spec_file, spec_file_basename, sandbox_dir, output_dir, input_options):
	print "condor_process start: %s" % (datetime.datetime.now())
	if not os.path.exists(sandbox_dir):
		os.makedirs(sandbox_dir)
	if spec.has_key("hardware") and spec["hardware"]:
		env_parameter_init(spec["hardware"], spec["kernel"], spec["os"])
	else:
		sys.exit("this spec has no hardware section\n")

	print "condor_process environment checking end: %s" % (datetime.datetime.now())
	global Condor_Submit_Path
	Condor_Submit_Path = "condor_task.submit"

	input_files = input_options
	input_files = re.sub( '\s+', '', input_files).strip() #remove all the whitespaces within the inputs option
	if input_files == '':
			input_list_origin = ''
	else:
		input_list_origin = input_files.split(',') 

	transfer_inputs = ''
	new_input_options = ''
	for item in input_list_origin:
		index_equal = item.find('=')
		access_path = item[:index_equal]
		actual_path = item[(index_equal+1):]
		transfer_inputs += ', %s' % (actual_path)
		new_input_options += '%s=%s,' % (access_path, os.path.basename(actual_path))
	if new_input_options[-1] == ',':
		new_input_options = new_input_options[:-1]
	print transfer_inputs 
	print new_input_options

	global Condor_Submit_File
	Condor_Submit_File = open(Condor_Submit_Path, "w+")
	Condor_Submit_File.write('universe = vanilla\n')
	Condor_Submit_File.write('executable = umbrella\n')
	Condor_Submit_File.write('arguments = "-c %s -l condor_umbrella -i \'%s\' -o condor_umbrella_output run \'%s\'"\n' % (spec_file_basename, new_input_options, User_Cmd[0]))
	Condor_Submit_File.write('transfer_input_files = umbrella, software.db, %s%s\n' % (spec_file, transfer_inputs))
	Condor_Submit_File.write('transfer_output_files = condor_umbrella_output\n')
	if Linux_Distro == "redhat5":
		Condor_Submit_File.write('requirements = TARGET.Arch == "%s" && TARGET.OpSys == "%s" && TARGET.OpSysAndVer == "redhat6"\n' % (Hardware_Platform, Kernel_Type))
	else:
		Condor_Submit_File.write('requirements = TARGET.Arch == "%s" && TARGET.OpSys == "%s" && TARGET.OpSysAndVer == "%s"\n' % (Hardware_Platform, Kernel_Type, Linux_Distro))
	Condor_Submit_File.write('output = stdout\n') 
	Condor_Submit_File.write('error = stderr\n')
	Condor_Submit_File.write('should_transfer_files = yes\n')
	Condor_Submit_File.write('when_to_transfer_output = on_exit\n')
	Condor_Submit_File.write('log = task.log\n')
	Condor_Submit_File.write('queue\n')
	Condor_Submit_File.close()
	print "condor_process construct submit file end: %s" % (datetime.datetime.now())

	#submit condor job
	cmd = 'condor_submit condor_task.submit'
	func_call(cmd)
	print "condor_process submit job end: %s" % (datetime.datetime.now())
	#keep tracking whether condor job is done
	user_name = getpass.getuser()
	job_running = 1
	print "Waiting for the job is done ..."
	while job_running > 0:
		cmd = 'condor_q %s' % user_name
		p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
		p_status = p.wait()
		for line in p.stdout:
			index = line.find('jobs;')
			if index != -1:
				job_running = int(line[:(index-1)])
				if job_running == 0:
					break
		time.sleep(5)
	print "condor_process job execution end: %s" % (datetime.datetime.now())
	#check until the condor job is done, post-processing (put the output back into the output directory)
	os.rename('condor_umbrella_output', output_dir)
	print "condor_process post processing end: %s" % (datetime.datetime.now())

def ec2_process(spec, spec_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type, input_list, input_options):
	if spec.has_key("hardware") and spec["hardware"]:
		env_parameter_init(spec["hardware"], spec["kernel"], spec["os"])
	else:
		sys.exit("this spec has no hardware section!\n")

	batch_set = ['ec2_level1', 'ec2_level2', 'ec2_level3', 'ec2_level4']
	if batch_type in batch_set:
		print "Start install python on the VM: %s" % datetime.datetime.now()
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'yum -y install wget\''
		func_call(cmd)
		
		python_item = db_search("python", Linux_Distro, Hardware_Platform, sw_conn_cursor) 
		python_url = python_item[3]
		#get the url of python
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'wget ' + python_url + '\''
		func_call(cmd)
		
		scheme, netloc, path, query, fragment = urlparse.urlsplit(python_url)
		python_url_filename = os.path.basename(path)
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'tar zxvf ' + python_url_filename + '\''
		print "Finish install python on the VM: %s" % datetime.datetime.now()
		func_call(cmd)

	#scp umbrella, cmssw.json, software.db and input files to vm
	input_file_string = ''
	for input_file in input_list:
		input_file_string += input_file + ' ' 
	print "Start send umbrella software.db json file: %s" % datetime.datetime.now()
	cmd = 'scp -i ' + ssh_key + ' umbrella software.db ' + spec_file + ' ' + input_file_string + ' ' + user_name + '@' + public_dns + ':' 
	func_call(cmd)
	print "Finish send umbrella software.db json file: %s" % datetime.datetime.now()

	print "Start Execution on the VM: %s" % datetime.datetime.now()
	python_dir = "python-%s-%s" % (Hardware_Platform, Linux_Distro) 
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'' + python_dir + '/bin/python umbrella -c ' + spec_file + ' -s specification -i "' + input_options + '" -o output run "' + User_Cmd[0] + '"\''
	func_call(cmd)
	print "Finish Execution on the VM: %s" % datetime.datetime.now()

	print "Start Post Processing: %s" % datetime.datetime.now()
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ' \'tar cvzf output.tar.gz output\''
	func_call(cmd)

	cmd = 'scp -i ' + ssh_key + ' ' + user_name + '@' + public_dns + ':output.tar.gz .'
	func_call(cmd)

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)

	cmd = 'tar zxvf output.tar.gz'
	func_call(cmd)
	os.rename('output', output_dir)
	print "Finish Post Processing: %s" % datetime.datetime.now()

""" Create the execution environment specified in the specification file and run the task on it.
"""
def specification_process(spec, sandbox_dir, behavior, sw_conn_cursor, cloud_conn_cursor, batch_type, output_dir, input_dict, env_para_dict):
	print "specification_process start: %s" % datetime.datetime.now()
	if not os.path.exists(sandbox_dir):
		os.makedirs(sandbox_dir)

	#copying input files is expensive, so mounting mechanism based on redirection the access_path to the actual_path is a better solution
	#copy all the input files into the sandbox	
#	for input_file in input_list: 
#		shutil.copy(input_file, sandbox_dir)

	#if batch_type is local, create the task.sh based on the user's requirements, download parrot, download SITEINFO, create a clean environment, do the experiment.
	#if batch_type is condor, create the task.sh based on the user's requirements, create condor submit file, submit condor job.
	if spec.has_key("hardware") and spec["hardware"] and spec.has_key("kernel") and spec["kernel"] and spec.has_key("os") and spec["os"]:
		env_parameter_init(spec["hardware"], spec["kernel"], spec["os"])
	else:
		sys.exit("this specification is not complete! You must have a hardware section, a kernel section and a os section!\n")

	env_check(sandbox_dir, batch_type)
	print "env_check end: %s" % datetime.datetime.now()

	print "software_install start: %s" % datetime.datetime.now()
	if spec.has_key("software") and spec["software"]:
		software_install(spec["software"], sw_conn_cursor, sandbox_dir, batch_type)
	else:
		print "this spec does not have software section!\n"
	print "software_install end: %s" % datetime.datetime.now()

	workflow_repeat(sandbox_dir, batch_type, output_dir, sw_conn_cursor, input_dict, env_para_dict)
	print "workflow_repeat end: %s" % datetime.datetime.now()

def dependency_check(dep_list):
	for item in dep_list:
		print "dependency check -- ", item, " "
		p = subprocess.Popen("which " + item, stdout = subprocess.PIPE, shell = True)
		(output, err) = p.communicate()
		p_status = p.wait()
		if p_status != 0:
			sys.exit("command `which(" + item + ")` failed. Please install " + item + " and ensure its directory be added into the PATH environment varibale.\n")

""" Get the minimum integer for the sandbox name
Parameter path: the path of the localdir
Return: the minimum integer which is not occupied by the current directories under the path
"""
def get_sandbox_id(path):
	i = 1
	while(os.path.exists(path + '/' + str(i))):
		i = i + 1
	return i

""" Start one VM instance through Amazon EC2 command line interface and return the instance id.
Parameter image_id: the Amazon Image Identifier
Return the id of the started instance
"""
def get_instance_id(image_id):
	cmd = 'ec2-run-instances ' + image_id + ' -t c3.large -k hmeng_key_1018 -g sg-24f96141 --associate-public-ip-address true'
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	p_status = p.wait()
	while True:
		line = p.stdout.readline()
		if line != '':
			line = line.rstrip()	
			if line[:8] == 'INSTANCE':
				instance_id = line[9:19]
				return instance_id

""" Get the public dns of one VM instance from Amazon EC2, `ec2-run-instances` can not directly return the public dns of the instance, so this function is needed to check the result of `ec2-describe-instances` to obtain the public dns of the instance.
Parameter: the id of the VM instance
Return: the public dns of the instance
"""
def get_public_dns(instance_id):
	public_dns = ''
	while public_dns == None or public_dns == '' or public_dns == 'l':
		cmd = 'ec2-describe-instances ' + instance_id
		p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
		p_status = p.wait()
		while True:
			line = p.stdout.readline()
			if line != '':
				line = line.rstrip()	
				str1 = 'PRIVATEIPADDRESS' 
				if line[:16] == str1:
					index = line.find("ec2")
					public_dns = line[index:]
					break
	return public_dns

def main():
	parser = OptionParser(usage="usage: %prog [options] run \"command\"",
						version="%prog 1.0")
	parser.add_option("-c", "--config",
					action="store",
					default="spec.json",
					help="The specification json file. (By default: spec.json)")
	parser.add_option("-l", "--localdir",
					action="store", 
					default="./umbrella_test",
					help="The path of directory used for all the cached data and all the sandboxes. (By default: ./umbrella_test)",)
	parser.add_option("-i", "--inputs",
					action="store", 
					default='',
					help="The path of input files in the format of access_path=actual_path. i.e, -i '/home/hmeng/file1=/tmp/file2'. access_path must be consistent with the semantics of the provided command, actual_path can be relative or absolute. (By default: '')",)
	parser.add_option("-e", "--env",
					action="store", 
					default='',
					help="The environment variable. I.e., -e 'PWD=/tmp'. (By default: '')")
	parser.add_option("-o", "--output",
					action="store", 
					default="./umbrella_output",
					help="The path of output. (By default: ./umbrella_output)",)
	parser.add_option("-T", "--batch_type",
					action="store", 
					default="local",
					choices=['local', 'chroot', 'docker', 'condor',],
					help="Batch system type, which can be local, chroot, docker, condor. (By default: local)",)
	parser.add_option("--softwaredb",
					action="store", 
					default="./software.db",
					help="The path of software db. (By default: ./software.db)",)
	parser.add_option("--clouddb",
					action="store", 
					default="./cloud.db",
					help="The path of cloud db. (By default: ./cloud.db)",)

	(options, args) = parser.parse_args()

#	print 'Number of arguments:', len(sys.argv), 'arguments.'
#	print 'Argument List:', str(sys.argv)

	if not args:
		print "You must provide the behavior and the command!\n"
		parser.print_help()
		sys.exit()
	behavior = args[0]
	behavior_list = ["run"]
	if behavior not in behavior_list:
		print behavior + " is not supported by umbrella!\n"
		parser.print_help()
		sys.exit()

	#cmd = sys.argv[-1]

	batch_type = options.batch_type
	if batch_type == 'chroot':
		if getpass.getuser() != 'root':
			print 'You must be root to use chroot method.\n'
			parser.print_help()
			sys.exit()

	#get the absolute path of the localdir directory, which will cache all the data, and store all the sandboxes.
	#to allow the reuse the local cache, the localdir can be a dir which already exists.
	localdir = options.localdir
	localdir = os.path.abspath(localdir)

	#get a sandbox number, which will become the name of the sandbox directory
	global Sandbox_ID #modification of a global variable within a function must declare the variable using `global` directive
	Sandbox_ID = get_sandbox_id(localdir)
	sandbox_dir = localdir + '/' + str(Sandbox_ID)
#	print sandbox_dir

	#transfer options.env into a dictionary, env_para_dict
	env_para_dict = {}
	env_para = options.env
	if env_para is None:
		env_para_list = ''
	else:
		env_para = re.sub('\s+', '', env_para).strip()
		env_para_list = env_para.split(',')

	for item in env_para_list:
		index = item.find('=')
		name = item[:index]	
		value = item[(index+1):]
		env_para_dict[name] = value

	spec_file = options.config
	spec_file_basename = os.path.basename(spec_file)
	print "spec_file", spec_file
	if not os.path.isfile(spec_file):
		print "The specification json file does not exist! Please refer the -c option.\n"
		parser.print_help()
		sys.exit()

	with open(spec_file) as f: #python 2.4 does not support this syntax: with open () as
		specification = json.load(f)

		#if the spec file has environ seciton, merge the variables defined in it into env_para_dict
		if specification.has_key("environ") and specification["environ"]:
			spec_env = specification["environ"]
			for key in spec_env:
				env_para_dict[key] = spec_env[key]

#	print env_para_dict

	global CWD_Setting
	if 'PWD' in env_para_dict:
		CWD_Setting = env_para_dict['PWD']
	else:
		CWD_Setting = sandbox_dir

	#get the absolute path of each input file
	input_files = options.inputs
	input_files = re.sub( '\s+', '', input_files).strip() #remove all the whitespaces within the inputs option
	if input_files == '':
		input_list_origin = ''
	else:
		input_list_origin = input_files.split(',') 

	input_list = []
	input_dict = {}
	for item in input_list_origin:
		index = item.find('=')
		access_path = item[:index]
		actual_path = item[(index+1):]
		if access_path[0] != '/':
			access_path = os.path.join(CWD_Setting, access_path)
		actual_path = os.path.abspath(actual_path)
		input_dict[access_path] = actual_path
		input_list.append(actual_path) #get the absolute path of each input file and add it into input_list

	#get the absolute path of each output file	
	output_dir = options.output
	output_dir = os.path.abspath(output_dir)

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	elif len(os.listdir(output_dir)) != 0:
		sys.exit("%s is not empty! Please clean the output directory first or specify another directory!\n" % output_dir)
	else:
		pass
	#create a connection to the software.db, which includes the name, version, platform, storage location url, checksum, type of each dependency (OS, software, data)
	software_db = options.softwaredb
	if not os.path.exists(software_db):
		print 'the software db does not exist. Please refer the --softwaredb option.\n'
		parser.print_help()
		sys.exit()
	sw_conn = sqlite3.connect(software_db)
	sw_conn_cursor = sw_conn.cursor()

	#create a connection to the ec2.db, which includes the metadata information of ec2 resources.
	cloud_db = options.clouddb
	if not os.path.exists(cloud_db):
		print 'the cloud db does not exist. Please refer the --clouddb option.\n'
		parser.print_help()
		sys.exit()
	cloud_conn = sqlite3.connect(cloud_db)
	cloud_conn_cursor = cloud_conn.cursor()
	
	global User_Cmd
	User_Cmd = args[1:]

	if behavior in ["run"]:
		dep_list = []
		dependency_check(dep_list)

		user_name = 'root' #username who can access the VM instances from Amazon EC2
		ssh_key = 'hmeng_key_1018.pem' #the pem key file used to access the VM instances from Amazon EC2
		if batch_type == "ec2_level1":
			print "ec2_level 1 Start a ec2 VM: %s" % datetime.datetime.now()
			#get the instance id
			instance_id = get_instance_id('ami-7bdaa84b') #RHEL-6.5_GA-x86_64-9-Hourly2; for povray
			#get the public DNS of the instance_id
			public_dns = get_public_dns(instance_id)
			print "ec2_level 1 finishing start a ec2 VM: %s" % datetime.datetime.now()
			ec2_process(specification, spec_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type, input_list, options.inputs)
		elif batch_type == "ec2_level2":
			public_dns = 'ec2-54-69-37-113.us-west-2.compute.amazonaws.com'
			ec2_process(specification, spec_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type, input_list, options.inputs)
		elif batch_type == "ec2_level3":
			instance_id = get_instance_id('ami-d76a29e7') ##RHEL-5.10_GA-x86_64-8-Hourly2-GP2; for povray
			public_dns = get_public_dns(instance_id)
			ec2_process(specification, spec_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type, input_list, options.inputs)
		elif batch_type == "ec2_level4":
			public_dns = 'ec2-54-69-219-28.us-west-2.compute.amazonaws.com'
			ec2_process(specification, spec_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type, input_list, options.inputs)
		elif batch_type == "ec2_level5":
			public_dns = 'ec2-54-69-219-28.us-west-2.compute.amazonaws.com'
			ec2_process(specification, spec_file, sw_conn_cursor, ssh_key, user_name, public_dns, output_dir, batch_type, input_list, options.inputs)
		elif batch_type == "condor":
			condor_process(specification, spec_file, spec_file_basename, sandbox_dir, output_dir, options.inputs)
		else:
			specification_process(specification, sandbox_dir, behavior, sw_conn_cursor, cloud_conn_cursor, batch_type, output_dir, input_dict, env_para_dict)

	#close the connections to databases
	sw_conn.close()
	cloud_conn.close()

if __name__ == "__main__":
	main()

#set sts=4 sw=4 ts=4 expandtab ft=python
