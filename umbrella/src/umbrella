#!/usr/bin/python
'''
Copyright (C) 2003-2004 Douglas Thain and the University of Wisconsin
Copyright (C) 2005- The University of Notre Dame
This software is distributed under the GNU General Public License.
See the file COPYING for details.
'''
import sys
from stat import *
from pprint import pprint
import subprocess
import platform
import re
import tarfile
import StringIO
from optparse import OptionParser
import os
import hashlib
import difflib
import sqlite3
import shutil
import datetime
import time
import getpass
import grp
import logging
import multiprocessing
import resource

if sys.version_info >= (3,):
	import urllib.request as urllib2
	import urllib.parse as urlparse
else:
	import urllib2
	import urlparse

if sys.version_info > (2,6,):
	import json
else:
	import simplejson as json #json module is introduce in python 2.4.3

""" Execute a command and return the standard output.
Parameter cmd: the command needs to execute using the subprocess module
Return: the output of the execution.
"""
def func_call(cmd):
	logging.debug("Start to execute command: %s", cmd)
	print "Start to execute command: ", cmd
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()
	print output
	return output, err

def func_call_output(cmd, output_dir):
	output, err = func_call(cmd)
	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/umbrella_stdout"
	logging.debug("Writing the output of the command into %s ....", stdout)
	with open(stdout, 'w+') as file1:
		file1.write(output)
	if err:
		stderr = output_dir + "/umbrella_stderr"
		logging.debug("Writing the stderr of the command into %s ....", stderr)
		with open(stderr, 'w+') as file1:
			file1.write(err)
	
def func_call_output_withenv(cmd, env_dict, output_dir):
	logging.debug("Start to execute command: %s", cmd)
	print "Start to execute command: ", cmd
	logging.debug("The environment variables for executing the command is:")
	logging.debug(env_dict)
	p = subprocess.Popen(cmd, env = env_dict, stdout = subprocess.PIPE, shell = True)
	(output, err) = p.communicate()
	p_status = p.wait()
	print "\n func_call_output_withenv"
	print "p_status: ", p_status
	print "output: ", output
	print "err: ", err
	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	stdout = output_dir + "/umbrella_stdout"
	logging.debug("Writing the output of the command into %s ....", stdout)
	with open(stdout, 'w+') as file1:
		file1.write(output)

""" Calculate the md5sum of a file
Parameter filename: the name of the file 
Parameter block_size: the size of each block
Return: the md5 value of the content of the file
"""
def md5_cal(filename, block_size=2**20):
	try:
		with open(filename, 'rb') as f:
			md5 = hashlib.md5()
			while True:
				data = f.read(block_size)
				if not data:
					break
				md5.update(data)
			return md5.hexdigest()
	except:
		logging.debug("Computing the checksum of %s fails.", filename)
		sys.exit("md5_cal(" + filename + ") failed.\n")

""" Check whether a url is broken or not.
Parameter url: a url
Return: if the url is broken, return 1; otherwise, return 0.
"""
def url_check(url):
	try:
		f = urllib2.urlopen(urllib2.Request(url))
	except:
		print "url({0}) is broken.".format(url)
		return 1
	return 0

''' Download url into dest
'''
def url_download(url, dest):
	try:
		logging.debug("Start to download %s ....", url)
		response = urllib2.urlopen(url)
		data = response.read()
	except urllib2.URLerror as e:
		logging.critical("URLerror (%d): %s", e.errno, e.strerror)
		sys.exit("URLerror({0}): {1}".format(e.errno, e.strerror))
	with open(dest, "wb") as code:
		code.write(data)

""" Download each dependency from the url and verify its integrity.
Parameter url: the storage location of the dependency
Parameter checksum: the checksum of the dependency
Parameter checksum_tool: the tool used to calculate the checksum, such as md5sum.
Parameter dest: the destination of the dependency where the downloaded dependency will be put
Parameter format_remote_storage: the file format of the dependency, such as .tgz.
"""
def dependency_download(url, checksum, checksum_tool, dest, format_remote_storage, action):
	logging.debug("Download software from %s into the dir (%s)", url, dest)
	dest_dir = os.path.dirname(dest)
	dest_uncompress = dest #dest_uncompress is the path of the uncompressed-version dependency

	scheme, netloc, path, query, fragment = urlparse.urlsplit(url)
	filename = os.path.basename(path)
	dest = os.path.join(dest_dir, filename) #dest is the path of the compressed-version dependency

	if not os.path.exists(dest_dir):
		os.makedirs(dest_dir)

	if not os.path.exists(dest):
		#download the dependency from the url
		#this method currently will fail when the data size is larger than the memory size, use subprocess + wget can solve it
		try:
			logging.debug("Start to download ....")
			response = urllib2.urlopen(url)
			data = response.read()
		except urllib2.URLerror as e:
			logging.critical("URLerror (%d): %s", e.errno, e.strerror)
			sys.exit("URLerror({0}): {1}".format(e.errno, e.strerror))
		with open(dest, "wb") as code:
			code.write(data)
		#if it exists, the uncompressed-version directory will be deleted first
		if action == "unpack" and format_remote_storage != 'plain' and os.path.exists(dest_uncompress):
			shutil.rmtree(dest_uncompress)
			logging.debug("the uncompressed-version directory exists already, first delete it")

	#calculate the checkusm of the compressed-version dependency
	if checksum_tool == "md5sum":
		local_checksum = md5_cal(dest)
		logging.debug("The checksum of %s is: %s", dest, local_checksum)
	else:
		logging.critical("%s is not supported currently!", checksum_tool)
		sys.exit(checksum_tool + "is not supported currently!")

	if not local_checksum == checksum:
		logging.critical("The version of %s is incorrect! Please first delete it and its unpacked directory!!", dest)
		sys.exit("the version of " + dest + " is incorrect! Please first delete it and its unpacked directory!!\n")
	
	#if the uncompressed-version dependency does not exist, uncompress the dependency
	if action == "unpack" and (not os.path.exists(dest_uncompress)) and format_remote_storage == "tgz": 
		logging.debug("Uncompressing %s into %s ....", dest, dest_uncompress)
		tfile = tarfile.open(dest, "r:gz")
		tfile.extractall(dest_dir)

def package_search(packages, name, id):
	if packages.has_key(name):
		if id == '':
			for item in packages[name]:
				return packages[name][item]
		else:
			if packages[name].has_key(id):
				return packages[name][id]
			else:
				logging.debug("packages does not has <%s> with the id <%s>", name, id)
				sys.exit("packages does not has <%s> with the id <%s>" % (name, id))
	else:
		logging.debug("packages does not include %s", name)
		sys.exit("packages does not include %s\n" % name)

def cctools_download(sandbox_dir, packages, hardware_platform, host_linux_distro, action):
	name = "cctools-4.4.0-%s-%s" % (host_linux_distro, hardware_platform)
	item = package_search(packages, name, '')
	dest = os.path.dirname(sandbox_dir) + "/cache/" + name
	dependency_download(item['source'][0], item["checksum"], "md5sum", dest, item["format"], action)
	return dest

#the db table itself does not understand the collaberation relationship between cvmfs, parrot, SITECONF
''' cms_parrot
'''
def cmssw_cvmfs_parrot(name, action, packages, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, parrot_submit_file):
	#construct the parrot submit script
	logging.debug("Construct parrot submit file for using CVMFS ....")
	parrot_submit_file.write("#!/bin/sh\n")
	parrot_submit_file.write("export HTTP_PROXY=http://cache01.hep.wisc.edu:3128\n")
	logging.debug("To access cvmfs, cctools binary is needed")
	cctools_download(sandbox_dir, packages, hardware_platform, host_linux_distro, action)
	has_parrot_localfile = 0
	cvmfs_siteinfo_mountpoint = ''
	#download SITECONF
#	site_item = package_search(packages, "cms_siteconf_local_cvmfs")
#	dest = os.path.dirname(sandbox_dir) + "/cache/cvmfs/cms.cern.ch/SITECONF"
#	dependency_download(site_item["source"][0], site_item["checksum"], "md5sum", dest, site_item["format"], action)
#	cvmfs_siteinfo_mountpoint = '/cvmfs/cms.cern.ch/SITECONF/local %s/local' % dest

	parrot_dest = "%s/cache/cctools-4.4.0-%s-%s/bin/parrot_run" % (os.path.dirname(sandbox_dir), host_linux_distro, hardware_platform)
	parrot_submit_file.write('env; ' + parrot_dest + " --no-set-foreground /bin/sh -c 'cd " + sandbox_dir + "; " + user_cmd[0] + "'\n" )

	has_parrot_localfile = 1
	return has_parrot_localfile, cvmfs_siteinfo_mountpoint

def data_dependency_process(name, id, packages_json, sandbox_dir, action):
	item = package_search(packages_json, name, id)
	#table schema: (name text, version text, platform text, store text, store_type text, type text)
	store = item["source"][0] 
	dest = os.path.dirname(sandbox_dir) + "/cache/" + name 
	dependency_download(store, item['checksum'], "md5sum", dest, item["format"], action)
	mount_value = dest
	return mount_value

''' Check whether cvmfs is installed on the host or not
'''
def check_cms():
	logging.debug("Check whether cvmfs is installed on the host or not")
	cmd = "df -h|grep '^cvmfs'|grep cms.cern.ch|rev| cut -d' '  -f1|rev"
	stdout, stderr = func_call(cmd)
	return stdout

'''
Parameter name: the item name in the software section
'''
def dependency_process(name, id, mountpoint, action, packages, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, parrot_submit_file):
	#this part should changed. First check whether name is in the format of `cmssw_...`. If yes, check the batch type: if parrot, run it using the current mechanism; if docker, download a cvmfs-cmssw package, and mount it as a volume into the docker container. If it is not cmssw software dependency, process it normally.
	has_parrot_localfile = 0
	is_cvmfs_parrot_app = 0
	cvmfs_siteinfo_mountpoint = ''
	mount_value = ''
	local_cvmfs = ''
	if name[:5] == 'cmssw':
		local_cms = check_cms()
		if local_cms:
			local_cvmfs = os.path.dirname(local_cms)
			logging.debug("The cvmfs is installed on the local host, and its mountpoint is: %s", local_cvmfs)
		else:
			logging.debug("The cvmfs is not installed on the local host.")
			#if batch_type is parrot, we need a cctools version specially compiled for cvmfs
			#if batch_type is cvmfs, we need add a special volume
		if batch_type == 'parrot':
			is_cvmfs_parrot_app = 1
			logging.debug("Software dependency: %s", name)
			r1, r2 = cmssw_cvmfs_parrot(name, action, packages, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, parrot_submit_file)	
			if r1 == 1:
				has_parrot_localfile = 1
				cvmfs_siteinfo_mountpoint = r2
			if local_cvmfs:
				mount_value = local_cvmfs
			else:
				item = package_search(packages, name, id)
				store = item ['source'][0]
		
				dest = os.path.dirname(sandbox_dir) + "/cache/" + name
				dependency_download(store, item['checksum'], "md5sum", dest, item["format"], action)
				mount_value = '-%s/cvmfs' % dest
			logging.debug('Parrot cmssw cvmfs mount source: %s', mount_value)
		
		elif batch_type == 'docker':
			is_cvmfs_parrot_app = 1
			logging.debug("Software dependency: %s", name)
			if local_cvmfs:
				mount_value = local_cvmfs
			else:
				item = package_search(packages, name, id)
				store = item ['source'][0]
		
				dest = os.path.dirname(sandbox_dir) + "/cache/" + name
				dependency_download(store, item['checksum'], "md5sum", dest, item["format"], action)
				mount_value = '-%s/cvmfs' % dest
			logging.debug('Docker cmssw cvmfs mount source: %s', mount_value)
		else:
			pass
	else:
		item = package_search(packages, name, id)
		#table schema: (name text, version text, platform text, store text, store_type text, type text)
		store = item["source"][0] 
	
		dest = os.path.dirname(sandbox_dir) + "/cache/" + name 
		dependency_download(store, item['checksum'], "md5sum", dest, item["format"], action)
		mount_value = dest
	return has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_value, local_cvmfs
	
''' Set the global environment parameters according to the specification file
'''	
def env_parameter_init(hardware_spec, kernel_spec, os_spec):
	hardware_platform = hardware_spec["arch"].lower()
	cpu_cores = hardware_spec["cores"].lower()
	memory_size = hardware_spec["memory"].lower()
	disk_size = hardware_spec["disk"].lower()
	kernel_name = kernel_spec["name"].lower()
	kernel_version = kernel_spec["version"].lower()
	distro_name = os_spec["name"].lower()
	distro_version = os_spec["version"].lower()
	if os_spec.has_key("id"):
		os_id = os_spec["id"]
	else:
		os_id = ''
	index = distro_version.find('.')
	linux_distro = distro_name + distro_version[:index]
	return hardware_platform, cpu_cores, memory_size, disk_size, kernel_name, kernel_version, linux_distro, distro_name, distro_version, os_id

''' Compare two versions, the format of version is: X.X.X
Parameter v1: a version
Parameter v2: a version
Return: 0 if v1 == v2; 1 if v1 is newer than v2; -1 if v1 is older than v2.
'''
def compare_versions(v1, v2):
	list1 = v1.split('.')
	list2 = v2.split('.')
	for i in range(len(list1)):
		list1[i] = int(list1[i])
	for i in range(len(list2)):
		list2[i] = int(list2[i])
	if list1[0] == list2[0]:
		if list1[1] == list2[1]:
			if list1[2] == list2[2]:
				return 0
			elif list1[2] > list2[2]:
				return 1
			else:
				return -1
		elif list1[1] > list2[1]:
			return 1
		else:
			return -1

	elif list1[0] > list2[0]:
		return 1
	else:
		return -1

def	verify_kernel(host_kernel_name, host_kernel_version, kernel_name, kernel_version):
	if host_kernel_name != kernel_name:
		logging.critical("The required kernel name is %s, the kernel name of the host machine is %s!", kernel_name, host_kernel_name)
		sys.exit("The required kernel name is %s, the kernel name of the host machine is %s!\n" % (kernel_name, host_kernel_name))	
	if kernel_version[0] == '[':
		list1 = kernel_version[1:-1].split(',')
		if compare_versions(host_kernel_version, list1[0]) >= 0 and compare_versions(host_kernel_version, list1[1]) <= 0:
			logging.debug("The kernel version matches!")
		else:
			logging.debug("The required kernel version is %s, the kernel version of the host machine is %s!", kernel_version, host_kernel_version)
			sys.exit("The required kernel version is %s, the kernel version of the host machine is %s!\n" % (kernel_version, host_kernel_version))
	elif kernel_version[0] == '>':
		if compare_versions(host_kernel_version, kernel_version[2:]) >= 0:
			logging.debug("The kernel version matches!")
		else:
			logging.debug("The required kernel version is %s, the kernel version of the host machine is %s!", kernel_version, host_kernel_version)
			sys.exit("The required kernel version is %s, the kernel version of the host machine is %s!\n" % (kernel_version, host_kernel_version))
	elif kernel_version[0] == '<':
		if compare_versions(host_kernel_version, kernel_version[2:]) <= 0:
			logging.debug("The kernel version matches!")
		else:
			logging.debug("The required kernel version is %s, the kernel version of the host machine is %s!", kernel_version, host_kernel_version)
			sys.exit("The required kernel version is %s, the kernel version of the host machine is %s!\n" % (kernel_version, host_kernel_version))
	else: #the kernel version is a single value 
		if compare_versions(host_kernel_version, kernel_version[2:]) == 0:
			logging.debug("The kernel version matches!")
		else:
			logging.critical("The required kernel version is %s, the kernel version of the host machine is %s!", kernel_version, host_kernel_version)
			sys.exit("The required kernel version is %s, the kernel version of the host machine is %s!\n" % (kernel_version, host_kernel_version))	

''' Currently check the following item: hardware platform, kernel, OS, disk, memory, cpu cores
Other things needed to check: software, and data??
'''	
def env_check(sandbox_dir, batch_type, hardware_platform, cpu_cores, memory_size, disk_size, kernel_name, kernel_version):
	print "Execution environment checking ..."
	
	if batch_type != "docker" and batch_type != "chroot" and batch_type != "parrot":
		logging.critical("Currently local execution engine only support three sandbox techniques: docker, chroot or parrot!")
		sys.exit("Currently local execution engine only support three sandbox techniques: docker, chroot or parrot!\n")

	parrot_submit_path = sandbox_dir + "/parrot_submit.sh"
	parrot_submit_file = open(parrot_submit_path, "wb")
	logging.debug("Create parrot submit file (%s)", parrot_submit_path)

	uname_list = platform.uname() #format of uname_list: (system,node,release,version,machine,processor)
#	for i in range(len(uname_list)):
#		print uname_list[i],
#	print ''

	logging.debug("Hardware platform checking ...")
	if hardware_platform != uname_list[4].lower():
		logging.critical("The specification requires %s, but the local machine is %s", hardware_platform, uname_list[4].lower())
		sys.exit("The specification requires " + hardware_platform + ", but the local machine is " + uname_list[4].lower() + "!\n")

	logging.debug("CPU cores checking ...")
	cpu_cores = int(cpu_cores)
	host_cpu_cores = multiprocessing.cpu_count()
	if cpu_cores > host_cpu_cores:
		logging.critical("The specification requires %d cpu cores, but the local machine only has %d cores!", cpu_cores, host_cpu_cores)
		sys.exit("The specification requires %d cpu cores, but the local machine only has %d cores!\n" % (cpu_cores, host_cpu_cores))

	logging.debug("Memory size checking ...")
	memory_size = re.sub('\s+', '', memory_size).strip()
	memory_size = float(memory_size[:-2])

	cmd = "free -tg|grep Total|sed 's/\s\+/ /g'|cut -d' ' -f2"
	stdout, stderr = func_call(cmd)
	host_memory_size = float(stdout)
	if memory_size > host_memory_size:
		logging.critical("The specification requires %.2f GB memory space, but the local machine only has %.2f GB free memory space!", memory_size, host_memory_size)
		sys.exit("The specification requires %.2f GB memory space, but the local machine only has %.2f GB free memory space!" % (memory_size, host_memory_size))

	logging.debug("Disk space checking ...")
	disk_size = re.sub('\s+', '', disk_size).strip()
	disk_size = float(disk_size[:-2])
	st = os.statvfs(sandbox_dir)
	free_disk = float(st.f_bavail * st.f_frsize) / (1024*1024*1024)
	if disk_size > free_disk:
		logging.critical("The specification requires %.2f GB disk space, but the local machine only has %.2f GB free disk space!", disk_size, free_disk)
		sys.exit("The specification requires %.2f GB disk space, but the local machine only has %.2f GB free disk space!" % (disk_size, free_disk))

	#check kernel
	logging.debug("Kernel checking ...")
	host_kernel_name = uname_list[0].lower()
	index = uname_list[2].find('-')
	host_kernel_version = uname_list[2][:index]
	verify_kernel(host_kernel_name, host_kernel_version, kernel_name, kernel_version)

	dist_list = platform.dist()
	logging.debug("The hardware information of the local machine:")
	logging.debug(dist_list)

	#set host_linux_distro
	arch_index = uname_list[2].find('ARCH')
	if arch_index != -1:
		host_linux_distro = 'arch'		
	redhat_index = uname_list[2].find('el')
	centos_index = uname_list[2].find('centos')
	if redhat_index != -1:
		dist_version = uname_list[2][redhat_index + 2]
		if centos_index != -1 or dist_list[0].lower() == 'centos':
			host_linux_distro = 'centos' + dist_version
		else:
			host_linux_distro = 'redhat' + dist_version		
	logging.debug("The OS distribution information of the local machine: %s", host_linux_distro)

	return host_linux_distro, parrot_submit_path, parrot_submit_file

""" Installation each software dependency specified in the software section of the specification
Parameter software_spec: the software section of the specification
Parameter sandbox_dir: the sandbox directory
Parameter batch_type: the batch type
"""
def software_install(os_id, software_spec, packages, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, distro_name, distro_version, parrot_submit_file, need_separate_rootfs, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict, host_cctools_path):
	print "Installing software dependencies ..."
	for item in software_spec:
		if software_spec[item].has_key('id'):
			id = software_spec[item]['id']
		else:
			id = ''
		mountpoint = software_spec[item]['mountpoint']
		action = software_spec[item]['action']
		r1, r2, r3, r4, r5 = dependency_process(item, id, mountpoint, action, packages, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, parrot_submit_file)
		if r1 == 1 and has_parrot_localfile == 0:
			has_parrot_localfile = 1
			cvmfs_siteinfo_mountpoint = r3
		if r2 == 1 and is_cvmfs_parrot_app == 0:
			is_cvmfs_parrot_app = 1
		if r5:
			mountpoint =  os.path.dirname(mountpoint)
			logging.debug("Add mountpoint (%s:%s) into mount_dict", mountpoint, r5)
			mount_dict[mountpoint] = r5
		if r4:
			if r4[0] == '-':
				mountpoint = '/cvmfs'	
				r4 = r4[1:]
			logging.debug("Add mountpoint (%s:%s) into mount_dict", mountpoint, r4)
			mount_dict[mountpoint] = r4

	#if the OS distribution does not match, add the OS image into the dependency list of the application and download it into the local machine
	if need_separate_rootfs == 1:
		item = '%s-%s-%s' % (distro_name, distro_version, hardware_platform)
		mountpoint = '/'	
		action = 'unpack'
		r1, r2, r3, r4, r5 = dependency_process(item, os_id, mountpoint, action, packages, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, parrot_submit_file)
		if r1 == 1 and has_parrot_localfile == 0:
			has_parrot_localfile = 1
			cvmfs_siteinfo_mountpoint = r3
		if r2 == 1 and is_cvmfs_parrot_app == 0:
			is_cvmfs_parrot_app = 1
		if r5:
			mountpoint =  os.path.dirname(mountpoint)
			logging.debug("Add mountpoint (%s:%s) into mount_dict", mountpoint, r5)
			mount_dict[mountpoint] = r5
		if r4:
			if r4[0] == '-':
				mountpoint = '/cvmfs'	
				r4 = r4[1:]
			logging.debug("Add mountpoint (%s:%s) into mount_dict", mountpoint, r4)
			mount_dict[mountpoint] = r4

	#if the batch_type is parrot, add cctools into the dependency list to guarantee parrot can be used to create sandbox for the worst case (No root access authority and no docker).
	if batch_type == "parrot":
		host_cctools_path = cctools_download(sandbox_dir, packages, hardware_platform, host_linux_distro, 'unpack')
		logging.debug("To support local execution engine, cctools binary (%s) is needed.", host_cctools_path)
	return host_cctools_path, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict

''' Process data section of the specification
'''
def data_install(data_spec, packages_json, sandbox_dir, mount_dict):
	print "Installing data dependencies ..."
	for item in data_spec:
		if data_spec[item].has_key('id'):
			id = data_spec[item]['id']
		else:
			id = ''
		mountpoint = data_spec[item]['mountpoint']
		action = data_spec[item]['action']
		mount_value = data_dependency_process(item, id, packages_json, sandbox_dir, action)
		logging.debug("Add mountpoint (%s:%s) into mount_dict", mountpoint, mount_value)
		mount_dict[mountpoint] = mount_value
	return mount_dict

""" Return the path of ld-linux.so within the downloaded os image dependency
"""
def get_linker_path(hardware_platform, os_image_dir):
	#env_list is directly under the directory of the downloaded os image dependency
	if hardware_platform == "x86_64":
		return os.path.dirname(os_image_dir + "/env_list") + "/lib64/ld-linux-x86-64.so.2"	
	else:
		return "undefined platform type"

""" Construct the docker volume parameters based on mount_dict 
"""
def construct_docker_volume(sandbox_dir, input_dict, is_cvmfs_parrot_app, mount_dict):
	del mount_dict["/"] #remove "/" from the mount_dict to avoid messing the root directory of the host machine
	volume_paras = ""
#	if is_cvmfs_parrot_app == 1:
#		cvmfs_data_path = os.path.dirname(sandbox_dir) + '/cache/cvmfs/cms.cern.ch/SITECONF/local'
#		mount_dict[cvmfs_data_path] = '/cvmfs/cms.cern.ch/SITECONF/local'
	for key in mount_dict:
		volume_paras = volume_paras + " -v " + mount_dict[key] + ":" + key + " "

	for key in input_dict:
		volume_paras = volume_paras + " -v " + input_dict[key] + ":" + key + " "

	return volume_paras

""" Get the path environment variable from envfile and add the mountpoints of software dependencies into it
"""
def obtain_path(os_image_dir, mount_dict):
	with open(os_image_dir + "/env_list", "rb") as f:
		path_env = ''	
		for line in f:
			if line[:5] == 'PATH=':
				path_env = line[5:-1]
				break
	for key in mount_dict:
		path_env = key + "/bin:" + path_env 
	return path_env

def transfer_env_para_docker(env_para_dict):
	other_envs = ''
	for key in env_para_dict:
		if key:
			other_envs = other_envs + ' -e "' + key + '=' + env_para_dict[key] + '" '
	return other_envs

""" Construct the path environment from the mountpoints of software dependencies for the case where a separate rootfs needs to be constrcuted
"""
def collect_software_bin(host_cctools_path, mount_dict):
	extra_path = ""
	for key in mount_dict:
		if key != '/':
			extra_path += '%s/bin:' % key
	if host_cctools_path != "":
		extra_path += '%s/bin:' % host_cctools_path 
	return extra_path

""" Judge whether a user exists in /etc/passwd
"""
def In_local_passwd():
	user_name = getpass.getuser()
	with open('/etc/passwd') as f:
		for line in f:
			if line[:len(user_name)] == user_name:
				logging.debug("%s is included in /etc/passwd!", user_name)
				return 'yes'
	logging.debug("%s is not included in /etc/passwd!", user_name)
	return 'no'

""" Judge whether a group exists in /etc/group
"""
def In_local_group():
	group_name = grp.getgrgid(os.getgid())[0]
	with open('/etc/group') as f:
		for line in f:
			if line[:len(group_name)] == group_name:
				logging.debug("%s is included in /etc/group!", group_name)
				return 'yes'
	logging.debug("%s is not included in /etc/group!", group_name)
	return 'no'

""" Create the mountfile if parrot is used to create a sandbox for the application
Return the path of the mountfile
"""
def construct_mountfile(sandbox_dir, input_dict, hardware_platform, host_linux_distro, os_image_dir, cvmfs_siteinfo_mountpoint, mount_dict):
	mountfile_path = sandbox_dir + "/mountlist"		
	with open(mountfile_path, "wb") as mountfile:
		new_root = mount_dict["/"]
		mountfile.write("/ " + new_root + "\n")	
		del mount_dict["/"]
		mountfile.write(new_root + " " + new_root + "\n")	
		logging.debug("Adding items from mount_dict into %s", mountfile_path)
		for key in mount_dict:
			mountfile.write(key + " " + mount_dict[key] + "\n")
			mountfile.write(mount_dict[key] + " " + mount_dict[key] + "\n")

		#common-mountlist includes all the common mountpoint (/proc, /dev, /sys, /mnt, /disc, /selinux)
		logging.debug("Adding items from %s into %s", os_image_dir + "/common-mountlist", mountfile_path)
		with open(os_image_dir + "/common-mountlist", "rb") as f:
			for line in f:
				mountfile.write(line)
		logging.debug("Add %s into %s", sandbox_dir, mountfile_path)
		mountfile.write(sandbox_dir + ' ' + sandbox_dir + '\n')

		logging.debug("Add /etc/hosts and /etc/resolv.conf into %s", mountfile_path)
		mountfile.write('/etc/hosts /etc/hosts\n')
		mountfile.write('/etc/resolv.conf /etc/resolv.conf\n')
		#nd workstation uses NSCD (Name Service Cache Daemon) to deal with passwd, group, hosts services. Here first check whether the current uid and gid is in the /etc/passwd and /etc/group, if yes, use them. Otherwise, construct separate passwd and group files.
		existed_user = In_local_passwd()
		if existed_user == 'yes':
			logging.debug("Add /etc/passwd into %s", mountfile_path)
			mountfile.write('/etc/passwd /etc/passwd\n')
		else:
			#If the current user name and group can not be found in /etc/passwd and /etc/group, a fake passwd and group file will be constructed.
			logging.debug("Construct a fake passwd file: .passwd, add .passwd into %s", mountfile_path)
			with open('.passwd', 'w+') as f:
				f.write('%s:x:%d:%d:unknown:%s:%s\n' % (getpass.getuser(), os.getuid(), os.getgid(), sandbox_dir + '/' + getpass.getuser(), os.environ['SHELL']))
			mountfile.write('/etc/passwd %s/.passwd\n' % (sandbox_dir))

			logging.debug("Construct a fake acl file: .__acl, add .__acl into %s", mountfile_path)
			with open('.__acl', 'w+') as acl_file:
				acl_file.write('%s rwlax\n' % getpass.getuser())

			#getpass.getuser() returns the login name of the user
			os.makedirs(getpass.getuser())

		existed_group = In_local_group()
		if existed_group == 'yes':
			logging.debug("Add /etc/group into %s", mountfile_path)
			mountfile.write('/etc/group /etc/group\n')
		else:
			logging.debug("Construct a fake group file: .group, add .group into %s", mountfile_path)
			with open('.group', 'w+') as f:
				f.write('%s:x:%d:%d\n' % (grp.getgrgid(os.getgid())[0], os.getgid(), os.getuid()))
			mountfile.write('/etc/group %s/.group\n' % (sandbox_dir))

		#add /var/run/nscd/socket into mountlist
		mountfile.write('/var/run/nscd/socket ENOENT\n')
		dest = "%s/cache/cctools-4.4.0-%s-%s/bin" % (os.path.dirname(sandbox_dir), host_linux_distro, hardware_platform)
		logging.debug("Add cctools binary (%s) into %s", dest, mountfile_path)
		mountfile.write(dest + ' ' + dest + '\n')

		logging.debug("Add %s into %s", os_image_dir + "/special_files", mountfile_path)
		with open(os_image_dir + "/special_files", "rb") as f:
			for line in f:
				mountfile.write(line)

		#add the input_dict into mountflie 
		logging.debug("Add items from input_dict into %s", mountfile_path)
		for key in input_dict:
			mountfile.write(key + " " + input_dict[key] + "\n")

		if cvmfs_siteinfo_mountpoint == '':
			logging.debug('cvmfs_siteinfo_mountpoint is null')
		else:
			mountfile.write(cvmfs_siteinfo_mountpoint + '\n')
			logging.debug('cvmfs_siteinfo_mountpoint is not null: %s', cvmfs_siteinfo_mountpoint)
	return mountfile_path

""" Add the input files into the mountfile
"""
def add_inputs_to_mountfile(sandbox_dir, input_dict, cvmfs_siteinfo_mountpoint, mount_dict):
	mountfile_path = sandbox_dir + "/mountlist"		
	with open(mountfile_path, "wb") as f:
		#add the input_dict into mountflie 
		for key in input_dict:
			f.write(key + " " + input_dict[key] + "\n")
		for key in mount_dict:
			f.write(key + " " + mount_dict[key] + "\n")
			f.write(mount_dict[key] + " " + mount_dict[key] + "\n")

		if cvmfs_siteinfo_mountpoint == '':
			logging.debug('cvmfs_siteinfo_mountpoint is null')
		else:
			f.write(cvmfs_siteinfo_mountpoint + '\n')
			logging.debug('cvmfs_siteinfo_mountpoint is not null: %s', cvmfs_siteinfo_mountpoint)

	return mountfile_path

""" Read env_list and save all the environment variables into a dictionary
Return: a dictionary which includes all the environment variables from env_list  
"""
def construct_env(sandbox_dir, os_image_dir):
	with open(os_image_dir + "/env_list", "rb") as f:
		env_dict = {}
		for line in f:
			index = line.find("=")
			key = line[:index] 
			value = line[(index+1):-1] 
			env_dict[key] = value	
		env_dict['PWD'] = sandbox_dir
		return env_dict

""" Check whether a docker images exists on the local machine or not.
"""
def has_docker_image(hardware_platform, distro_name, distro_version):
	name = "%s-%s-%s" %(distro_name, distro_version, hardware_platform)
	cmd = 'docker images ' + name
	logging.debug("Start to run the command: %s", cmd)
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	p_status = p.wait()
	while True:
		line = p.stdout.readline()
		if line != '':
			line = line.rstrip()	
			if line[:len(name)] == name:
				return 'yes'
		else:
			return 'no'

""" Create a docker image based on the cached os image directory
"""
def create_docker_image(sandbox_dir, hardware_platform, distro_name, distro_version):
	name = "%s-%s-%s" %(distro_name, distro_version, hardware_platform)
	location = os.path.dirname(sandbox_dir) + '/cache/' + name
	#docker container runs as root user, so use the owner option of tar command to set the owner of the docker image
	cmd = 'cd ' + location + '; tar --owner=root -c .|docker import - ' + name + '; cd -'
	func_call(cmd)

""" Construct directory mount list and file mount list for chroot. chroot requires the target mountpoint must be created within the chroot jail.
Return: a tuple includes the directory mount list and the file mount list
"""
def construct_chroot_mount_dict(sandbox_dir, output_dir, input_dict, need_separate_rootfs, os_image_dir, is_cvmfs_parrot_app, mount_dict):
	dir_dict = {}
	file_dict = {}
	logging.debug("need_separate_rootfs: %d", need_separate_rootfs)
	if need_separate_rootfs == 1:
		logging.debug("Add %s into dir_dict of chroot", os_image_dir + "/common-mountlist")
		with open(os_image_dir + "/common-mountlist") as f:
			for line in f:
				index = line.find(' ')
				item = line[:index]
				dir_dict[item] = item	

		#special_files includes all the paths of the files which includes all the file paths of special types (block, character, socket, pipe)
		logging.debug("Add %s into dir_dict of chroot", os_image_dir + "/special_files")
		with open(os_image_dir + "/special_files") as f:
			for line in f:
				index = line.find(' ')
				item = line[:index]
				if os.path.exists(item):
					file_dict[item] = item	
	
	if is_cvmfs_parrot_app == 1:
		cctools_path = os.path.dirname(sandbox_dir) + '/cache/cctools-4.4.0-x86_64-' + host_linux_distro 
		logging.debug("Add cctools binary (%s) into dir_dict of chroot", cctools_path)
		dir_dict[cctools_path] = cctools_path
	
	logging.debug("Add sandbox_dir and output_dir into dir_dict of chroot")	
	dir_dict[sandbox_dir] = sandbox_dir
	dir_dict[output_dir] = output_dir 
	for key in mount_dict:
		if key != '/':
			dir_dict[mount_dict[key]] = key

	logging.debug("Add /etc/passwd /etc/group /etc/hosts /etc/resolv.conf into file_dict of chroot")
	file_dict['/etc/passwd'] = '/etc/passwd'
	file_dict['/etc/group'] = '/etc/group'
	file_dict['/etc/hosts'] = '/etc/hosts'
	file_dict['/etc/resolv.conf'] = '/etc/resolv.conf'

	logging.debug("Add input_dict into file_dict of chroot")
	for key in input_dict:
		value = input_dict[key]
		mode = os.lstat(value).st_mode
		if S_ISDIR(mode):
			dir_dict[value] = key
		else:
			file_dict[value] = key

	logging.debug("dir_dict:")
	logging.debug(dir_dict)
	logging.debug("file_dict:")
	logging.debug(file_dict)
	return (dir_dict, file_dict)

""" Create each target mountpoint under the cached os image directory, `mount --bind`
"""
def chroot_mount_bind(dir_dict, file_dict, sandbox_dir, need_separate_rootfs, hardware_platform, distro_name, distro_version):
	logging.debug("Use mount --bind to redirect mountpoints")
	if need_separate_rootfs == 1:
		os_image_name = "%s-%s-%s" %(distro_name, distro_version, hardware_platform)
		os_image_path = os.path.dirname(sandbox_dir) + '/cache/' + os_image_name
	else:
		os_image_path = '/'
	#mount --bind -o ro hostdir sandboxdir
	for key in dir_dict:
		if key == '/cvmfs/cms.cern.ch':
			jaildir = '%s%s/cache/cvmfs/cms.cern.ch/SITECONF/local' % (os_image_path, os.path.dirname(sandbox_dir))
			hostdir = '%s/cache/cvmfs/cms.cern.ch/SITECONF/local' % (os.path.dirname(sandbox_dir))
		else:	
			jaildir = '%s%s' % (os_image_path, dir_dict[key]) 
			hostdir = key
		if not os.path.exists(jaildir):
			os.makedirs(jaildir)
		cmd = 'mount --bind -o ro %s %s' % (hostdir, jaildir)
		func_call(cmd)

	for key in file_dict:
		jailfile = '%s%s' % (os_image_path, file_dict[key]) 
		hostfile = key
		if not os.path.exists(jailfile):
			d = os.path.dirname(jailfile)
			if not os.path.exists(d):
				os.makedirs(d)
			with open(jailfile, 'w+') as f:
				pass
		cmd = 'mount --bind -o ro %s %s' % (hostfile, jailfile)
		func_call(cmd)

""" Remove all the created target mountpoints within the cached os image directory
It is not necessary to change the mode of the output dir, because only the root user can use the chroot method.
"""
def chroot_post_process(dir_dict, file_dict, sandbox_dir, need_separate_rootfs, hardware_platform, distro_name, distro_version):
	logging.debug("post process of chroot")
	if need_separate_rootfs == 1:
		os_image_name = "%s-%s-%s" %(distro_name, distro_version, hardware_platform)
		os_image_path = os.path.dirname(sandbox_dir) + '/cache/' + os_image_name
	else:
		os_image_path = '/'

	#file_dict must be processed ahead of dir_dict, because we can not umount a directory if there is another mountpoints created for files under it.
	for key in file_dict:
		jailfile = '%s%s' % (os_image_path, file_dict[key]) 
		if os.path.exists(jailfile):
			cmd = 'umount -f %s' % (jailfile)
			func_call(cmd)

	for key in dir_dict:
		if key == '/cvmfs/cms.cern.ch':
			jaildir = '%s%s/cache/cvmfs/cms.cern.ch/SITECONF/local' % (os_image_path, os.path.dirname(sandbox_dir))
		else:	
			jaildir = '%s%s' % (os_image_path, dir_dict[key]) 
		if os.path.exists(jaildir):
			cmd = 'umount -f %s' % (jaildir)
			func_call(cmd)
			#remove all the empty ancestor directory
			parent_dir = jaildir
			mode = os.lstat(parent_dir).st_mode
			if S_ISDIR(mode):
				while len(os.listdir(parent_dir)) == 0:
					os.rmdir(parent_dir)
					parent_dir = os.path.dirname(parent_dir)

""" Run user task directory on the host's rootfs
"""
def execute_task_host_rootfs(sandbox_dir, env_dict, batch_type, user_cmd, is_cvmfs_parrot_app, parrot_submit_path, parrot_submit_file):
	logging.debug("Close parrot submit file (%s)", parrot_submit_path)
	parrot_submit_file.close()
	#need to construct the parrot_submit.sh
	logging.debug("is_cvmfs_parrot_app: %d", is_cvmfs_parrot_app)
	if is_cvmfs_parrot_app == 1:
		cmd = "/bin/sh " + parrot_submit_path
		func_call_output_withenv(cmd, env_dict, sandbox_dir)
	else:
		if batch_type == 'parrot':
			cmd = "parrot_run --no-set-foreground " + user_cmd[0]
		elif batch_type == 'chroot':
			cmd = 'chroot / /bin/sh -c "cd %s; %s"' %(sandbox_dir, user_cmd[0]) 
		print "cmd:", cmd
		func_call_output_withenv(cmd, env_dict, sandbox_dir)


""" Run user's task with the help of the sandbox techniques, which currently inculde chroot, parrot, docker.
"""
def workflow_repeat(sandbox_dir, batch_type, output_dir, input_dict, env_para_dict, user_cmd, hardware_platform, host_linux_distro, distro_name, distro_version, need_separate_rootfs, os_image_dir, host_cctools_path, parrot_submit_path, parrot_submit_file, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict):
	#sandbox_dir will be the home directory of the sandbox
	print 'Executing the application ....'
	logging.debug("chdir(%s)", sandbox_dir)
	os.chdir(sandbox_dir)
	#at this point, all the software should be under the cache dir, all the mountpoint of the software should be in mount_dict 
	if batch_type == "chroot":
		logging.debug("chroot execution engine")
		logging.debug("need_separate_rootfs: %d", need_separate_rootfs)
		if need_separate_rootfs == 1:
			#traverse the common-mountlist file to create the mountpoint and mount --bind -o ro
			#traverse the special file to create the mountpoint and mount --bind
			#remount /etc/passwd /etc/group /etc/hosts /etc/resolv.conf
			(dir_dict, file_dict) = construct_chroot_mount_dict(sandbox_dir, output_dir, input_dict, 1, os_image_dir, is_cvmfs_parrot_app, mount_dict)
			chroot_mount_bind(dir_dict, file_dict, sandbox_dir, 1, hardware_platform, distro_name, distro_version)
			#redirect outputdir
			logging.debug("Construct environment variables ....")
			env_dict = construct_env(sandbox_dir, os_image_dir)
			logging.debug("Add software binary into PATH")
			extra_path = collect_software_bin(host_cctools_path, mount_dict)
			env_dict['PATH'] = '%s:%s' % (env_dict['PATH'], extra_path[:-1])
			logging.debug("Add env_para_dict into environment variables")
			for key in env_para_dict:
				env_dict[key] = env_para_dict[key]

			#run user_cmd
			os_image_name = "%s-%s-%s" %(distro_name, distro_version, hardware_platform)
			os_image_path = os.path.dirname(sandbox_dir) + '/cache/' + os_image_name
			logging.debug("is_cvmfs_parrot_app: %d", is_cvmfs_parrot_app)
			if is_cvmfs_parrot_app == 1:
				parrot_submit_file.close()
				sub_cmd = "/bin/sh " + parrot_submit_path
				cmd = 'env; strace -o strace.log chroot %s /bin/sh -c "cd %s; %s"' % (os_image_path, sandbox_dir, user_cmd[0])
			else:
				cmd = 'chroot %s /bin/sh -c "cd %s; %s"' % (os_image_path, sandbox_dir, user_cmd[0])
			func_call_output_withenv(cmd, env_dict, sandbox_dir)
			
			#post-process to clean up
			chroot_post_process(dir_dict, file_dict, sandbox_dir, 1, hardware_platform, distro_name, distro_version)
		else:
			(dir_dict, file_dict) = construct_chroot_mount_dict(sandbox_dir, output_dir, input_dict, 0, os_image_dir, is_cvmfs_parrot_app, mount_dict)
			chroot_mount_bind(dir_dict, file_dict, sandbox_dir, 0, hardware_platform, distro_name, distro_version)
			logging.debug("Construct environment variables ....")
			env_dict = os.environ
			logging.debug("Add software binary into PATH")
			extra_path = collect_software_bin(host_cctools_path, mount_dict)
			env_dict['PATH'] = '%s:%s' % (env_dict['PATH'], extra_path[:-1])
			logging.debug("Add env_para_dict into environment variables")
			for key in env_para_dict:
				env_dict[key] = env_para_dict[key]
			execute_task_host_rootfs(sandbox_dir, env_dict, 'chroot', user_cmd, is_cvmfs_parrot_app, parrot_submit_path, parrot_submit_file)
			chroot_post_process(dir_dict, file_dict, sandbox_dir, 0, hardware_platform, distro_name, distro_version)
		#rename the sandbox_dir to output_dir
		logging.debug("Rename sandbox_dir (%s) to output_dir (%s)", sandbox_dir, output_dir)
		os.rename(sandbox_dir, output_dir)
	elif batch_type == "docker":
		logging.debug("docker execution engine")
		logging.debug("need_separate_rootfs: %d", need_separate_rootfs)
		if need_separate_rootfs == 1:
			if has_docker_image(hardware_platform, distro_name, distro_version) == 'no':
				logging.debug("Start to construct a docker image from the os image")
				create_docker_image(sandbox_dir, hardware_platform, distro_name, distro_version)
				logging.debug("Finish constructing a docker image from the os image")

			logging.debug("Add a volume item (%s:%s)", sandbox_dir, sandbox_dir)
			#-v /home/hmeng/umbrella_test/output:/home/hmeng/umbrella_test/output 
			volume_output = " -v %s:%s " % (sandbox_dir, sandbox_dir)
			#-v /home/hmeng/umbrella_test/cache/git-x86_64-redhat5:/software/git-x86_64-redhat5/ 
			logging.debug("Start to construct other volumes from input_dict")
			volume_parameters = construct_docker_volume(sandbox_dir, input_dict, is_cvmfs_parrot_app, mount_dict)

			#-e "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/software/git-x86_64-redhat5/bin" 
			logging.debug("Set the environment variables ....")
			path_env = obtain_path(os_image_dir, mount_dict) 
			other_envs = transfer_env_para_docker(env_para_dict)
			docker_image_name = "%s-%s-%s" %(distro_name, distro_version, hardware_platform)
			#by default, docker executes user_cmd as the root user, `chown` is used to change the owner of the output dir to be the user who calls `umbrella`
			chown_cmd = 'chown -R %d:%d %s' % (os.getuid(), os.getgid(), sandbox_dir)
			#to count the post processing time, this cmd is split into two commands
			container_name = "container_%s" % docker_image_name
			#do not enable `-i` and `-t` option of Docker, it will fail when condor execution engine is chosen.
			if is_cvmfs_parrot_app == 1:
				parrot_submit_file.close()
				#cmd = 'docker run --rm --name %s %s %s -e "PATH=%s" %s %s /bin/sh -c "cd %s; %s>docker_stdout 2>docker_stderr; %s"' % (container_name, volume_output, volume_parameters, path_env, other_envs, docker_image_name, sandbox_dir, user_cmd[0], chown_cmd)
				cmd = 'docker run --rm %s %s -e "PATH=%s" %s %s /bin/sh -c "cd %s; %s; %s"' % (volume_output, volume_parameters, path_env, other_envs, docker_image_name, sandbox_dir, user_cmd[0], chown_cmd)
			else:
				cmd = 'docker run --rm %s %s -e "PATH=%s" %s %s /bin/sh -c "cd %s; %s; %s"' % (volume_output, volume_parameters, path_env, other_envs, docker_image_name, sandbox_dir, user_cmd[0], chown_cmd)
			func_call(cmd)
			logging.debug("Rename the sandbox dir(%s) to the output directory(%s)", sandbox_dir, output_dir)
			cmd = 'cp -r %s/* %s' % (sandbox_dir, output_dir)
			func_call(cmd)
			shutil.rmtree(sandbox_dir)
		else:
			#if a separate rootfs is not needed to execute the user's cmd, should forcely use other execution engine to run the user cmd.
			logging.debug("Docker execution engine can only be used when a separate rootfs is needed.")
			sys.exit("Docker execution engine can only be used when a separate rootfs is needed.\n")
	elif batch_type == "parrot":
		logging.debug("local execution engine")
		logging.debug("need_separate_rootfs: %d", need_separate_rootfs)
		if need_separate_rootfs == 1:
			logging.debug("Construct environment variables ....")
			env_dict = construct_env(sandbox_dir, os_image_dir)
			logging.debug("Construct mounfile ....")
			env_dict['PARROT_MOUNT_FILE'] = construct_mountfile(sandbox_dir, input_dict, hardware_platform, host_linux_distro, os_image_dir, cvmfs_siteinfo_mountpoint, mount_dict)
		#here, setting the linker will cause strange errors.
			logging.debug("Construct dynamic linker path ....")
			env_dict['PARROT_LDSO_PATH'] = get_linker_path(hardware_platform, os_image_dir) 
			env_dict['USER'] = getpass.getuser()
			env_dict['HOME'] = sandbox_dir + '/' + getpass.getuser()
			logging.debug("Add software binary into PATH")
			extra_path = collect_software_bin(host_cctools_path, mount_dict)
			env_dict['PATH'] = '%s%s' % (extra_path, env_dict['PATH'])

			if has_parrot_localfile == 0:
				parrot_submit_file.write("#!/bin/sh\n")

				dest = "%s/cache/cctools-4.4.0-%s-%s" % (os.path.dirname(sandbox_dir), host_linux_distro, hardware_platform)
				parrot_submit_file.write(dest + '/bin/parrot_run --no-set-foreground ')
				parrot_submit_file.write(user_cmd[0] + '\n')
				
			parrot_submit_file.close()
			cmd = "/bin/sh " + parrot_submit_path
			func_call_output_withenv(cmd, env_dict, sandbox_dir)

		else:
			env_dict = os.environ
			env_dict['PARROT_MOUNT_FILE'] = add_inputs_to_mountfile(sandbox_dir, input_dict, cvmfs_siteinfo_mountpoint, mount_dict)
			for key in env_para_dict:
				env_dict[key] = env_para_dict[key]
			logging.debug("Add software binary into PATH")
			extra_path = collect_software_bin(host_cctools_path, mount_dict)
			#print "extra_path: ", extra_path
			if 'PATH' not in env_dict: #if we run umbrella on Condor, Condor will not set PATH by default.
				env_dict['PATH'] = '/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin'
				logging.debug("PATH is empty, forcely set it to be %s", env_dict['PATH'])
			env_dict['PATH'] = '%s%s' % (extra_path, env_dict['PATH'])

			execute_task_host_rootfs(sandbox_dir, env_dict, 'parrot', user_cmd, is_cvmfs_parrot_app, parrot_submit_path,  parrot_submit_file)
		logging.debug("Rename sandbox_dir (%s) to output_dir (%s)", sandbox_dir, output_dir)
		os.rename(sandbox_dir, output_dir)
	else:
		pass

""" the process of specification when condor execution engine is chosen
"""
def condor_process(spec_path, spec, spec_path_basename, sandbox_dir, output_dir, input_list_origin, user_cmd, cwd_setting):
	if not os.path.exists(sandbox_dir):
		os.makedirs(sandbox_dir)

	if spec.has_key("hardware") and spec["hardware"] and spec.has_key("kernel") and spec["kernel"] and spec.has_key("os") and spec["os"]:
		logging.debug("Setting the global environment parameters (hardware, kernle and os) according to the specification file ....")
		hardware_platform, cpu_cores, memory_size, disk_size, kernel_name, kernel_version, linux_distro, distro_name, distro_version, os_id = env_parameter_init(spec["hardware"], spec["kernel"], spec["os"])
	else:
		logging.critical("this specification is not complete! You must have a hardware section, a kernel section and a os section!")
		sys.exit("this spec has no hardware section\n")

	condor_submit_path = sandbox_dir + "/condor_task.submit"

	transfer_inputs = ''
	new_input_options = ''
	logging.debug("Transform input_list_origin into condor attributes ....")
	for item in input_list_origin:
		index_equal = item.find('=')
		access_path = item[:index_equal]
		actual_path = item[(index_equal+1):]
		transfer_inputs += ',%s' % (actual_path)
		new_input_options += '%s=%s,' % (access_path, os.path.basename(actual_path))
	if new_input_options[-1] == ',':
		new_input_options = new_input_options[:-1]
	logging.debug("transfer_input_files: %s, %s", spec_path, transfer_inputs)
	logging.debug("The new_input_options of Umbrella: %s", new_input_options)

	condor_output_dir = os.path.basename(output_dir)
	condor_log_path = sandbox_dir + '/condor_task.log'
	
	condor_submit_file = open(condor_submit_path, "w+")
	condor_submit_file.write('universe = vanilla\n')
	condor_submit_file.write('executable = umbrella\n')
	condor_submit_file.write('arguments = "-T local -c %s -l condor_umbrella -i \'%s\' -o %s --log condor_umbrella.log run \'%s\'"\n' % (spec_path_basename, new_input_options, condor_output_dir, user_cmd[0]))
	condor_submit_file.write('transfer_input_files = umbrella, %s%s\n' % (spec_path, transfer_inputs))
	condor_submit_file.write('transfer_output_files = %s\n' % condor_output_dir)
	if linux_distro == "redhat5":
		condor_submit_file.write('requirements = TARGET.Arch == "%s" && TARGET.OpSys == "%s" && TARGET.OpSysAndVer == "redhat6"\n' % (hardware_platform, kernel_name))
	else:
		#condor_submit_file.write('requirements = TARGET.Arch == "%s" && TARGET.OpSys == "%s" && TARGET.OpSysAndVer == "%s" && TARGET.has_docker == true\n' % (hardware_platform, kernel_name, linux_distro))
		condor_submit_file.write('requirements = TARGET.Arch == "%s" && TARGET.OpSys == "%s" && TARGET.OpSysAndVer == "%s"\n' % (hardware_platform, kernel_name, linux_distro))
	condor_submit_file.write('environment = PATH=/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin\n')

#	sandbox_id = os.path.basename(sandbox_dir)
#	condor_submit_file.write('output = condor_stdout_%s\n' % sandbox_id) 
#	condor_submit_file.write('error = condor_stderr_%s\n' % sandbox_id)
#	condor_submit_file.write('log = condor_log_%s\n' % sandbox_id)

	condor_submit_file.write('output = %s/condor_stdout\n' % sandbox_dir) 
	condor_submit_file.write('error = %s/condor_stderr\n' % sandbox_dir)
	condor_submit_file.write('log = %s\n' % condor_log_path)

	condor_submit_file.write('should_transfer_files = yes\n')
	condor_submit_file.write('when_to_transfer_output = on_exit\n')
	condor_submit_file.write('queue\n')
	condor_submit_file.close()

	#submit condor job
	cmd = 'condor_submit ' + condor_submit_path
	func_call(cmd)
	#keep tracking whether condor job is done

#	print "Waiting for the job is done ..."
#	logging.debug("Waiting for the job is done ...")
#	cmd = 'condor_wait %s' % condor_log_path 
#	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
#	p_status = p.wait()
#	logging.debug("the condor jos is done, put the output back into the output directory!")
#	print "the condor jos is done, put the output back into the output directory!"
#	#check until the condor job is done, post-processing (put the output back into the output directory)
#	os.rename(condor_output_dir, output_dir)
#	#copy all the stuff inside the sandbox_dir into output)dir, and then remove the sandbox_dir
#	cmd = 'cp -r %s/* %s' % (sandbox_dir, output_dir)
#	func_call(cmd)
#	shutil.rmtree(sandbox_dir)

''' Compare the required hardware configurations with each instance type, and return the first matched instance type, return 'no' if no matched instance type exist.
Note: We can rank each instance type in the future, so that in the case of multiple matches exit, the closest matched instance type is returned.
'''
def decide_instance_type(cpu_cores, memory_size, disk_size, instances):
	cpu_cores = int(cpu_cores)
	memory_size = int(memory_size[:-2])
	disk_size = int(disk_size[:-2])
	for item in instances:
		j = instances[item]
		inst_mem = int(j["memory"][:-2])
		inst_disk = int(j["disk"][:-2])
		if cpu_cores <= int(j["cores"]) and memory_size <= inst_mem and disk_size <= inst_disk:
			return item
	return 'no' 

def ec2_process(spec_path, spec, packages_path, packages, ec2_path, ec2_json, ssh_key, key_pair, security_group, output_dir, batch_type, input_list, input_list_origin, env_options, user_cmd, cwd_setting):
	if spec.has_key("hardware") and spec["hardware"] and spec.has_key("kernel") and spec["kernel"] and spec.has_key("os") and spec["os"]:
		hardware_platform, cpu_cores, memory_size, disk_size, kernel_name, kernel_version, linux_distro, distro_name, distro_version, os_id = env_parameter_init(spec["hardware"], spec["kernel"], spec["os"])
	else:
		sys.exit("this spec has no hardware section!\n")

	#According to the given specification file, the AMI and the instance type can be identified. os and arch can be used to decide the AMI; cores, memory and disk can be used to decide the instance type.
	#decide the AMI according to (distro_name, distro_version, hardware_platform)
	name = '%s-%s-%s' % (distro_name, distro_version, hardware_platform)
	if ec2_json.has_key(name):
		if os_id == '':
			for item in ec2_json[name]:
				logging.debug("The AMI information is: ")
				logging.debug(ec2_json[name][item])
				ami = ec2_json[name][item]['ami']
				user_name = ec2_json[name][item]['user']
				break
		else:
			if ec2_json[name].has_key(os_id):	
				logging.debug("The AMI information is: ")
				logging.debug(ec2_json[name][os_id])
				ami = ec2_json[name][os_id]['ami']
				user_name = ec2_json[name][os_id]['user']
			else:
				logging.critical("%s with the id <%s> is not in the ec2 json file (%s).", name, os_id, ec2_path)
				sys.exit("%s with the id <%s> is not in the ec2 json file (%s)." % (name, os_id, ec2_path))
	else:
		logging.critical("%s is not in the ec2 json file (%s).", name, ec2_path)
		sys.exit("%s is not in the ec2 json file (%s).\n" % (name, ec2_path))

	#decide the instance type according to (cores, memory, disk)
	instances = ec2_json["instances"]
	r = decide_instance_type(cpu_cores, memory_size, disk_size, instances)
	if r == 'no':
		logging.critical("No matched instance type.")
		sys.exit("No matched instance type.\n")
	else:
		logging.debug("the matched instance type exists: %s", r)

	print ami, user_name, r, key_pair, security_group, ssh_key
	
	#start the instance and obtain the instance id
	instance_id = get_instance_id(ami, r, key_pair, security_group)
	logging.debug("Start the instance and obtain the instance id: ", instance_id)

	#get the public DNS of the instance_id
	public_dns = get_public_dns(instance_id)
	logging.debug("Get the public DNS of the instance_id: ", public_dns)

	#install wget on the instance	
	logging.debug("Install wget on the instance")
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i %s %s@%s \'yum -y install wget\'' % (ssh_key, user_name, public_dns)
	func_call(cmd)

	logging.debug("Install python 2.6.9 on the instance.")
	python_name = 'python-2.6.9-%s-%s' % (linux_distro, hardware_platform)
	python_item = package_search(packages, python_name, '')
	python_url = python_item["source"][0] #get the url of python
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i %s %s@%s  \'wget %s\'' % (ssh_key, user_name, public_dns, python_url)
	func_call(cmd)

	scheme, netloc, path, query, fragment = urlparse.urlsplit(python_url)
	python_url_filename = os.path.basename(path)
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i %s %s@%s  \'tar zxvf %s\'' % (ssh_key, user_name, public_dns, python_url_filename)
	func_call(cmd)

	#scp umbrella, packages.json and input files to the instance 
	logging.debug("scp relevant files into the HOME dir of the instance.")
	input_file_string = ''
	for input_file in input_list:
		input_file_string += input_file + ' ' 
	cmd = 'scp -i %s umbrella %s %s %s %s@%s:' % (ssh_key, spec_path, packages_path, input_file_string, user_name, public_dns)
	func_call(cmd)

	#change the --inputs option to put all the inputs directory in the home dir of the instance
	logging.debug("change the --inputs option to put all the inputs directory in the home dir of the instance")	
	new_input_options = ''
	logging.debug("Transform input_list_origin ....")
	for item in input_list_origin:
		index_equal = item.find('=')
		access_path = item[:index_equal]
		actual_path = item[(index_equal+1):]
		new_input_options += '%s=%s,' % (access_path, os.path.basename(actual_path))
	if new_input_options[-1] == ',':
		new_input_options = new_input_options[:-1]
	logging.debug("The new_input_options of Umbrella: %s", new_input_options) #--inputs option
	
	#execute the command on the instance 
	logging.debug("Execute the command on the instance ...")
	if env_options == '':
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i %s %s@%s \'%s/bin/python umbrella -T local -c %s -l ec2_umbrella -o output -i \'%s\'  -p %s run \'%s\'' % (ssh_key, user_name, public_dns, python_name, os.path.basename(spec_path), new_input_options, os.path.basename(packages_path), user_cmd[0])
	else:
		cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i %s %s@%s \'%s/bin/python umbrella -T local -c %s -l ec2_umbrella -o output -i \'%s\' -p %s -e %s run \'%s\'' % (ssh_key, user_name, public_dns, python_name, os.path.basename(spec_path), new_input_options, os.path.basename(packages_path), env_options, user_cmd[0])
	func_call(cmd)

	#postprocessing
	logging.debug("Create a tarball for the output dir on the instance.")
	cmd = 'ssh -o ConnectionAttempts=5 -o StrictHostKeyChecking=no -o ConnectTimeout=60 -i %s %s@%s \'tar cvzf output.tar.gz output\'' % (ssh_key, user_name, public_dns)
	func_call(cmd)

	logging.debug("The instance returns the output.tar.gz to the local machine.")
	cmd = 'scp -i %s %s@%s:output.tar.gz .' % (ssh_key, user_name, public_dns)
	func_call(cmd)

	if not os.path.exists(output_dir):
		os.makedirs(output_dir)

	logging.debug("Uncompress output.tar.gz.")
	cmd = 'tar zxvf output.tar.gz'
	func_call(cmd)
	logging.debug("Rename output to the output_dir (%s).", output_dir)
	#os.rename('output', output_dir)

""" Create the execution environment specified in the specification file and run the task on it.
"""
def specification_process(spec_json, sandbox_dir, behavior, packages_json, batch_type, output_dir, input_dict, env_para_dict, user_cmd, cwd_setting):
	#copying input files is expensive, so mounting mechanism based on redirection the access_path to the actual_path is a better solution
	#copy all the input files into the sandbox	
#	for input_file in input_list: 
#		shutil.copy(input_file, sandbox_dir)

	#if batch_type is local, download parrot, download SITEINFO, create a clean environment, do the experiment.
	#if batch_type is condor, create condor submit file, submit condor job.
	if spec_json.has_key("hardware") and spec_json["hardware"] and spec_json.has_key("kernel") and spec_json["kernel"] and spec_json.has_key("os") and spec_json["os"]:
		logging.debug("Setting the global environment parameters (hardware, kernle and os) according to the specification file ....")
		hardware_platform, cpu_cores, memory_size, disk_size, kernel_name, kernel_version, linux_distro, distro_name, distro_version, os_id = env_parameter_init(spec_json["hardware"], spec_json["kernel"], spec_json["os"])
	else:
		logging.critical("this specification is not complete! You must have a hardware section, a kernel section and a os section!")
		sys.exit("this specification is not complete! You must have a hardware section, a kernel section and a os section!\n")

	host_linux_distro, parrot_submit_path, parrot_submit_file = env_check(sandbox_dir, batch_type, hardware_platform, cpu_cores, memory_size, disk_size, kernel_name, kernel_version)
	
	need_separate_rootfs = 0
	os_image_dir = ''
	if linux_distro != host_linux_distro or batch_type == 'docker':
		print "The required linux distro specified in the specification is %s; the linux distro of the host machine is %s. The %s os images will be downloaded." % (linux_distro, host_linux_distro, linux_distro)
		logging.debug("The required linux distro specified in the specification is %s; the linux distro of the host machine is %s. The %s os images will be downloaded.", linux_distro, host_linux_distro, linux_distro)
		need_separate_rootfs = 1
		item = '%s-%s-%s' % (distro_name, distro_version, hardware_platform)
		dest = "%s/cache/%s" % (os.path.dirname(sandbox_dir), item)
		os_image_dir = dest
		logging.debug("A separate OS (%s) is needed!", dest)
	
	has_parrot_localfile = 0
	is_cvmfs_parrot_app = 0
	cvmfs_siteinfo_mountpoint = ''
	mount_dict = {}
	host_cctools_path = '' #the path of the cctools binary which is compatible with the host machine under the umbrella cache 

	if spec_json.has_key("software") and spec_json["software"]:
		host_cctools_path, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict = software_install(os_id, spec_json["software"], packages_json, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, distro_name, distro_version, parrot_submit_file, need_separate_rootfs, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict, host_cctools_path)
	else:
		logging.debug("this spec does not have software section!")
		host_cctools_path, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict = software_install(os_id, "", packages_json, sandbox_dir, batch_type, user_cmd, cwd_setting, hardware_platform, host_linux_distro, distro_name, distro_version, parrot_submit_file, need_separate_rootfs, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict, host_cctools_path)

	if spec_json.has_key("data") and spec_json["data"]:
		data_install(spec_json["data"], packages_json, sandbox_dir, mount_dict)
		pass
	else:
		logging.debug("this spec does not have dat section!")
	
	workflow_repeat(sandbox_dir, batch_type, output_dir, input_dict, env_para_dict, user_cmd, hardware_platform, host_linux_distro, distro_name, distro_version, need_separate_rootfs, os_image_dir, host_cctools_path, parrot_submit_path, parrot_submit_file, has_parrot_localfile, is_cvmfs_parrot_app, cvmfs_siteinfo_mountpoint, mount_dict)

'''Check whether an executable exists or not. If yes, return 0; if not, return -1
'''
def dependency_check(item):
	print "dependency check -- ", item, " "
	cmd = 'which %s' % item
	stdout, stderr = func_call(cmd)
	if stdout:
		logging.debug("command `which %s` found.", item)
		print "command `which %s` found." % item
		return 0
	else:
		logging.debug("command `which %s` failed.", item)
		print "command `which %s` failed." % item
		return -1

""" Get the minimum integer for the sandbox name
Parameter path: the path of the localdir
Return: the minimum integer which is not occupied by the current directories under the path
"""
def get_sandbox_id(path):
	i = 1
	while(os.path.exists(path + '/' + str(i))):
		i = i + 1
	return i

""" Start one VM instance through Amazon EC2 command line interface and return the instance id.
Parameter image_id: the Amazon Image Identifier
Return the id of the started instance
"""
def get_instance_id(image_id, instance_type, key_pair, security_group):
	cmd = 'ec2-run-instances %s -t %s -k %s -g %s --associate-public-ip-address true' % (image_id, instance_type, key_pair, security_group)
	logging.debug("Starting an instance: %s", cmd)
	p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
	p_status = p.wait()
	while True:
		line = p.stdout.readline()
		if line != '':
			line = line.rstrip()	
			if line[:8] == 'INSTANCE':
				instance_id = line[9:19]
				return instance_id

""" Get the public dns of one VM instance from Amazon EC2, `ec2-run-instances` can not directly return the public dns of the instance, so this function is needed to check the result of `ec2-describe-instances` to obtain the public dns of the instance.
Parameter: the id of the VM instance
Return: the public dns of the instance
"""
def get_public_dns(instance_id):
	public_dns = ''
	while public_dns == None or public_dns == '' or public_dns == 'l':
		cmd = 'ec2-describe-instances ' + instance_id
		p = subprocess.Popen(cmd, stdout = subprocess.PIPE, shell = True)
		p_status = p.wait()
		while True:
			line = p.stdout.readline()
			if line != '':
				line = line.rstrip()	
				str1 = 'PRIVATEIPADDRESS' 
				if line[:16] == str1:
					index = line.find("ec2")
					public_dns = line[index:]
					break
	return public_dns

def main():
	parser = OptionParser(usage="usage: %prog [options] run \"command\"",
						version="%prog 1.0")
	parser.add_option("-c", "--config",
					action="store",
					default="./spec.json",
					help="The specification json file. (By default: spec.json)")
	parser.add_option("-l", "--localdir",
					action="store", 
					default="./umbrella_test",
					help="The path of directory used for all the cached data and all the sandboxes. (By default: ./umbrella_test)",)
	parser.add_option("-i", "--inputs",
					action="store", 
					default='',
					help="The path of input files in the format of access_path=actual_path. i.e, -i '/home/hmeng/file1=/tmp/file2'. access_path must be consistent with the semantics of the provided command, actual_path can be relative or absolute. (By default: '')",)
	parser.add_option("-e", "--env",
					action="store", 
					default='',
					help="The environment variable. I.e., -e 'PWD=/tmp'. (By default: '')")
	parser.add_option("-o", "--output",
					action="store", 
					default="./umbrella_output",
					help="The path of output. (By default: ./umbrella_output)",)
	parser.add_option("-T", "--batch_type",
					action="store", 
					default="parrot",
					choices=['local', 'parrot', 'chroot', 'docker', 'condor', 'ec2',],
					help="Batch system type, which can be local, parrot, chroot, docker, condor, ec2. (By default: local)",)
	parser.add_option("--packages",
					action="store", 
					default='./packages.json',
					help="The source of packages information. (By default: ./packages.json)",)
	parser.add_option("--ec2",
					action="store", 
					default='./ec2.json',
					help="The source of ec2 information. (By default: ./ec2.json)",)
	parser.add_option("--log",
					action="store", 
					default="./umbrella.log",
					help="The path of umbrella log file. (By default: ./umbrella.log)",)
	parser.add_option("-g", "--group",
					action="store", 
					help="the security group within which an instance should be run.",)
	parser.add_option("-k", "--key",
					action="store", 
					help="the name of the key pair to use when launching an instance.",)
	parser.add_option("--sshkey",
					action="store", 
					help="the name of the private key file to use when connecting to an instance.",)

	(options, args) = parser.parse_args()

	logfilename = options.log
	print "logfilename: ", logfilename
	logging.basicConfig(filename=logfilename, level=logging.DEBUG,
        format='%(asctime)s.%(msecs)d %(levelname)s %(module)s - %(funcName)s: %(message)s', datefmt="%Y-%m-%d %H:%M:%S")

	logging.debug("*******Welcome to Umbrella*******")
	logging.debug("Arguments: ")
	logging.debug(sys.argv)
	start = datetime.datetime.now()
	logging.debug("Check the validity of the command ....")
	if not args:
		logging.critical("You must provide the behavior and the command!")
		print "You must provide the behavior and the command!\n"
		parser.print_help()
		sys.exit()

	behavior = args[0]
	logging.debug("Check the validity of the behavior: %s", behavior)
	behavior_list = ["run"]
	if behavior not in behavior_list:
		logging.critical("%s is not supported by umbrella!", behavior)
		print behavior + " is not supported by umbrella!\n"
		parser.print_help()
		sys.exit()

	batch_type = options.batch_type
	logging.debug("Check the batch_type option: %s", batch_type)
	if batch_type == 'chroot':
		if getpass.getuser() != 'root':
			logging.critical("You must be root to use chroot method.")
			print 'You must be root to use chroot method.\n'
			parser.print_help()
			sys.exit()

	#get the absolute path of the localdir directory, which will cache all the data, and store all the sandboxes.
	#to allow the reuse the local cache, the localdir can be a dir which already exists.
	localdir = options.localdir
	localdir = os.path.abspath(localdir)
	logging.debug("Check the localdir option: %s", localdir)

	#get a sandbox number, which will become the name of the sandbox directory
	sandbox_id = get_sandbox_id(localdir)
	sandbox_dir = localdir + '/' + str(sandbox_id)
	logging.debug("Allocate %d as the sandbox ID, %s as the sanbox_dir", sandbox_id, sandbox_dir)
	
	if not os.path.exists(sandbox_dir):
		logging.debug("Create the sandbox_dir: %s", sandbox_dir)
		os.makedirs(sandbox_dir)

#	print sandbox_dir

	#transfer options.env into a dictionary, env_para_dict
	env_para = options.env
	env_para_dict = {}
	if env_para == '':
		logging.debug("The env option is null")
		env_para_list = ''
		env_para_dict = {}
	else:
		logging.debug("Process the env option: %s", env_para)
		env_para = re.sub('\s+', '', env_para).strip()
		env_para_list = env_para.split(',')
		for item in env_para_list:
			index = item.find('=')
			name = item[:index]	
			value = item[(index+1):]
			env_para_dict[name] = value
		logging.debug("the dictionary format of the env options (env_para_dict):")
		logging.debug(env_para_dict)

	spec_path = options.config
	spec_path_basename = os.path.basename(spec_path)
	logging.debug("Start to read the specification file: %s", spec_path)
	if not os.path.isfile(spec_path):
		logging.critical("The specification json file (%s) does not exist! Please refer the -c option.", spec_path)
		print "The specification json file does not exist! Please refer the -c option.\n"
		parser.print_help()
		sys.exit()

	with open(spec_path) as f: #python 2.4 does not support this syntax: with open () as
		spec_json = json.load(f)

		#if the spec file has environ seciton, merge the variables defined in it into env_para_dict
		if spec_json.has_key("environ") and spec_json["environ"]:
			logging.debug("The specification file has environ section, update env_para_dict ....")
			spec_env = spec_json["environ"]
			for key in spec_env:
				env_para_dict[key] = spec_env[key]
			logging.debug("env_para_dict:")
			logging.debug(env_para_dict)

#	print env_para_dict

	if 'PWD' in env_para_dict:
		cwd_setting = env_para_dict['PWD']
		logging.debug("CWD environment variable is set explicitly: %s", cwd_setting)
	else:
		cwd_setting = sandbox_dir
		logging.debug("CWD is not set explicitly, use sandbox_dir (%s) as CWD", cwd_setting)

	#get the absolute path of each input file
	input_files = options.inputs
	input_files = re.sub( '\s+', '', input_files).strip() #remove all the whitespaces within the inputs option

	input_list = []
	input_dict = {}

	if input_files == '':
		input_list_origin = ''
		input_list = []
		input_dict = {}
		logging.debug("the inputs options is null")
	else:
		logging.debug("The inputs option: %s", input_files)
		input_list_origin = input_files.split(',') 
		for item in input_list_origin:
			index = item.find('=')
			access_path = item[:index]
			actual_path = item[(index+1):]
			if access_path[0] != '/':
				access_path = os.path.join(cwd_setting, access_path)
			actual_path = os.path.abspath(actual_path)
			input_dict[access_path] = actual_path
			input_list.append(actual_path) #get the absolute path of each input file and add it into input_list
		logging.debug("The list version of the inputs option: ")
		logging.debug(input_list)
		logging.debug("The dict version of the inputs option: ")
		logging.debug(input_dict)

	#get the absolute path of each output file	
	output_dir = options.output
	output_dir = os.path.abspath(output_dir)

	if not os.path.exists(output_dir):
		logging.debug("create the output_dir: %s", output_dir)
		os.makedirs(output_dir)
	elif len(os.listdir(output_dir)) != 0:
		logging.critical("output_dir (%s) is not empty!", output_dir)
		sys.exit("%s is not empty! Please clean the output directory first or specify another directory!\n" % output_dir)
	else:
		pass

	#obtain packages.json	
	packages_path = options.packages
	packages_path = os.path.abspath(packages_path)
	logging.debug("Check the packages information file: %s", packages_path)

	if not os.path.exists(packages_path):
		path1 = packages_path
		url = 'http://ccl.cse.nd.edu/software/umbrella/database/packages.json'
		packages_path = '%s/packages.json' % (sandbox_dir)
		logging.debug("The provided packages info (%s) does not exist, download from %s into %s", path1, url, packages_path)
		url_download(url, packages_path)

	with open(packages_path) as f: #python 2.4 does not support this syntax: with open () as
		packages_json = json.load(f)

	user_cmd = args[1:]
	logging.debug("The user's command is: %s", user_cmd)

	if behavior in ["run"]:
#		user_name = 'root' #username who can access the VM instances from Amazon EC2
#		ssh_key = 'hmeng_key_1018.pem' #the pem key file used to access the VM instances from Amazon EC2
		if batch_type == "ec2":
			#obtain ec2.json
			ec2_path = options.ec2
			ec2_path = os.path.abspath(ec2_path)	
			logging.debug("Check the ec2 information file: %s", ec2_path)
	
			if not os.path.exists(ec2_path):
				path1 = ec2_path
				url = 'http://ccl.cse.nd.edu/software/umbrella/database/ec2.json'
				ec2_path = '%s/ec2.json' % (sandbox_dir)
				logging.debug("The provided ec2 info (%s) does not exist, download from %s into %s", path1, url, ec2_path)
				url_download(url, ec2_path)
		
			with open(ec2_path) as f: #python 2.4 does not support this syntax: with open () as
				ec2_json = json.load(f)

			key_pair = options.key
			security_group = options.group
			ssh_key = options.sshkey
				
			ec2_process(spec_path, spec_json, packages_path, packages_json, ec2_path, ec2_json, ssh_key, key_pair, security_group, output_dir, batch_type, input_list, input_list_origin, env_para, user_cmd, cwd_setting)
		elif batch_type == "condor":
			condor_process(spec_path, spec_json, spec_path_basename, sandbox_dir, output_dir, input_list_origin, user_cmd, cwd_setting)
		elif batch_type == "local":
			#first check whether Docker exists, if yes, use docker execution engine; if not, use parrot execution engine.
			if dependency_check('docker') == 0:
				logging.debug('docker exists, use docker execution engine')
				specification_process(spec_json, sandbox_dir, behavior, packages_json, 'docker', output_dir, input_dict, env_para_dict, user_cmd, cwd_setting)
			else:
				logging.debug('docker does not exist, use parrot execution engine')
				specification_process(spec_json, sandbox_dir, behavior, packages_json, 'parrot', output_dir, input_dict, env_para_dict, user_cmd, cwd_setting)
		else:
			if batch_type == 'docker' and dependency_check('docker') != 0:
				logging.critical('Docker is not installed on the host machine, please try other execution engines!')
				sys.exit('Docker is not installed on the host machine, please try other execution engines!')
			specification_process(spec_json, sandbox_dir, behavior, packages_json, batch_type, output_dir, input_dict, env_para_dict, user_cmd, cwd_setting)
	end = datetime.datetime.now()
	diff = end - start
	print "Start time: ", start
	print "End time: ", end
	print "execution time: ", diff.seconds

if __name__ == "__main__":
	main()

#set sts=4 sw=4 ts=4 expandtab ft=python
